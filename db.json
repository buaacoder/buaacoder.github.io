{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/header.jpg","path":"images/header.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"334da94ca6f024d60d012cc26ea655681e724ad8","modified":1568959987388},{"_id":"themes/next/.editorconfig","hash":"211d2c92bfdddb3e81ea946f4ca7a539f150f4da","modified":1568959987389},{"_id":"themes/next/.gitattributes","hash":"8454b9313cb1a97b63fb87e2d29daee497ce6249","modified":1568959987391},{"_id":"themes/next/.gitignore","hash":"ee0b13c268cc8695d3883a5da84930af02d4ed08","modified":1568959987397},{"_id":"themes/next/.hound.yml","hash":"289dcf5bfe92dbd680d54d6e0668f41c9c9c0c78","modified":1568959987399},{"_id":"themes/next/.javascript_ignore","hash":"cd250ad74ca22bd2c054476456a73d9687f05f87","modified":1568959987400},{"_id":"themes/next/.jshintrc","hash":"b7d23f2ce8d99fa073f22f9960605f318acd7710","modified":1568959987401},{"_id":"themes/next/.stylintrc","hash":"3b7f9785e9ad0dab764e1c535b40df02f4ff5fd6","modified":1568959987402},{"_id":"themes/next/.travis.yml","hash":"6674fbdfe0d0c03b8a04527ffb8ab66a94253acd","modified":1568959987404},{"_id":"themes/next/LICENSE","hash":"ec44503d7e617144909e54533754f0147845f0c5","modified":1568959987405},{"_id":"themes/next/README.cn.md","hash":"b878b73f3fcdef47849453c94420871903d487b3","modified":1568959987407},{"_id":"themes/next/README.md","hash":"efcdc4b0ca791c3fc64afa28c8721e137f2d11ea","modified":1568959987408},{"_id":"themes/next/_config.yml","hash":"9164115d728d91c986b5f9947fb60f0e2de3a7d2","modified":1608548494031},{"_id":"themes/next/bower.json","hash":"486ebd72068848c97def75f36b71cbec9bb359c5","modified":1568959987411},{"_id":"themes/next/gulpfile.coffee","hash":"412defab3d93d404b7c26aaa0279e2e586e97454","modified":1568959987412},{"_id":"themes/next/package.json","hash":"3963ad558a24c78a3fd4ef23cf5f73f421854627","modified":1568959987539},{"_id":"source/_posts/01背包.md","hash":"66de978b241101eb12ee5b3d3395928c22695817","modified":1569751492493},{"_id":"source/_posts/Mobilenetv2_第一版.md","hash":"7fde40b5aa3094110ff94e1cecaf10cb2ff239ac","modified":1580268685272},{"_id":"source/_posts/Mobilenetv2_第三版.md","hash":"0f60ca9d75ce0b07a14681d6bc298359adf439d1","modified":1580299699250},{"_id":"source/_posts/Mobilenetv2_第二版.md","hash":"a6039167e1282341349042c0c44a9f4339b8e768","modified":1580296036775},{"_id":"source/_posts/STL容器的总结.md","hash":"54047b6704fbbcdd6660c2ddc21cf7a83363ef8f","modified":1599442389319},{"_id":"source/_posts/git操作.md","hash":"5bc765260bf5ca9b56753aaeffe7f95fe0dc218d","modified":1599442391956},{"_id":"source/_posts/torch操作总结.md","hash":"0948d36510807921330013553ab4ee4bd339f373","modified":1579859639930},{"_id":"source/_posts/关于此博客.md","hash":"e8678ec432dbd2d09b4ffc2c8b85490d2a8be149","modified":1569751500369},{"_id":"source/_posts/数字电路.md","hash":"45b65c8d36d514c9b48bbd61c0ea2ccbd670d3f8","modified":1608544711620},{"_id":"source/_posts/最短路算法.md","hash":"225d97ee9db17e2f31f7b8d4de464b0c25c3049f","modified":1574698820509},{"_id":"source/_posts/最小生成树.md","hash":"d8d02671e38021af0153b9ceaf9caf4e6077d8c9","modified":1574687827382},{"_id":"source/_posts/智能计算机.md","hash":"c60a414154bc0c54323760a00366ea02833dc233","modified":1610984449835},{"_id":"source/_posts/第一次上机E题题解.md","hash":"a46e4802e4f20b2a28eb7ac4ec283393a604e728","modified":1570768673894},{"_id":"source/_posts/状压dp.md","hash":"a58e1f6c7e8b235118a1b010ff3220b8c18a21b7","modified":1569751514417},{"_id":"source/categories/index.md","hash":"ccf2eba5cb3b4bf4c3631b12505c825a1dc3c84a","modified":1569499660304},{"_id":"source/schedule/index.md","hash":"6542aa5a419b8e5d89e087091a883248305925ce","modified":1569500233469},{"_id":"source/tags/index.md","hash":"975415cba5940331c23256985759e145ac2a6772","modified":1569499501032},{"_id":"themes/next/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1568959987342},{"_id":"themes/next/.git/config","hash":"8e94cc015a498d35202e9fd57e44b3c51e1e5634","modified":1568959987358},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1568959965640},{"_id":"themes/next/.git/index","hash":"8441226cd9b0f5725a16fd4721bb3b56757e650d","modified":1568959987971},{"_id":"themes/next/.git/packed-refs","hash":"3bb2e8e3fad44742d3e3bfadfb0b4d791fe9fe9e","modified":1568959987331},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5adfad3ef1b870063e621bc0838268eb2c7c697a","modified":1568959987392},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"a0a82dbfabdef9a9d7c17a08ceebfb4052d98d81","modified":1568959987393},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1228506a940114288d61812bfe60c045a0abeac1","modified":1568959987395},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1568959987396},{"_id":"themes/next/languages/de.yml","hash":"fd02d9c2035798d5dc7c1a96b4c3e24b05b31a47","modified":1568959987414},{"_id":"themes/next/languages/en.yml","hash":"2f4b4776ca1a08cc266a19afb0d1350a3926f42c","modified":1568959987417},{"_id":"themes/next/languages/default.yml","hash":"b3bcd8934327448a43d9bfada5dd11b1b8c1402e","modified":1568959987415},{"_id":"themes/next/languages/id.yml","hash":"dccae33e2a5b3c9f11c0e05ec4a7201af1b25745","modified":1568959987420},{"_id":"themes/next/languages/fr-FR.yml","hash":"efeeb55d5c4add54ad59a612fc0630ee1300388c","modified":1568959987418},{"_id":"themes/next/languages/it.yml","hash":"a215d016146b1bd92cef046042081cbe0c7f976f","modified":1568959987421},{"_id":"themes/next/languages/ja.yml","hash":"37f954e47a3bc669620ca559e3edb3b0072a4be5","modified":1568959987422},{"_id":"themes/next/languages/ko.yml","hash":"dc8f3e8c64eb7c4bb2385025b3006b8efec8b31d","modified":1568959987423},{"_id":"themes/next/languages/nl-NL.yml","hash":"213e7a002b82fb265f69dabafbbc382cfd460030","modified":1568959987425},{"_id":"themes/next/languages/pt-BR.yml","hash":"568d494a1f37726a5375b11452a45c71c3e2852d","modified":1568959987426},{"_id":"themes/next/languages/pt.yml","hash":"2efcd240c66ab1a122f061505ca0fb1e8819877b","modified":1568959987427},{"_id":"themes/next/languages/ru.yml","hash":"e33ee44e80f82e329900fc41eb0bb6823397a4d6","modified":1568959987428},{"_id":"themes/next/languages/vi.yml","hash":"a9b89ebd3e5933033d1386c7c56b66c44aca299a","modified":1568959987430},{"_id":"themes/next/languages/zh-Hans.yml","hash":"66b9b42f143c3cb2f782a94abd4c4cbd5fd7f55f","modified":1568959987431},{"_id":"themes/next/languages/zh-hk.yml","hash":"fe0d45807d015082049f05b54714988c244888da","modified":1568959987432},{"_id":"themes/next/languages/zh-tw.yml","hash":"432463b481e105073accda16c3e590e54c8e7b74","modified":1568959987433},{"_id":"themes/next/layout/_layout.swig","hash":"2164570bb05db11ee4bcfbbb5d183a759afe9d07","modified":1568959987436},{"_id":"themes/next/layout/archive.swig","hash":"9a2c14874a75c7085d2bada5e39201d3fc4fd2b4","modified":1568959987529},{"_id":"themes/next/layout/category.swig","hash":"3cbb3f72429647411f9e85f2544bdf0e3ad2e6b2","modified":1568959987531},{"_id":"themes/next/layout/index.swig","hash":"555a357ecf17128db4e29346c92bb6298e66547a","modified":1568959987532},{"_id":"themes/next/layout/page.swig","hash":"e8fcaa641d46930237675d2ad4b56964d9e262e9","modified":1568959987534},{"_id":"themes/next/layout/post.swig","hash":"7a6ce102ca82c3a80f776e555dddae1a9981e1ed","modified":1568959987535},{"_id":"themes/next/layout/schedule.swig","hash":"87ad6055df01fa2e63e51887d34a2d8f0fbd2f5a","modified":1568959987536},{"_id":"themes/next/layout/tag.swig","hash":"34e1c016cbdf94a31f9c5d494854ff46b2a182e9","modified":1568959987538},{"_id":"themes/next/scripts/merge-configs.js","hash":"38d86aab4fc12fb741ae52099be475196b9db972","modified":1568959987541},{"_id":"themes/next/scripts/merge.js","hash":"39b84b937b2a9608b94e5872349a47200e1800ff","modified":1568959987543},{"_id":"themes/next/test/.jshintrc","hash":"c9fca43ae0d99718e45a6f5ce736a18ba5fc8fb6","modified":1568959987964},{"_id":"themes/next/test/helpers.js","hash":"f25e7f3265eb5a6e1ccbb5e5012fa9bebf134105","modified":1568959987965},{"_id":"themes/next/test/intern.js","hash":"db90b1063356727d72be0d77054fdc32fa882a66","modified":1568959987967},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1568959987700},{"_id":"source/_posts/数字电路/image-20201207100101916.png","hash":"b01d1a1f722c3ec4d7e5e25b6c5495da7407d812","modified":1607306461922},{"_id":"source/_posts/数字电路/image-20201207100105985.png","hash":"988ce7cbdab3874b9f568a13b5911fb417ea23b6","modified":1607306465994},{"_id":"source/_posts/数字电路/image-20201207100058038.png","hash":"309141b91b97d8acf1e6c3a3c0d881310a5f046f","modified":1607306458042},{"_id":"source/_posts/数字电路/image-20201207100108953.png","hash":"26a6987d7ff9bee9fdc558b34fee034a5c420b15","modified":1607306468959},{"_id":"source/_posts/数字电路/image-20201207100339923.png","hash":"9fa09bb1200c9947b5fa947f5d839e09290ae575","modified":1607306619938},{"_id":"source/_posts/数字电路/image-20201207100458411.png","hash":"f172933cf56640284b42dd89783fd470dbfd641f","modified":1607306698425},{"_id":"source/_posts/数字电路/image-20201207143351015.png","hash":"bfa4b3d0239e1e6c75c2b5249952e02ca1c49ea4","modified":1607322831020},{"_id":"source/_posts/数字电路/image-20201207143605620.png","hash":"a4d9ab9b0e2b980acde81d16c86181e9be145ef8","modified":1607322965635},{"_id":"source/_posts/数字电路/image-20201207150409345.png","hash":"79b6173bf2610e2f5f99659492708d9b7583ee45","modified":1607324649357},{"_id":"source/_posts/数字电路/image-20201207155711758.png","hash":"0f9057039512521878b2142d59aada39ef134836","modified":1607327831764},{"_id":"source/_posts/数字电路/image-20201207160054355.png","hash":"f394fe0a53c83ae313e818a74cb9347516afdbcb","modified":1607328054680},{"_id":"source/_posts/数字电路/image-20201207163239045.png","hash":"62ca87c0295e484515ea1043591866470fcb2201","modified":1607329959053},{"_id":"source/_posts/数字电路/image-20201207164852673.png","hash":"030827c689b79167b003c696457421b206e178ad","modified":1607330932776},{"_id":"source/_posts/数字电路/image-20201207202738889.png","hash":"2641f29c6ca2690436df1f12eda3cc2d79531e02","modified":1607344058971},{"_id":"source/_posts/数字电路/image-20201207211753609.png","hash":"3c1684fb8626a1636cae93f6c79bac2bfe7e856e","modified":1607347073651},{"_id":"source/_posts/数字电路/image-20201207231703395.png","hash":"1fb633d36196eb7f628ee5b468d07cdd021c396e","modified":1607354223415},{"_id":"source/_posts/数字电路/image-20201207234319334.png","hash":"78c2ecdb63756cf03fc4ce471d892e694bb71b5e","modified":1607355799352},{"_id":"source/_posts/数字电路/image-20201208093951521.png","hash":"2f556c824c8cfeba257f1cc96037a831b71d6b9e","modified":1607391591537},{"_id":"source/_posts/数字电路/image-20201208095118685.png","hash":"2676c648d423fa3c8c7b8dc744adb21a8d42a4c5","modified":1607392278696},{"_id":"source/_posts/数字电路/image-20201208100213115.png","hash":"840cc9f26ab91e6744d5bc45d09c550b85c2ae75","modified":1607392933259},{"_id":"source/_posts/数字电路/image-20201208100311393.png","hash":"52805e700d42195b6ba8c45d7986a21420a7b3c5","modified":1607392991398},{"_id":"source/_posts/数字电路/image-20201208100710777.png","hash":"35656b209d31e2bfd2da2f2828ba1f91e5d7db24","modified":1607393230797},{"_id":"source/_posts/数字电路/image-20201208102916928.png","hash":"76748cd010cbfe48a36ab8454179c62e2817c3ba","modified":1607394556943},{"_id":"source/_posts/数字电路/image-20201208103304650.png","hash":"d7c8320df6f5bf6462ce57ea0653663ecfa3c1eb","modified":1607394784655},{"_id":"source/_posts/数字电路/image-20201208103050351.png","hash":"ffaaa807ee0ac73c41420ee21a030927556bb6d2","modified":1607394650356},{"_id":"source/_posts/数字电路/image-20201208120335673.png","hash":"5a6abbb6fef06b21b33ff635a215a8a1a73c71a6","modified":1607400215675},{"_id":"source/_posts/数字电路/image-20201208133000921.png","hash":"6ea3e46e0c7832973f765592957102da72dfc521","modified":1607405400935},{"_id":"source/_posts/数字电路/image-20201208133500161.png","hash":"cbe400ff81b2264d957cc392b9c2bc5dfc0432b3","modified":1607405700173},{"_id":"source/_posts/数字电路/image-20201208162623051.png","hash":"a7c31e981c0f40fbc27277abaa000041106a3d00","modified":1607415983072},{"_id":"source/_posts/数字电路/image-20201208163034352.png","hash":"126736da4b5b4457ee36aff7616aecfe75d7b786","modified":1607416234357},{"_id":"source/_posts/数字电路/image-20201208192312875.png","hash":"70c9a72818418f2822e3441a1b5215fe15b48d77","modified":1607426592908},{"_id":"source/_posts/数字电路/image-20201208192326383.png","hash":"7ee71f9606484c6c3093ca91497cf758870d5a44","modified":1607426606429},{"_id":"source/_posts/数字电路/image-20201208211825145.png","hash":"d18429f88dc87c69ffc1a6ed99cf370189edcd09","modified":1607433505158},{"_id":"source/_posts/数字电路/image-20201208212439760.png","hash":"af31ef32eea5b4210e6a1d15300fb84c05e0519a","modified":1607433879766},{"_id":"source/_posts/数字电路/image-20201208214549378.png","hash":"346c8ef92418e497018b151af59aa12a96895867","modified":1607435149382},{"_id":"source/_posts/数字电路/image-20201208215405366.png","hash":"323315ed9a1e2fff4b55785a599b6e16c662906e","modified":1607435645376},{"_id":"source/_posts/数字电路/image-20201208215859239.png","hash":"977b9fb79d6a57439327a84590d5e90c536cc390","modified":1607435939246},{"_id":"source/_posts/数字电路/image-20201209091933646.png","hash":"35039a66fc325195ec82862fa4397d49b498f4ab","modified":1607476773711},{"_id":"source/_posts/智能计算机/image-20201221161604172.png","hash":"3d7e8b4429182ac3e12a471b8ab731d8531dfb3b","modified":1608538564235},{"_id":"source/_posts/智能计算机/image-20201221170316556.png","hash":"f622dd4ad6ad8acf8b219063d79a0c762c3fd2ac","modified":1608541396570},{"_id":"source/_posts/智能计算机/image-20201221171419046.png","hash":"4ac09f41e7c46d7064af4422f81fc56faf3d3b33","modified":1608542059063},{"_id":"source/_posts/智能计算机/image-20201221173107160.png","hash":"860c97a1c0d1f361862cab7ba5421040dbdb0430","modified":1608543067180},{"_id":"source/_posts/智能计算机/image-20201221173555856.png","hash":"02d70bf7fdd7e64349a4f88d6e6638fe87f8b651","modified":1608543355875},{"_id":"source/_posts/智能计算机/image-20201221173834863.png","hash":"36e36c60423dd7c8c6971e44850cc98ae614dbc5","modified":1608543514866},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1568959965641},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1568959965642},{"_id":"themes/next/.git/hooks/fsmonitor-watchman.sample","hash":"f7c0aa40cb0d620ff0bca3efe3521ec79e5d7156","modified":1568959965643},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1568959965643},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1568959965644},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"33729ad4ce51acda35094e581e4088f3167a0af8","modified":1568959965646},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1568959965646},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1568959965647},{"_id":"themes/next/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1568959965647},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1568959965648},{"_id":"themes/next/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1568959965649},{"_id":"themes/next/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1568959965649},{"_id":"themes/next/.git/logs/HEAD","hash":"f0603ed9d7b9bd815cc0b781597bef2672c11e74","modified":1568959987348},{"_id":"themes/next/layout/_custom/header.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1568959987436},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"c97bbd2bd56e1e610ce19f9634b56efd5e107bf4","modified":1569321497338},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"f83befdc740beb8dc88805efd7fbb0fef9ed19be","modified":1568959987439},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"8c56dd26157cbc580ae41d97ac34b90ab48ced3f","modified":1568959987439},{"_id":"themes/next/layout/_macro/reward.swig","hash":"357d86ec9586705bfbb2c40a8c7d247a407db21a","modified":1568959987442},{"_id":"themes/next/layout/_macro/post.swig","hash":"4ba938822d56c597490f0731893eaa2443942e0f","modified":1568959987442},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"265cbed84c3470fbfe60e6b17d96489d27d847d7","modified":1569309978493},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"e2e4eae391476da994045ed4c7faf5e05aca2cd7","modified":1568959987445},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4adc65a602d1276615da3b887dcbf2ac68e7382b","modified":1568959987448},{"_id":"themes/next/layout/_partials/footer.swig","hash":"58e63d890724fcf957e1898f0c5a1d1e5699f543","modified":1570504590535},{"_id":"themes/next/layout/_partials/head.swig","hash":"f14a39dad1ddd98e6d3ceb25dda092ba80d391b5","modified":1568959987450},{"_id":"themes/next/layout/_partials/header.swig","hash":"c54b32263bc8d75918688fb21f795103b3f57f03","modified":1568959987454},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"77c61e0baea3544df361b7338c3cd13dc84dde22","modified":1568959987455},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"1634fb887842698e01ff6e632597fe03c75d2d01","modified":1568959987457},{"_id":"themes/next/layout/_partials/search.swig","hash":"b4ebe4a52a3b51efe549dd1cdee846103664f5eb","modified":1568959987458},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"931808ad9b8d8390c0dcf9bdeb0954eeb9185d68","modified":1568959987470},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9be624634703be496a5d2535228bc568a8373af9","modified":1568959987477},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"c0f5a0955f69ca4ed9ee64a2d5f8aa75064935ad","modified":1568959987469},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"ba75672183d94f1de7c8bd0eeee497a58c70e889","modified":1568959987510},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"8301c9600bb3e47f7fb98b0e0332ef3c51bb1688","modified":1568959987511},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"a0bd3388587fd943baae0d84ca779a707fbcad89","modified":1568959987512},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"fa882641da3bd83d9a58a8a97f9d4c62a9ee7b5c","modified":1568959987514},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"554ec568e9d2c71e4a624a8de3cb5929050811d6","modified":1568959987515},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"db15d7e1552aa2d2386a6b8a33b3b3a40bf9e43d","modified":1568959987517},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"9a188938d46931d5f3882a140aa1c48b3a893f0c","modified":1568959987518},{"_id":"themes/next/scripts/tags/button.js","hash":"eddbb612c15ac27faf11c59c019ce188f33dec2c","modified":1568959987546},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"99b66949f18398689b904907af23c013be1b978f","modified":1568959987546},{"_id":"themes/next/scripts/tags/exturl.js","hash":"5022c0ba9f1d13192677cf1fd66005c57c3d0f53","modified":1568959987547},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"ac681b0d0d8d39ba3817336c0270c6787c2b6b70","modified":1568959987550},{"_id":"themes/next/scripts/tags/full-image.js","hash":"c9f833158c66bd72f627a0559cf96550e867aa72","modified":1568959987549},{"_id":"themes/next/scripts/tags/label.js","hash":"6f00952d70aadece844ce7fd27adc52816cc7374","modified":1568959987551},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"bcba2ff25cd7850ce6da322d8bd85a8dd00b5ceb","modified":1568959987553},{"_id":"themes/next/scripts/tags/note.js","hash":"f7eae135f35cdab23728e9d0d88b76e00715faa0","modified":1568959987554},{"_id":"themes/next/scripts/tags/tabs.js","hash":"aa7fc94a5ec27737458d9fe1a75c0db7593352fd","modified":1568959987555},{"_id":"themes/next/source/css/main.styl","hash":"a91dbb7ef799f0a171b5e726c801139efe545176","modified":1568959987699},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1568959987701},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1568959987702},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1568959987704},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1568959987705},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1568959987707},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1568959987709},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1568959987710},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1568959987711},{"_id":"themes/next/source/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1568959987713},{"_id":"themes/next/source/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1568959987714},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1568959987715},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1568959987716},{"_id":"themes/next/source/images/header.jpg","hash":"2468631d3d39c618d9f979dd0d88d9b0e10b36a9","modified":1569506619254},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1568959987717},{"_id":"themes/next/source/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1568959987719},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1568959987720},{"_id":"themes/next/source/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1568959987721},{"_id":"themes/next/source/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1568959987723},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1568959987724},{"_id":"source/_posts/数字电路/image-20201207095115200.png","hash":"ff3c0b6316ab16a9343d9e21188e861707e99f12","modified":1607305875249},{"_id":"source/_posts/数字电路/image-20201207095702879.png","hash":"42f473b2603984168c903595acfc34a030aa9ede","modified":1607306222896},{"_id":"source/_posts/数字电路/image-20201207100257128.png","hash":"e2aa11fb165062682803214965be327bb9c64a2c","modified":1607306577143},{"_id":"source/_posts/数字电路/image-20201207141227512.png","hash":"1ce71b33fdc4105dc3861d150f309aaa532cda12","modified":1607321547567},{"_id":"source/_posts/数字电路/image-20201207141230974.png","hash":"0be0d7d089387fcfcd996f2c024493f7128aeac1","modified":1607321550996},{"_id":"source/_posts/数字电路/image-20201207155851664.png","hash":"8d1e66b9417c2c5aedd3c7e19d81953be49a326a","modified":1607327931682},{"_id":"source/_posts/数字电路/image-20201207180624804.png","hash":"cea4460a84ce5843e40be1d58b892f817d033071","modified":1607335584823},{"_id":"source/_posts/数字电路/image-20201207202208723.png","hash":"20a6a049b80550dbb015e4c7cc0aae84ddaca94f","modified":1607343728854},{"_id":"source/_posts/数字电路/image-20201207202442317.png","hash":"ea44990663f58f2b055e8f8acdde76b5939035b5","modified":1607343882394},{"_id":"source/_posts/数字电路/image-20201207204428555.png","hash":"0e78da4fc8327fa8b94fb8e53c3016c10c0b220d","modified":1607345068668},{"_id":"source/_posts/数字电路/image-20201207210045223.png","hash":"9895665aae38d3d5c5f03d8f1cc5d9b7f9fd8fdc","modified":1607346045304},{"_id":"source/_posts/数字电路/image-20201207225752379.png","hash":"eff574aa511fad9000c7dc781e7eb7b81ee31ee1","modified":1607353072408},{"_id":"source/_posts/数字电路/image-20201207231253193.png","hash":"82f22e74f937370ee8525cad3718fd761f52a05b","modified":1607353973230},{"_id":"source/_posts/数字电路/image-20201207231257765.png","hash":"82f22e74f937370ee8525cad3718fd761f52a05b","modified":1607353977792},{"_id":"source/_posts/数字电路/image-20201208100252440.png","hash":"38a17863244e78291d7098d602015302fae783c9","modified":1607392972464},{"_id":"source/_posts/数字电路/image-20201208120149198.png","hash":"23d150c39c05c13400825e7e4f0d1297628e9219","modified":1607400109267},{"_id":"source/_posts/数字电路/image-20201208162700995.png","hash":"479143b43e62e67bc77f56445ec92c0b193faa98","modified":1607416021013},{"_id":"source/_posts/数字电路/image-20201208163053439.png","hash":"76436bc5351d92fad4358f47657e8d721fca0389","modified":1607416253465},{"_id":"source/_posts/数字电路/image-20201208163510773.png","hash":"077183511e2a9d45bfe76c14163daade925107c7","modified":1607416510790},{"_id":"source/_posts/数字电路/image-20201208214956731.png","hash":"bc153a596374e35b5ea1485c1b5575c8b8b52057","modified":1607435396761},{"_id":"source/_posts/数字电路/image-20201208215602590.png","hash":"474c405471a1bacb438b8841c7de6e1cc960805b","modified":1607435762606},{"_id":"source/_posts/数字电路/image-20201208215654220.png","hash":"80daaec9fb801494c0c237eb8b62ce2f1d75ec7f","modified":1607435814229},{"_id":"source/_posts/数字电路/image-20201208215639819.png","hash":"6fa78fc1f53536e6b53dce4ddbd534e99d420155","modified":1607435799842},{"_id":"source/_posts/数字电路/image-20201209092949508.png","hash":"fa23d0e39e9b18cbead8250769c0ed59aa9cf756","modified":1607477389542},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1568959987474},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1568959987475},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1568959987656},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1568959987657},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1568959987660},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1568959987694},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1568959987697},{"_id":"source/_posts/数字电路/image-20201207155940917.png","hash":"c693224c47a4457ccfd6254a7648c075e0dff254","modified":1607327980940},{"_id":"source/_posts/数字电路/image-20201207202617679.png","hash":"28753a12f6a2ef1fe742cd86a6924028d6ffd619","modified":1607343977853},{"_id":"source/_posts/数字电路/image-20201207204956445.png","hash":"6767c45d14f30e7c11e85fe176713e67bdd55826","modified":1607345396593},{"_id":"source/_posts/数字电路/image-20201207234431264.png","hash":"19cf9761663b441307581144fdae9a12daca927c","modified":1607355871294},{"_id":"source/_posts/数字电路/image-20201208094730885.png","hash":"d7e74c14877ecf40d64f93bacf93275591fce318","modified":1607392050923},{"_id":"source/_posts/数字电路/image-20201208103414917.png","hash":"48b837cdc4d91620e1ec82fe67c79321a2190146","modified":1607394854948},{"_id":"source/_posts/数字电路/image-20201208103416148.png","hash":"48b837cdc4d91620e1ec82fe67c79321a2190146","modified":1607394856189},{"_id":"source/_posts/数字电路/image-20201208211819333.png","hash":"af1ee8586ee0928f04d4406ffa3da2b3667c9048","modified":1607433499390},{"_id":"source/_posts/数字电路/image-20201208214717350.png","hash":"60da6abd96582c7a863e756df9d3a1a0d0e93d21","modified":1607435237383},{"_id":"source/_posts/数字电路/image-20201208215327269.png","hash":"480f55205244a1b599b98569ac20bb1ef15f6181","modified":1607435607291},{"_id":"source/_posts/数字电路/image-20201208215446146.png","hash":"a9dc65aa42104631c2060a647c265453844283a7","modified":1607435686185},{"_id":"themes/next/.git/refs/heads/master","hash":"3c959678e3fe6e51e935526c19927d21443a3be3","modified":1568959987347},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"a223919d2e1bf17ca4d6abb2c86f2efca9883dc1","modified":1568959987452},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"f5e487b0d213ca0bd94aa30bc23b240d65081627","modified":1568959987453},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"b2f0d247b213e4cf8de47af6a304d98070cc7256","modified":1568959987460},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"a8c7f9ca7c605d039a1f3bf4e4d3183700a3dd62","modified":1568959987461},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"b25002a83cbd2ca0c4a5df87ad5bff26477c0457","modified":1568959987462},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"9e3d133ac5bcc6cb51702c83b2611a49811abad1","modified":1568959987463},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"d9e2d9282f9be6e04eae105964abb81e512bffed","modified":1568959987465},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"d4fbffd7fa8f2090eb32a871872665d90a885fac","modified":1568959987467},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"0a9cdd6958395fcdffc80ab60f0c6301b63664a5","modified":1568959987468},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"9b84ab576982b2c3bb0291da49143bc77fba3cc6","modified":1568959987472},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1568959987474},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1568959987475},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"ff947f3561b229bc528cb1837d4ca19612219411","modified":1568959987479},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"71397a5823e8ec8aad3b68aace13150623b3e19d","modified":1568959987481},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"753d262911c27baf663fcaf199267133528656af","modified":1568959987482},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"7b11eac3a0685fa1ab2ab6ecff60afc4f15f0d16","modified":1568959987483},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"a10b7f19d7b5725527514622899df413a34a89db","modified":1568959987484},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"7d94845f96197d9d84a405fa5d4ede75fb81b225","modified":1568959987485},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"ccc443b22bd4f8c7ac4145664686c756395b90e0","modified":1568959987487},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"b1e13df83fb2b1d5d513b30b7aa6158b0837daab","modified":1568959987488},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"45f3f629c2aacc381095750e1c8649041a71a84b","modified":1568959987489},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"5a8027328f060f965b3014060bebec1d7cf149c1","modified":1568959987494},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"e6d10ee4fb70b3ae1cd37e9e36e000306734aa2e","modified":1568959987491},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"8a399df90dadba5ad4e781445b58f4765aeb701e","modified":1568959987492},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"f9a1647a8f1866deeb94052d1f87a5df99cb1e70","modified":1568959987495},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"4c501ea0b9c494181eb3c607c5526a5754e7fbd8","modified":1568959987497},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b83a51bbe0f1e2ded9819070840b0ea145f003a6","modified":1568959987499},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"1600f340e0225361580c44890568dc07dbcf2c89","modified":1568959987500},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"4dcc3213c033994d342d02b800b6229295433d30","modified":1568959987502},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"af7f3e43cbdc4f88c13f101f0f341af96ace3383","modified":1568959987503},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"493bd5999a1061b981922be92d8277a0f9152447","modified":1568959987505},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"9246162d4bc7e949ce1d12d135cbbaf5dc3024ec","modified":1568959987506},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"4050553d44ba1396174161c9a6bb0f89fa779eca","modified":1568959987507},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"7e65ff8fe586cd655b0e9d1ad2912663ff9bd36c","modified":1568959987509},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"34599633658f3b0ffb487728b7766e1c7b551f5a","modified":1568959987522},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"93479642fd076a1257fecc25fcf5d20ccdefe509","modified":1568959987524},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"fe95dd3d166634c466e19aa756e65ad6e8254d3e","modified":1568959987526},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"d8c98938719284fa06492c114d99a1904652a555","modified":1568959987527},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"6558e3e9ae742c2d44aa90e8936022351c880dbe","modified":1569322071494},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"07f7da320689f828f6e36a6123807964a45157a0","modified":1568959987656},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"0e55cbd93852dc3f8ccb44df74d35d9918f847e0","modified":1568959987659},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"7896c3ee107e1a8b9108b6019f1c070600a1e8cc","modified":1568959987658},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"58e7dd5947817d9fc30770712fc39b2f52230d1e","modified":1568959987692},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"a25408534f8fe6e321db4bbf9dd03335d648fe17","modified":1568959987693},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"4069f918ccc312da86db6c51205fc6c6eaabb116","modified":1568959987695},{"_id":"themes/next/source/css/_variables/base.styl","hash":"3ff06a6d285e60b116705464a193d3ee854ee6b3","modified":1568962651909},{"_id":"themes/next/source/js/src/affix.js","hash":"1b509c3b5b290a6f4607f0f06461a0c33acb69b1","modified":1568959987725},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"cb431b54ba9c692165a1f5a12e4c564a560f8058","modified":1568959987726},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"0289031200c3d4c2bdd801ee10fff13bb2c353e4","modified":1568959987728},{"_id":"themes/next/source/js/src/exturl.js","hash":"a2a0f0de07e46211f74942a468f42ee270aa555c","modified":1568959987729},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"b35a7dc47b634197b93487cea8671a40a9fdffce","modified":1568959987730},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"1512c751d219577d338ac0780fb2bbd9075d5298","modified":1568959987732},{"_id":"themes/next/source/js/src/motion.js","hash":"885176ed51d468f662fbf0fc09611f45c7e5a3b1","modified":1568959987734},{"_id":"themes/next/source/js/src/post-details.js","hash":"93a18271b4123dd8f94f09d1439b47c3c19a8712","modified":1568959987735},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"02cf91514e41200bc9df5d8bdbeb58575ec06074","modified":1568959987737},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"b7657be25fc52ec67c75ab5481bdcb483573338b","modified":1568959987739},{"_id":"themes/next/source/js/src/utils.js","hash":"b3e9eca64aba59403334f3fa821f100d98d40337","modified":1568959987741},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1568959987762},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1568959987773},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"b02737510e9b89aeed6b54f89f602a9c24b06ff2","modified":1568959987775},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"9be892a4e14e0da18ff9cb962c9ef71f163b1b22","modified":1568959987777},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"672d3b5767e0eacd83bb41b188c913f2cf754793","modified":1568959987778},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"bf3eef9d647cd7c9b62feda3bc708c6cdd7c0877","modified":1568959987803},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1568959987804},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"68a9b9d53126405b0fa5f3324f1fb96dbcc547aa","modified":1568959987805},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"a9b3ee1e4db71a0e4ea6d5bed292d176dd68b261","modified":1568959987807},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"865d6c1328ab209a4376b9d2b7a7824369565f28","modified":1568959987888},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"b4aefc910578d76b267e86dfffdd5121c8db9aec","modified":1568959987812},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"03ddbf76c1dd1afb93eed0b670d2eee747472ef1","modified":1568959987814},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"c31ff06a740955e44edd4403902e653ccabfd4db","modified":1568959987815},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1568959987816},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"71e7183634dc1b9449f590f15ebd7201add22ca7","modified":1568959987817},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"90fa628f156d8045357ff11eaf32e61abacf10e8","modified":1568959987893},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4ded6fee668544778e97e38c2b211fc56c848e77","modified":1568959987894},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"b930297cb98b8e1dbd5abe9bc1ed9d5935d18ce8","modified":1568959987895},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"f4a570908f6c89c6edfb1c74959e733eaadea4f2","modified":1568959987898},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"e0acf1db27b0cc16128a59c46db1db406b5c4c58","modified":1568959987896},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"bf773ad48a0b9aa77681a89d7569eefc0f7b7b18","modified":1568959987900},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"14264a210bf94232d58d7599ea2ba93bfa4fb458","modified":1568959987903},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"e33aa8fa48b6639d8d8b937d13261597dd473b3a","modified":1568959987904},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"2ce5f3bf15c523b9bfc97720d8884bb22602a454","modified":1568959987907},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1568959987908},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1568959987910},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1568959987912},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1568959987913},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1568959987915},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1568959987916},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1568959987917},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1568959987919},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1568959987920},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1568959987921},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1568959987922},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1568959987924},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1568959987925},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"8aaa675f577d5501f5f22d5ccb07c2b76310b690","modified":1568959987926},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"2d9a9f38c493fdf7c0b833bb9184b6a1645c11b2","modified":1568959987929},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"46a50b91c98b639c9a2b9265c5a1e66a5c656881","modified":1568959987930},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"8148492dd49aa876d32bb7d5b728d3f5bf6f5074","modified":1568959987931},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"63da5e80ebb61bb66a2794d5936315ca44231f0c","modified":1568959987950},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"92d92860418c4216aa59eb4cb4a556290a7ad9c3","modified":1568959987951},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1568959987959},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"dbbfb50f6502f6b81dcc9fee7b31f1e812da3464","modified":1568959987961},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1568959987963},{"_id":"source/_posts/数字电路/image-20201207103734768.png","hash":"3cb727584bcfcd006a68887a678572cc7ddf4712","modified":1607308654824},{"_id":"source/_posts/数字电路/image-20201207151538922.png","hash":"1e1a74a129514793505945b05842c09f2c33468f","modified":1607325338959},{"_id":"source/_posts/数字电路/image-20201207164837016.png","hash":"f05e1552e2e8773274e801045a999bb1fb92508c","modified":1607330917057},{"_id":"source/_posts/数字电路/image-20201207205834377.png","hash":"ad0f91b6751cd392a7673ce8337d96a274bb6404","modified":1607345914577},{"_id":"source/_posts/数字电路/image-20201208212442919.png","hash":"603b3fdb52f24d485721ce91620aef13c8141574","modified":1607433882939},{"_id":"source/_posts/智能计算机/image-20201221173352870.png","hash":"8de819712861a65c7f7112d68058d5f10c332b38","modified":1608543232964},{"_id":"themes/next/source/lib/jquery/index.js","hash":"17a740d68a1c330876c198b6a4d9319f379f3af2","modified":1568959987891},{"_id":"source/_posts/数字电路/image-20201207141338902.png","hash":"b90ee0ca2378015ed8dfcea9bece2738e0259b7b","modified":1607321619016},{"_id":"source/_posts/数字电路/image-20201207163011726.png","hash":"9a93370cba7679c9e67742d466e30cd8a09210aa","modified":1607329811763},{"_id":"source/_posts/数字电路/image-20201207180435959.png","hash":"7ad185157544531002c784059e31a217d3b9a488","modified":1607335476019},{"_id":"source/_posts/数字电路/image-20201207204622034.png","hash":"6023a324f40790f5f210d6bf428e35af63736896","modified":1607345182223},{"_id":"source/_posts/数字电路/image-20201207205904689.png","hash":"ad0f91b6751cd392a7673ce8337d96a274bb6404","modified":1607345944774},{"_id":"source/_posts/数字电路/image-20201207230758027.png","hash":"0998b74e4bba7fd4119b66057c9fe6897d86ef07","modified":1607353678064},{"_id":"themes/next/.git/logs/refs/heads/master","hash":"f0603ed9d7b9bd815cc0b781597bef2672c11e74","modified":1568959987350},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1568959987340},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"218cc936ba3518a3591b2c9eda46bc701edf7710","modified":1568959987520},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"2530de0f3125a912756f6c0e9090cd012134a4c5","modified":1568959987522},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"8f86f694c0749a18ab3ad6f6df75466ca137a4bc","modified":1568959987558},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"237d185ac62ec9877e300947fa0109c44fb8db19","modified":1568959987559},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"7ad4081466b397e2a6204141bb7768b7c01bd93c","modified":1568959987563},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"8b32928686c327151e13d3ab100157f9a03cd59f","modified":1568959987561},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"ff4489cd582f518bba6909a301ac1292a38b4e96","modified":1568959987562},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"4f2801fc4cf3f31bf2069f41db8c6ce0e3da9e39","modified":1568959987584},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"6eb4bcc3056bd279d000607e8b4dad50d368ca69","modified":1568959987618},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"12662536c7a07fff548abe94171f34b768dd610f","modified":1568959987644},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"24ee4b356ff55fc6e58f26a929fa07750002cf29","modified":1568959987646},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"1da5c800d025345f212a3bf1be035060f4e5e6ed","modified":1568959987648},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"91ca75492cd51f2553f4d294ed2f48239fcd55eb","modified":1568959987649},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"3f40e8a9fe8e7bd5cfc4cf4cbbbcb9539462e973","modified":1568959987650},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a17e2b871a335f290afb392a08f94fd35f59c715","modified":1568959987652},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"ea9069645696f86c5df64208490876fe150c8cae","modified":1568959987653},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"60fa84aa7731760f05f52dd7d8f79b5f74ac478d","modified":1568959987661},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"25d5e45a355ee2093f3b8b8eeac125ebf3905026","modified":1568959987663},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"d0bfd1bef988c76f7d7dd72d88af6f0908a8b0db","modified":1568959987664},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"b1025c421406d2c24cc92a02ae28c1915b01e240","modified":1568959987666},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"26666c1f472bf5f3fb9bc62081cca22b4de15ccb","modified":1568959987667},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"9c99034f8e00d47e978b3959f51eb4a9ded0fcc8","modified":1568959987669},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9b913b73d31d21f057f97115ffab93cfa578b884","modified":1568959987672},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1568959987670},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"31127dcbf4c7b4ada53ffbf1638b5fe325b7cbc0","modified":1568959987676},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"e695e58f714129ca292c2e54cd62c251aca7f7fe","modified":1568959987678},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"748dbfbf9c08e719ddc775958003c64b00d39dab","modified":1568959987678},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"5dbc0d0c897e46760e5dbee416530d485c747bba","modified":1568959987681},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1568959987679},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"bce344d3a665b4c55230d2a91eac2ad16d6f32fd","modified":1568959987685},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"416988dca389e6e2fdfa51fa7f4ee07eb53f82fb","modified":1568959987685},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"4642e30010af8b2b037f5b43146b10a934941958","modified":1568959987687},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"1f6e2ce674735269599acc6d77b3ea18d31967fc","modified":1568959987688},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"86197902dfd3bededba10ba62b8f9f22e0420bde","modified":1568959987691},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"f1d0b5d7af32c423eaa8bb93ab6a0b45655645dc","modified":1568959987736},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"ad2dcedf393ed1f3f5afd2508d24969c916d02fc","modified":1568959987690},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"16b03db23a52623348f37c04544f2792032c1fb6","modified":1568959987759},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"6d586bfcfb7ae48f1b12f76eec82d3ad31947501","modified":1568959987758},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1568959987780},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1568959987781},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1568959987782},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1568959987784},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1568959987785},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1568959987787},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1568959987797},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"d71602cbca33b9ecdb7ab291b7f86a49530f3601","modified":1568959987799},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1568959987802},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1568959987811},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1568959987824},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"41ea797c68dbcff2f6fb3aba1d1043a22e7cc0f6","modified":1568959987946},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"a817b6c158cbc5bab3582713de9fe18a18a80552","modified":1568959987948},{"_id":"source/_posts/数字电路/image-20201207163100622.png","hash":"a6718ed741234dac1e256bfb3e2c7f24bd26229e","modified":1607329860787},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"6c26cdb36687d4f0a11dabf5290a909c3506be5c","modified":1568959987752},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"1d6aeda0480d0e4cb6198edf7719d601d4ae2ccc","modified":1568959987809},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"3655f1fdf1e584c4d8e8d39026093ca306a5a341","modified":1568959987819},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1568959987821},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1568959987864},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1568959987886},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"4237c6e9d59da349639de20e559e87c2c0218cfd","modified":1568959987957},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"f0603ed9d7b9bd815cc0b781597bef2672c11e74","modified":1568959987340},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"53cde051e0337f4bf42fb8d6d7a79fa3fa6d4ef2","modified":1568959987567},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d63e0cacc53dd375fcc113465a4328c59ff5f2c1","modified":1568959987568},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"1a0d059799a298fe17c49a44298d32cebde93785","modified":1568959987569},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"0656e753f182c9f47fef7304c847b7587a85ef0d","modified":1568959987570},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"1727702eac5d326b5c81a667944a245016668231","modified":1568959987572},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"9f73c4696f0907aa451a855444f88fc0698fa472","modified":1568959987565},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"b6f3a06a94a6ee5470c956663164d58eda818a64","modified":1568959987578},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"7fb593f90d74a99c21840679933b9ef6fdc16a61","modified":1568959987579},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"f9760ecf186954cee3ba4a149be334e9ba296b89","modified":1568959987581},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"4e3838d7ac81d9ad133960f0f7ed58a44a015285","modified":1568959987581},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"8cf318644acc8b4978537c263290363e21c7f5af","modified":1568959987583},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"167986d0f649516671ddf7193eebba7b421cd115","modified":1568959987573},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"50450d9fdc8a2b2be8cfca51e3e1a01ffd636c0b","modified":1568959987575},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"7fe4d4d656e86276c17cb4e48a560cb6a4def703","modified":1568959987576},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"39f04c4c7237a4e10acd3002331992b79945d241","modified":1568959987605},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"57d982e3003a35c538991d3a2d83ee3ee15bcd33","modified":1569753725995},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"8dd9a1c6f4f6baa00c2cf01837e7617120cf9660","modified":1568959987607},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"11c22f0fb3f6beb13e5a425ec064a4ff974c13b7","modified":1568959987608},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"61f8cea3c01acd600e90e1bc2a07def405503748","modified":1568959987609},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"1153bb71edf253765145559674390e16dd67c633","modified":1568959987611},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"c8fe49a4bc014c24dead05b782a7082411a4abc5","modified":1568959987612},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a1521d48bb06d8d703753f52a198baa197af7da2","modified":1568959987613},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"5ef6343835f484a2c0770bd1eb9cc443609e4c39","modified":1568959987615},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"e71652d3216e289c8548b1ea2357822c1476a425","modified":1568959987617},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"62fbbd32cf5a99ae550c45c763a2c4813a138d01","modified":1568959987585},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"875cbe88d5c7f6248990e2beb97c9828920e7e24","modified":1568959987587},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"caf263d1928496688c0e1419801eafd7e6919ce5","modified":1568959987588},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"a200c0a1c5a895ac9dc41e0641a5dfcd766be99b","modified":1568959987589},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"a6c6eb8adba0a090ad1f4b9124e866887f20d10d","modified":1568959987591},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"cd9e214e502697f2f2db84eb721bac57a49b0fce","modified":1568959987592},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"d0d7a5c90d62b685520d2b47fea8ba6019ff5402","modified":1568959987593},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"27deb3d3a243d30022055dac7dad851024099a8b","modified":1568959987595},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"b2495ae5e04dcca610aacadc47881d9e716cd440","modified":1568959987597},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"ca88ea6999a61fb905eb6e72eba5f92d4ee31e6e","modified":1568959987596},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"ccb34c52be8adba5996c6b94f9e723bd07d34c16","modified":1568959987600},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"5a982d8ef3b3623ea5f59e63728990f5623c1b57","modified":1568959987598},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"01567edaea6978628aa5521a122a85434c418bfd","modified":1568959987601},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"7968343e41f8b94b318c36289dff1196c3eb1791","modified":1568959987602},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"2fe76476432b31993338cb45cdb3b29a518b6379","modified":1568959987619},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"89d6c3b697efc63de42afd2e89194b1be14152af","modified":1568959987603},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"f825da191816eef69ea8efb498a7f756d5ebb498","modified":1568959987622},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"2ad1a2a9bbf6742d1b0762c4c623b68113d1e0fe","modified":1568959987623},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"2ab1322fe52ab5aafd49e68f5bd890e8380ee927","modified":1568959987624},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"a3bdd71237afc112b2aa255f278cab6baeb25351","modified":1568959987621},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"9a409b798decdefdaf7a23f0b11004a8c27e82f3","modified":1568959987627},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"154a87a32d2fead480d5e909c37f6c476671c5e6","modified":1568959987629},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"b80604868e4f5cf20fccafd7ee415c20c804f700","modified":1568959987630},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"5dbeed535d63a50265d96b396a5440f9bb31e4ba","modified":1568959987633},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"bba4f3bdb7517cd85376df3e1209b570c0548c69","modified":1568959987632},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"a6e7d698702c2e383dde3fde2abde27951679084","modified":1568959987634},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"717cc7f82be9cc151e23a7678601ff2fd3a7fa1d","modified":1568959987635},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"874278147115601d2abf15987f5f7a84ada1ac6b","modified":1568959987636},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"15975ba7456b96916b1dbac448a1a0d2c38b8f3d","modified":1568959987639},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"10599e16414a8b7a76c4e79e6617b5fe3d4d1adf","modified":1568959987638},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"16087276945fa038f199692e3eabb1c52b8ea633","modified":1568959987640},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"28825ae15fa20ae3942cdaa7bcc1f3523ce59acc","modified":1568959987642},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"9c8196394a89dfa40b87bf0019e80144365a9c93","modified":1568959987643},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1568959987675},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"a07aa12cc36ac5c819670c2a3c17d07ed7a08986","modified":1568959987674},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1568959987683},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1568959987747},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1568959987745},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1568959987749},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1568959987745},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1568959987750},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"4ac683b2bc8531c84d98f51b86957be0e6f830f3","modified":1568959987756},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1568959987788},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"6394c48092085788a8c0ef72670b0652006231a1","modified":1568959987790},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"ee948b4489aedeb548a77c9e45d8c7c5732fd62d","modified":1568959987791},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"51139a4c79573d372a347ef01a493222a1eaf10a","modified":1568959987792},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1568959987794},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"d22b1629cb23a6181bebb70d0cf653ffe4b835c8","modified":1568959987795},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"b7076e58d647265ee0ad2b461fe8ce72c9373bc5","modified":1568959987626},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1568959987862},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1568959987832},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1568959987840},{"_id":"themes/next/.git/objects/pack/pack-347eba1c40ddd53439d7c846769cee791cbb72dd.idx","hash":"a8e7f9be846104fdc443ba7f3835647c854fbb74","modified":1568959987164},{"_id":"themes/next/source/lib/three/three.min.js","hash":"26273b1cb4914850a89529b48091dc584f2c57b8","modified":1568959987944},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"90a1b22129efc172e2dfcceeeb76bff58bc3192f","modified":1568959987771},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1568959987853},{"_id":"source/_posts/智能计算机/image-20201221171900968.png","hash":"c3e744467ed01516649b937ce22482128ee692e9","modified":1608542341061},{"_id":"themes/next/.git/objects/pack/pack-347eba1c40ddd53439d7c846769cee791cbb72dd.pack","hash":"4ecc8aa607eccda26d6a4ffd1f968a9f13da83cd","modified":1568959987141},{"_id":"public/atom.xml","hash":"004d9735e732ec9d03a12e0bb144d645fe0402d4","modified":1610984456464},{"_id":"public/schedule/index.html","hash":"d290f80889a8b1a22866ced1b8279ce389f2d574","modified":1610983992852},{"_id":"public/categories/index.html","hash":"5728f6a506a6a18d79279d5f3767e5778792d9d3","modified":1610983992853},{"_id":"public/tags/index.html","hash":"2f6b834fb473de01d52eb779b306702e1a9cb1c8","modified":1610983992866},{"_id":"public/archives/page/2/index.html","hash":"7fa78305450b83f72acd1f29644214e163b7e8f7","modified":1610983992866},{"_id":"public/archives/2019/09/index.html","hash":"0a2f0dad31c2dba3aa9c4dead58cfa723cf76315","modified":1610983992866},{"_id":"public/archives/2019/10/index.html","hash":"4fce3373df082551bbbf20714134a1c1c1d222ab","modified":1610983992866},{"_id":"public/archives/2020/01/index.html","hash":"9695965b549a8588f998713f111c2b60f6dc04b9","modified":1610983992866},{"_id":"public/archives/2020/09/index.html","hash":"16da35c2dbce068a12750440498b6a8b7065ed3e","modified":1610983992866},{"_id":"public/archives/2020/12/index.html","hash":"d780ff16f8d8aa0fc3c30e89f0563c81b01a955e","modified":1610983992866},{"_id":"public/tags/算法/index.html","hash":"c34a654d31ecf65bb5662128c427d2b9f85d2220","modified":1610983992866},{"_id":"public/tags/动态规划/index.html","hash":"4507b9f87277bd4d535ecfa66af97fede4164ade","modified":1610983992866},{"_id":"public/tags/背包问题/index.html","hash":"f359821dd4be655e10d20df85f930640bece77e2","modified":1610983992866},{"_id":"public/tags/机器学习/index.html","hash":"83fc36349154ee68ff16b825d316a874ab9e8b16","modified":1610983992866},{"_id":"public/tags/STL/index.html","hash":"4e80ade6b0f7876c9f7b4cf5b04171182461a115","modified":1610983992866},{"_id":"public/tags/数据结构/index.html","hash":"ea46d820ec27ac185bf4efb61880198107bde33a","modified":1610983992866},{"_id":"public/tags/题解/index.html","hash":"0a1943a719d691ce7a862703d76c5a68554cf23d","modified":1610983992866},{"_id":"public/2020/12/21/智能计算机/index.html","hash":"9c50d76c34e2fb5bb5aa5ae36117f9cf28f11e39","modified":1610984456496},{"_id":"public/2020/09/07/数字电路/index.html","hash":"e7b87a68bed3b5e7a47f7b5ff2770962ecc6687d","modified":1610983992867},{"_id":"public/2020/01/30/git操作/index.html","hash":"33c863afaa3482865103d052f5c6e9ffb8a41090","modified":1610983992867},{"_id":"public/2020/01/29/Mobilenetv2_第三版/index.html","hash":"df32f5fe637c88619058b8ef94beaaee2a9df547","modified":1610983992867},{"_id":"public/2020/01/29/Mobilenetv2_第二版/index.html","hash":"245b4aaecd57d3db5576a22e47e7e1b508117d55","modified":1610983992867},{"_id":"public/2020/01/23/torch操作总结/index.html","hash":"56b96b47e310b8edc79651b9bfac419574b85ec6","modified":1610983992867},{"_id":"public/2020/01/20/Mobilenetv2_第一版/index.html","hash":"2871a67a762fd7b0d97b22cb5689ed73521b1e65","modified":1610983992867},{"_id":"public/2019/10/11/第一次上机E题题解/index.html","hash":"f4381447891cacbd6141a2fcf174c1a7d066d9cd","modified":1610983992867},{"_id":"public/2019/09/29/STL容器的总结/index.html","hash":"8d686d428cb0e18dc1657e702d6a29010bc3e1b8","modified":1610983992867},{"_id":"public/2019/09/24/最短路算法/index.html","hash":"c8927c16e6f9f836169f6e3e5e4d85b15ec61bb3","modified":1610983992867},{"_id":"public/2019/09/24/最小生成树/index.html","hash":"895d174d4161fa98c4977f240a4907dcb070115a","modified":1610983992867},{"_id":"public/2019/09/22/状压dp/index.html","hash":"5e87adb5994c316eacdf0852f4c53f66d8fc510b","modified":1610983992867},{"_id":"public/2019/09/20/01背包/index.html","hash":"2b038edb7e7e08c2fcc7d76e6f78f903328a22c5","modified":1610983992867},{"_id":"public/2019/09/20/关于此博客/index.html","hash":"b0dfb339184f3467aeb5ad4b9cc19506688e9db1","modified":1610983992867},{"_id":"public/archives/index.html","hash":"31908d7a8e581a31f5545f0a7a102772103d2362","modified":1610983992868},{"_id":"public/archives/2019/index.html","hash":"8ddd2ab0f49fa52bfde9597f3748958b637d02e9","modified":1610983992868},{"_id":"public/archives/2020/index.html","hash":"dfdce7c9e872161a37726fdd5842503017935769","modified":1610983992868},{"_id":"public/index.html","hash":"72aef2eb124c8d39ef4229fbf3f4456ad4d28043","modified":1610983992867},{"_id":"public/page/2/index.html","hash":"053bcf01768f1ef1b8ee5883625126a2f72445fe","modified":1610983992868},{"_id":"public/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1608550105502},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1608550105502},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1608550105503},{"_id":"public/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1608550105503},{"_id":"public/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1608550105503},{"_id":"public/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1608550105503},{"_id":"public/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1608550105503},{"_id":"public/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1608550105504},{"_id":"public/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1608550105504},{"_id":"public/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1608550105504},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1608550105504},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1608550105505},{"_id":"public/images/header.jpg","hash":"2468631d3d39c618d9f979dd0d88d9b0e10b36a9","modified":1608550105505},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1608550105505},{"_id":"public/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1608550105505},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1608550105506},{"_id":"public/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1608550105506},{"_id":"public/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1608550105506},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1608550105506},{"_id":"public/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1608550105506},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1608550105506},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1608550105507},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1608550105507},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1608550105507},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1608550105507},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1608550105507},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1608550105507},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1608550105507},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1608550105508},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1608550105508},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1608550105508},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1608550105508},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1608550105508},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1608550105508},{"_id":"public/2020/12/21/智能计算机/image-20201221161604172.png","hash":"3d7e8b4429182ac3e12a471b8ab731d8531dfb3b","modified":1608550105508},{"_id":"public/2020/12/21/智能计算机/image-20201221170316556.png","hash":"f622dd4ad6ad8acf8b219063d79a0c762c3fd2ac","modified":1608550105509},{"_id":"public/2020/12/21/智能计算机/image-20201221171419046.png","hash":"4ac09f41e7c46d7064af4422f81fc56faf3d3b33","modified":1608550105509},{"_id":"public/2020/12/21/智能计算机/image-20201221173107160.png","hash":"860c97a1c0d1f361862cab7ba5421040dbdb0430","modified":1608550105509},{"_id":"public/2020/12/21/智能计算机/image-20201221173555856.png","hash":"02d70bf7fdd7e64349a4f88d6e6638fe87f8b651","modified":1608550105509},{"_id":"public/2020/12/21/智能计算机/image-20201221173834863.png","hash":"36e36c60423dd7c8c6971e44850cc98ae614dbc5","modified":1608550105510},{"_id":"public/2020/09/07/数字电路/image-20201207100058038.png","hash":"309141b91b97d8acf1e6c3a3c0d881310a5f046f","modified":1608550105511},{"_id":"public/2020/09/07/数字电路/image-20201207100101916.png","hash":"b01d1a1f722c3ec4d7e5e25b6c5495da7407d812","modified":1608550105512},{"_id":"public/2020/09/07/数字电路/image-20201207100105985.png","hash":"988ce7cbdab3874b9f568a13b5911fb417ea23b6","modified":1608550105512},{"_id":"public/2020/09/07/数字电路/image-20201207100108953.png","hash":"26a6987d7ff9bee9fdc558b34fee034a5c420b15","modified":1608550105512},{"_id":"public/2020/09/07/数字电路/image-20201207100339923.png","hash":"9fa09bb1200c9947b5fa947f5d839e09290ae575","modified":1608550105513},{"_id":"public/2020/09/07/数字电路/image-20201207100458411.png","hash":"f172933cf56640284b42dd89783fd470dbfd641f","modified":1608550105514},{"_id":"public/2020/09/07/数字电路/image-20201207143351015.png","hash":"bfa4b3d0239e1e6c75c2b5249952e02ca1c49ea4","modified":1608550105514},{"_id":"public/2020/09/07/数字电路/image-20201207143605620.png","hash":"a4d9ab9b0e2b980acde81d16c86181e9be145ef8","modified":1608550105514},{"_id":"public/2020/09/07/数字电路/image-20201207150409345.png","hash":"79b6173bf2610e2f5f99659492708d9b7583ee45","modified":1608550105515},{"_id":"public/2020/09/07/数字电路/image-20201207155711758.png","hash":"0f9057039512521878b2142d59aada39ef134836","modified":1608550105516},{"_id":"public/2020/09/07/数字电路/image-20201207160054355.png","hash":"f394fe0a53c83ae313e818a74cb9347516afdbcb","modified":1608550105516},{"_id":"public/2020/09/07/数字电路/image-20201207163239045.png","hash":"62ca87c0295e484515ea1043591866470fcb2201","modified":1608550105516},{"_id":"public/2020/09/07/数字电路/image-20201207164852673.png","hash":"030827c689b79167b003c696457421b206e178ad","modified":1608550105516},{"_id":"public/2020/09/07/数字电路/image-20201207202738889.png","hash":"2641f29c6ca2690436df1f12eda3cc2d79531e02","modified":1608550105517},{"_id":"public/2020/09/07/数字电路/image-20201207211753609.png","hash":"3c1684fb8626a1636cae93f6c79bac2bfe7e856e","modified":1608550105517},{"_id":"public/2020/09/07/数字电路/image-20201207231703395.png","hash":"1fb633d36196eb7f628ee5b468d07cdd021c396e","modified":1608550105517},{"_id":"public/2020/09/07/数字电路/image-20201207234319334.png","hash":"78c2ecdb63756cf03fc4ce471d892e694bb71b5e","modified":1608550105517},{"_id":"public/2020/09/07/数字电路/image-20201208093951521.png","hash":"2f556c824c8cfeba257f1cc96037a831b71d6b9e","modified":1608550105517},{"_id":"public/2020/09/07/数字电路/image-20201208095118685.png","hash":"2676c648d423fa3c8c7b8dc744adb21a8d42a4c5","modified":1608550105518},{"_id":"public/2020/09/07/数字电路/image-20201208100213115.png","hash":"840cc9f26ab91e6744d5bc45d09c550b85c2ae75","modified":1608550105518},{"_id":"public/2020/09/07/数字电路/image-20201208103050351.png","hash":"ffaaa807ee0ac73c41420ee21a030927556bb6d2","modified":1608550105518},{"_id":"public/2020/09/07/数字电路/image-20201208100311393.png","hash":"52805e700d42195b6ba8c45d7986a21420a7b3c5","modified":1608550105519},{"_id":"public/2020/09/07/数字电路/image-20201208102916928.png","hash":"76748cd010cbfe48a36ab8454179c62e2817c3ba","modified":1608550105519},{"_id":"public/2020/09/07/数字电路/image-20201208100710777.png","hash":"35656b209d31e2bfd2da2f2828ba1f91e5d7db24","modified":1608550105520},{"_id":"public/2020/09/07/数字电路/image-20201208103304650.png","hash":"d7c8320df6f5bf6462ce57ea0653663ecfa3c1eb","modified":1608550105520},{"_id":"public/2020/09/07/数字电路/image-20201208120335673.png","hash":"5a6abbb6fef06b21b33ff635a215a8a1a73c71a6","modified":1608550105520},{"_id":"public/2020/09/07/数字电路/image-20201208133000921.png","hash":"6ea3e46e0c7832973f765592957102da72dfc521","modified":1608550105520},{"_id":"public/2020/09/07/数字电路/image-20201208133500161.png","hash":"cbe400ff81b2264d957cc392b9c2bc5dfc0432b3","modified":1608550105521},{"_id":"public/2020/09/07/数字电路/image-20201208162623051.png","hash":"a7c31e981c0f40fbc27277abaa000041106a3d00","modified":1608550105521},{"_id":"public/2020/09/07/数字电路/image-20201208163034352.png","hash":"126736da4b5b4457ee36aff7616aecfe75d7b786","modified":1608550105522},{"_id":"public/2020/09/07/数字电路/image-20201208192312875.png","hash":"70c9a72818418f2822e3441a1b5215fe15b48d77","modified":1608550105522},{"_id":"public/2020/09/07/数字电路/image-20201208192326383.png","hash":"7ee71f9606484c6c3093ca91497cf758870d5a44","modified":1608550105522},{"_id":"public/2020/09/07/数字电路/image-20201208211825145.png","hash":"d18429f88dc87c69ffc1a6ed99cf370189edcd09","modified":1608550105522},{"_id":"public/2020/09/07/数字电路/image-20201208212439760.png","hash":"af31ef32eea5b4210e6a1d15300fb84c05e0519a","modified":1608550105522},{"_id":"public/2020/09/07/数字电路/image-20201208214549378.png","hash":"346c8ef92418e497018b151af59aa12a96895867","modified":1608550105522},{"_id":"public/2020/09/07/数字电路/image-20201208215405366.png","hash":"323315ed9a1e2fff4b55785a599b6e16c662906e","modified":1608550105523},{"_id":"public/2020/09/07/数字电路/image-20201208215859239.png","hash":"977b9fb79d6a57439327a84590d5e90c536cc390","modified":1608550105523},{"_id":"public/2020/09/07/数字电路/image-20201209091933646.png","hash":"35039a66fc325195ec82862fa4397d49b498f4ab","modified":1608550105523},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1608550111040},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1608550111055},{"_id":"public/2020/09/07/数字电路/image-20201207095115200.png","hash":"ff3c0b6316ab16a9343d9e21188e861707e99f12","modified":1608550111056},{"_id":"public/2020/09/07/数字电路/image-20201207095702879.png","hash":"42f473b2603984168c903595acfc34a030aa9ede","modified":1608550111056},{"_id":"public/2020/09/07/数字电路/image-20201207100257128.png","hash":"e2aa11fb165062682803214965be327bb9c64a2c","modified":1608550111057},{"_id":"public/2020/09/07/数字电路/image-20201207141230974.png","hash":"0be0d7d089387fcfcd996f2c024493f7128aeac1","modified":1608550111057},{"_id":"public/2020/09/07/数字电路/image-20201207141227512.png","hash":"1ce71b33fdc4105dc3861d150f309aaa532cda12","modified":1608550111057},{"_id":"public/2020/09/07/数字电路/image-20201207155851664.png","hash":"8d1e66b9417c2c5aedd3c7e19d81953be49a326a","modified":1608550111057},{"_id":"public/2020/09/07/数字电路/image-20201207180624804.png","hash":"cea4460a84ce5843e40be1d58b892f817d033071","modified":1608550111057},{"_id":"public/2020/09/07/数字电路/image-20201207202208723.png","hash":"20a6a049b80550dbb015e4c7cc0aae84ddaca94f","modified":1608550111058},{"_id":"public/2020/09/07/数字电路/image-20201207202442317.png","hash":"ea44990663f58f2b055e8f8acdde76b5939035b5","modified":1608550111058},{"_id":"public/2020/09/07/数字电路/image-20201207204428555.png","hash":"0e78da4fc8327fa8b94fb8e53c3016c10c0b220d","modified":1608550111058},{"_id":"public/2020/09/07/数字电路/image-20201207210045223.png","hash":"9895665aae38d3d5c5f03d8f1cc5d9b7f9fd8fdc","modified":1608550111059},{"_id":"public/2020/09/07/数字电路/image-20201207225752379.png","hash":"eff574aa511fad9000c7dc781e7eb7b81ee31ee1","modified":1608550111059},{"_id":"public/2020/09/07/数字电路/image-20201207231253193.png","hash":"82f22e74f937370ee8525cad3718fd761f52a05b","modified":1608550111059},{"_id":"public/2020/09/07/数字电路/image-20201207231257765.png","hash":"82f22e74f937370ee8525cad3718fd761f52a05b","modified":1608550111059},{"_id":"public/2020/09/07/数字电路/image-20201208100252440.png","hash":"38a17863244e78291d7098d602015302fae783c9","modified":1608550111060},{"_id":"public/2020/09/07/数字电路/image-20201208120149198.png","hash":"23d150c39c05c13400825e7e4f0d1297628e9219","modified":1608550111060},{"_id":"public/2020/09/07/数字电路/image-20201208162700995.png","hash":"479143b43e62e67bc77f56445ec92c0b193faa98","modified":1608550111060},{"_id":"public/2020/09/07/数字电路/image-20201208163053439.png","hash":"76436bc5351d92fad4358f47657e8d721fca0389","modified":1608550111061},{"_id":"public/2020/09/07/数字电路/image-20201208163510773.png","hash":"077183511e2a9d45bfe76c14163daade925107c7","modified":1608550111061},{"_id":"public/2020/09/07/数字电路/image-20201208214956731.png","hash":"bc153a596374e35b5ea1485c1b5575c8b8b52057","modified":1608550111061},{"_id":"public/2020/09/07/数字电路/image-20201208215602590.png","hash":"474c405471a1bacb438b8841c7de6e1cc960805b","modified":1608550111061},{"_id":"public/2020/09/07/数字电路/image-20201208215639819.png","hash":"6fa78fc1f53536e6b53dce4ddbd534e99d420155","modified":1608550111062},{"_id":"public/2020/09/07/数字电路/image-20201208215654220.png","hash":"80daaec9fb801494c0c237eb8b62ce2f1d75ec7f","modified":1608550111063},{"_id":"public/2020/09/07/数字电路/image-20201209092949508.png","hash":"fa23d0e39e9b18cbead8250769c0ed59aa9cf756","modified":1608550111064},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1608550111104},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1608550111104},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1608550111106},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1608550111107},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1608550111107},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1608550111107},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1608550111107},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1608550111107},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1608550111107},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1608550111107},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1608550111107},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1608550111108},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1608550111108},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1608550111108},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1608550111108},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1608550111108},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1608550111108},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1608550111109},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1608550111109},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1608550111109},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1608550111110},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1608550111110},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1608550111112},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1608550111113},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1608550111113},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1608550111113},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1608550111114},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1608550111114},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1608550111114},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1608550111114},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1608550111114},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1608550111114},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1608550111115},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1608550111115},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1608550111115},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1608550111115},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1608550111116},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1608550111116},{"_id":"public/lib/fastclick/README.html","hash":"d6e90449a2c09f3033f7e43d68b0cc8208e22e09","modified":1608550111117},{"_id":"public/lib/jquery_lazyload/README.html","hash":"a08fccd381c8fdb70ba8974b208254c5ba23a95f","modified":1608550111117},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"06811ca2f722dead021493457f27cdc264ef928d","modified":1608550111117},{"_id":"public/css/main.css","hash":"6592703f6f739c14a3f6e5e29ee2445a77cbd9fc","modified":1608550111118},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1608550111118},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1608550111119},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1608550111119},{"_id":"public/2020/09/07/数字电路/image-20201207103734768.png","hash":"3cb727584bcfcd006a68887a678572cc7ddf4712","modified":1608550111120},{"_id":"public/2020/09/07/数字电路/image-20201207164837016.png","hash":"f05e1552e2e8773274e801045a999bb1fb92508c","modified":1608550111121},{"_id":"public/2020/09/07/数字电路/image-20201208212442919.png","hash":"603b3fdb52f24d485721ce91620aef13c8141574","modified":1608550111122},{"_id":"public/2020/12/21/智能计算机/image-20201221173352870.png","hash":"8de819712861a65c7f7112d68058d5f10c332b38","modified":1608550111122},{"_id":"public/2020/09/07/数字电路/image-20201207204622034.png","hash":"6023a324f40790f5f210d6bf428e35af63736896","modified":1608550111122},{"_id":"public/2020/09/07/数字电路/image-20201207230758027.png","hash":"0998b74e4bba7fd4119b66057c9fe6897d86ef07","modified":1608550111123},{"_id":"public/2020/09/07/数字电路/image-20201207155940917.png","hash":"c693224c47a4457ccfd6254a7648c075e0dff254","modified":1608550111124},{"_id":"public/2020/09/07/数字电路/image-20201207202617679.png","hash":"28753a12f6a2ef1fe742cd86a6924028d6ffd619","modified":1608550111124},{"_id":"public/2020/09/07/数字电路/image-20201207204956445.png","hash":"6767c45d14f30e7c11e85fe176713e67bdd55826","modified":1608550111125},{"_id":"public/2020/09/07/数字电路/image-20201207234431264.png","hash":"19cf9761663b441307581144fdae9a12daca927c","modified":1608550111125},{"_id":"public/2020/09/07/数字电路/image-20201208094730885.png","hash":"d7e74c14877ecf40d64f93bacf93275591fce318","modified":1608550111126},{"_id":"public/2020/09/07/数字电路/image-20201208103414917.png","hash":"48b837cdc4d91620e1ec82fe67c79321a2190146","modified":1608550111126},{"_id":"public/2020/09/07/数字电路/image-20201208103416148.png","hash":"48b837cdc4d91620e1ec82fe67c79321a2190146","modified":1608550111127},{"_id":"public/2020/09/07/数字电路/image-20201208211819333.png","hash":"af1ee8586ee0928f04d4406ffa3da2b3667c9048","modified":1608550111127},{"_id":"public/2020/09/07/数字电路/image-20201208214717350.png","hash":"60da6abd96582c7a863e756df9d3a1a0d0e93d21","modified":1608550111128},{"_id":"public/2020/09/07/数字电路/image-20201208215327269.png","hash":"480f55205244a1b599b98569ac20bb1ef15f6181","modified":1608550111128},{"_id":"public/2020/09/07/数字电路/image-20201208215446146.png","hash":"a9dc65aa42104631c2060a647c265453844283a7","modified":1608550111129},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1608550111157},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1608550111157},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1608550111158},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1608550111158},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1608550111158},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1608550111158},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1608550111158},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1608550111158},{"_id":"public/2020/09/07/数字电路/image-20201207151538922.png","hash":"1e1a74a129514793505945b05842c09f2c33468f","modified":1608550111159},{"_id":"public/2020/09/07/数字电路/image-20201207205834377.png","hash":"ad0f91b6751cd392a7673ce8337d96a274bb6404","modified":1608550111159},{"_id":"public/2020/09/07/数字电路/image-20201207163011726.png","hash":"9a93370cba7679c9e67742d466e30cd8a09210aa","modified":1608550111159},{"_id":"public/2020/09/07/数字电路/image-20201207205904689.png","hash":"ad0f91b6751cd392a7673ce8337d96a274bb6404","modified":1608550111160},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1608550111166},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1608550111167},{"_id":"public/2020/09/07/数字电路/image-20201207180435959.png","hash":"7ad185157544531002c784059e31a217d3b9a488","modified":1608550111168},{"_id":"public/2020/09/07/数字电路/image-20201207163100622.png","hash":"a6718ed741234dac1e256bfb3e2c7f24bd26229e","modified":1608550111168},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1608550111171},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1608550111171},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1608550111786},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1608550111786},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1608550111788},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1608550111788},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1608550111788},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1608550111788},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1608550111788},{"_id":"public/2020/09/07/数字电路/image-20201207141338902.png","hash":"b90ee0ca2378015ed8dfcea9bece2738e0259b7b","modified":1608550111789},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1608550111789},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1608550111789},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1608550112060},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1608550112060},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1608550112465},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1608550112466},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1608550112881},{"_id":"public/2020/12/21/智能计算机/image-20201221171900968.png","hash":"c3e744467ed01516649b937ce22482128ee692e9","modified":1608550112901},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1608550112905},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1608550112920},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1608550112933},{"_id":"source/_posts/智能计算机/image-20201222004933612.png","hash":"c9cfc9cd4053937603a341bcefbba55d20e97c31","modified":1608569373804},{"_id":"source/_posts/智能计算机/image-20201222004952263.png","hash":"df59b8e8feaf67fc0eab891a5439bd09b1018abb","modified":1608569392438},{"_id":"source/_posts/智能计算机/image-20201222004846500.png","hash":"a4e8f9de0a2156b6f643451f0f175e3007f2747d","modified":1608569327001},{"_id":"source/_posts/智能计算机/image-20201222004912384.png","hash":"798b506d3a9da1961392272e904309ca2a1c231c","modified":1608569352481},{"_id":"source/_posts/智能计算机/image-20201222005007770.png","hash":"92c0acf9921db29ded253c36907549bb1c460e63","modified":1608569407911},{"_id":"public/2020/12/21/智能计算机/image-20201222004933612.png","hash":"c9cfc9cd4053937603a341bcefbba55d20e97c31","modified":1608569736968},{"_id":"public/2020/12/21/智能计算机/image-20201222004952263.png","hash":"df59b8e8feaf67fc0eab891a5439bd09b1018abb","modified":1608569736969},{"_id":"public/2020/12/21/智能计算机/image-20201222004846500.png","hash":"a4e8f9de0a2156b6f643451f0f175e3007f2747d","modified":1608569736969},{"_id":"public/2020/12/21/智能计算机/image-20201222005007770.png","hash":"92c0acf9921db29ded253c36907549bb1c460e63","modified":1608569737207},{"_id":"public/2020/12/21/智能计算机/image-20201222004912384.png","hash":"798b506d3a9da1961392272e904309ca2a1c231c","modified":1608569737208},{"_id":"source/_posts/智能计算机/image-20201222014249959.png","hash":"71060358cf8d317009b259b6b43892904550b6c7","modified":1608572570148},{"_id":"public/2020/12/21/智能计算机/image-20201222014249959.png","hash":"71060358cf8d317009b259b6b43892904550b6c7","modified":1608573793427},{"_id":"source/_posts/智能计算机/image-20201222121105346.png","hash":"ba64f85e68b785782d320ae9e90a346edf226133","modified":1608610265408},{"_id":"source/_posts/智能计算机/image-20201222121110969.png","hash":"8c4bfd3e60d52e8160db204d5ba5f068f89ca44f","modified":1608610270982},{"_id":"source/_posts/智能计算机/image-20201222121125219.png","hash":"b182d899aef1f438ecd8e395d06007f36ad1d0ff","modified":1608610285229},{"_id":"source/_posts/智能计算机/image-20201222121129289.png","hash":"86eab63c745c03c3e9559a3890e0f2bc284c7824","modified":1608610289298},{"_id":"public/2020/12/21/智能计算机/image-20201222121110969.png","hash":"8c4bfd3e60d52e8160db204d5ba5f068f89ca44f","modified":1608610725195},{"_id":"public/2020/12/21/智能计算机/image-20201222121125219.png","hash":"b182d899aef1f438ecd8e395d06007f36ad1d0ff","modified":1608610725195},{"_id":"public/2020/12/21/智能计算机/image-20201222121129289.png","hash":"86eab63c745c03c3e9559a3890e0f2bc284c7824","modified":1608610725195},{"_id":"public/2020/12/21/智能计算机/image-20201222121105346.png","hash":"ba64f85e68b785782d320ae9e90a346edf226133","modified":1608610725195},{"_id":"source/_posts/智能计算机/image-20200118.png","hash":"ad2885de9b051028cc2b3536b7b7866ab1799d17","modified":1610983626949},{"_id":"public/2020/12/21/智能计算机/image-20200118.png","hash":"ad2885de9b051028cc2b3536b7b7866ab1799d17","modified":1610983992962}],"Category":[],"Data":[],"Page":[{"title":"schedule","date":"2019-09-26T11:54:01.000Z","type":"schedule","_content":"","source":"schedule/index.md","raw":"---\ntitle: schedule\ndate: 2019-09-26 19:54:01\ntype: \"schedule\"\n---\n","updated":"2019-09-26T12:17:13.469Z","path":"schedule/index.html","comments":1,"layout":"page","_id":"ckiyh700f0001a0uzjifv4p8i","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2019-09-26T11:54:32.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-09-26 19:54:32\ntype: \"categories\"\n---\n","updated":"2019-09-26T12:07:40.304Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ckiyh700l0003a0uzi0oeq1eu","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2019-09-26T11:53:26.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-09-26 19:53:26\ntype: \"tags\"\n---\n","updated":"2019-09-26T12:05:01.032Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ckiyh700w0006a0uzhxtw6kpg","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"背包问题(一) -- 01背包","date":"2019-09-20T14:28:51.000Z","_content":"\n## 题目：Magry的朋友很多 - 零食篇\n\n### 题目描述\n\nMagry有个好朋友Ricardo快要过生日了。Ricardo突然想到可以借生日坑蒙拐骗点东西出来，于是就找了Magry要他买零食当生日礼物。\n\nMagry手上没那么多钱，不过想了想还是上了天猫超市搜了一波，被那么多吃的看的眼花缭乱头晕目眩不知所措，因为Ricardo只有一个要求，那就是东西尽量好吃，而且还不要有Ricardo不喜欢的东西。。。\n\nMagry已经知道的是：卖的零食总共有n种，不过比较坑爹的是一种零食一个用户限购一件；每种商品的价格为x元，好吃程度为w。另外，Magry已经知道在那些零食中有一部分是Ricardo不喜欢的（也许是忌口，总之这个和零食的好吃程度毫无关联，甚至对于一部分好吃程度为0甚至是负数的黑暗料理Ricardo也很有可能喜欢吃）。然后，Magry身上总共只有k元。\n\n现在，Magry想要的是：如何确定购买方案使得在Magry手上的k元不会被透支（即商品总额不大于k元）的情况下买到总的好吃程度最高并且没有Ricardo不喜欢的零食呢？\n<!--more-->\n### 输入\n\n多组测试数据。\n\n每组数据第一行为一个数，为商品种类数n，0≤n≤10000\n接下来n行，每行3个整数x,w,t，每行分别表示一种商品，x代表商品价格，w代表东西的好吃程度，t表示Ricardo喜不喜欢这个东西，1表示喜欢，0表示不喜欢。其中1≤x≤1000，w在int范围内。\n\n还有最后一行，一个数，k，表示Magry手头的钱。0≤k≤100000\n\n### 输出\n\n对于每组数据，输出一行，一个数，表示Magry在手头的k元不被透支的情况下所购商品的最大好吃程度。\n\n### 输入样例\n\n{% codeblock  %}\n2\n3 61 1\n7 101 0\n100\n1\n10 1 0\n2\n{% endcodeblock %}\n\n### 输出样例\n\n{% codeblock  %}\n61\n0\n{% endcodeblock %}\n\n## 思路\n\n### 关于 01 背包\n\n顾名思义，01背包指放入背包的物品每一种只有一个，因此对于每一种物品都只有两个选择，放或者不放，所以我们可以遍历所有的物品，得出状态转移方程：f[m] = max(f[m], f[m-a[i].x]+a[i].w), 其中 f[m] 指花 m 元钱的时候能得到的最大好吃程度 ，a结构数组用来存放每一个物品的价格，好吃程度和喜不喜欢\n\n关键：我们在里面的循环要通过状态转移方程得出所有的f[m]值，而这个循环必须是从最大钱数 k 递减到 a[i].x， 这是为什么呢？\n        因为对于每一个 m ,f[m]都是由钱数少于m的状态所得到的，所以如果有少到多，每一个物品都会出现放多个的情况(这就是完全背包的思路)\n        相信聪明的你一定懂了！！！\n\n### 代码\n\n这里是本蒟蒻的代码~\n{% codeblock lang:JavaScript %}\n/* \n Author: 王振\n Result: AC\tSubmission_id: 1838386\n Created at: Fri Sep 20 2019 22:24:18 GMT+0800 (CST)\n Problem_id: 474\tTime: 2670\tMemory: 4056\n*/\n\n#include <iostream>\n#include <algorithm>\nusing namespace std;\nstruct thing{\n\tlong long x,w,t;\n}a[10005];\nlong long f[100005];\nint main()\n{\n\tint n;\n\twhile(cin>>n)\n\t{\n\t\tfor(int i=1;i<=n;i++)\n\t\t{\n\t\t\tcin>>a[i].x>>a[i].w>>a[i].t;\n\t\t\tif(a[i].t==0||a[i].w<=0)\n\t\t\t{\n\t\t\t\ti--;\n\t\t\t\tn--;\n\t\t\t}\n\t\t}\n\t\tint k;\n\t\tcin>>k;\n\t\tfor(int i=0;i<=k;i++)\n\t\t{\n\t\t\tf[i]=0;\n\t\t}\n\t\tfor(int i=1;i<=n;i++)\n\t\t{\n\t\t\tfor(int m=k;m>=a[i].x;m--)\n\t\t\t{\n\t\t\t\tf[m]=max(f[m],f[m-a[i].x]+a[i].w);\n\t\t\t}\n\t\t}\n\t\tcout<<f[k]<<endl;\n\t}\n    return 0;\n}\n{% endcodeblock %}\n\n感谢观看~","source":"_posts/01背包.md","raw":"---\ntitle: 背包问题(一) -- 01背包\ndate: 2019-09-20 22:28:51\ntags: [算法,动态规划,背包问题]\n---\n\n## 题目：Magry的朋友很多 - 零食篇\n\n### 题目描述\n\nMagry有个好朋友Ricardo快要过生日了。Ricardo突然想到可以借生日坑蒙拐骗点东西出来，于是就找了Magry要他买零食当生日礼物。\n\nMagry手上没那么多钱，不过想了想还是上了天猫超市搜了一波，被那么多吃的看的眼花缭乱头晕目眩不知所措，因为Ricardo只有一个要求，那就是东西尽量好吃，而且还不要有Ricardo不喜欢的东西。。。\n\nMagry已经知道的是：卖的零食总共有n种，不过比较坑爹的是一种零食一个用户限购一件；每种商品的价格为x元，好吃程度为w。另外，Magry已经知道在那些零食中有一部分是Ricardo不喜欢的（也许是忌口，总之这个和零食的好吃程度毫无关联，甚至对于一部分好吃程度为0甚至是负数的黑暗料理Ricardo也很有可能喜欢吃）。然后，Magry身上总共只有k元。\n\n现在，Magry想要的是：如何确定购买方案使得在Magry手上的k元不会被透支（即商品总额不大于k元）的情况下买到总的好吃程度最高并且没有Ricardo不喜欢的零食呢？\n<!--more-->\n### 输入\n\n多组测试数据。\n\n每组数据第一行为一个数，为商品种类数n，0≤n≤10000\n接下来n行，每行3个整数x,w,t，每行分别表示一种商品，x代表商品价格，w代表东西的好吃程度，t表示Ricardo喜不喜欢这个东西，1表示喜欢，0表示不喜欢。其中1≤x≤1000，w在int范围内。\n\n还有最后一行，一个数，k，表示Magry手头的钱。0≤k≤100000\n\n### 输出\n\n对于每组数据，输出一行，一个数，表示Magry在手头的k元不被透支的情况下所购商品的最大好吃程度。\n\n### 输入样例\n\n{% codeblock  %}\n2\n3 61 1\n7 101 0\n100\n1\n10 1 0\n2\n{% endcodeblock %}\n\n### 输出样例\n\n{% codeblock  %}\n61\n0\n{% endcodeblock %}\n\n## 思路\n\n### 关于 01 背包\n\n顾名思义，01背包指放入背包的物品每一种只有一个，因此对于每一种物品都只有两个选择，放或者不放，所以我们可以遍历所有的物品，得出状态转移方程：f[m] = max(f[m], f[m-a[i].x]+a[i].w), 其中 f[m] 指花 m 元钱的时候能得到的最大好吃程度 ，a结构数组用来存放每一个物品的价格，好吃程度和喜不喜欢\n\n关键：我们在里面的循环要通过状态转移方程得出所有的f[m]值，而这个循环必须是从最大钱数 k 递减到 a[i].x， 这是为什么呢？\n        因为对于每一个 m ,f[m]都是由钱数少于m的状态所得到的，所以如果有少到多，每一个物品都会出现放多个的情况(这就是完全背包的思路)\n        相信聪明的你一定懂了！！！\n\n### 代码\n\n这里是本蒟蒻的代码~\n{% codeblock lang:JavaScript %}\n/* \n Author: 王振\n Result: AC\tSubmission_id: 1838386\n Created at: Fri Sep 20 2019 22:24:18 GMT+0800 (CST)\n Problem_id: 474\tTime: 2670\tMemory: 4056\n*/\n\n#include <iostream>\n#include <algorithm>\nusing namespace std;\nstruct thing{\n\tlong long x,w,t;\n}a[10005];\nlong long f[100005];\nint main()\n{\n\tint n;\n\twhile(cin>>n)\n\t{\n\t\tfor(int i=1;i<=n;i++)\n\t\t{\n\t\t\tcin>>a[i].x>>a[i].w>>a[i].t;\n\t\t\tif(a[i].t==0||a[i].w<=0)\n\t\t\t{\n\t\t\t\ti--;\n\t\t\t\tn--;\n\t\t\t}\n\t\t}\n\t\tint k;\n\t\tcin>>k;\n\t\tfor(int i=0;i<=k;i++)\n\t\t{\n\t\t\tf[i]=0;\n\t\t}\n\t\tfor(int i=1;i<=n;i++)\n\t\t{\n\t\t\tfor(int m=k;m>=a[i].x;m--)\n\t\t\t{\n\t\t\t\tf[m]=max(f[m],f[m-a[i].x]+a[i].w);\n\t\t\t}\n\t\t}\n\t\tcout<<f[k]<<endl;\n\t}\n    return 0;\n}\n{% endcodeblock %}\n\n感谢观看~","slug":"01背包","published":1,"updated":"2019-09-29T10:04:52.493Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh70040000a0uzfafqh67h","content":"<h2 id=\"题目：Magry的朋友很多-零食篇\"><a href=\"#题目：Magry的朋友很多-零食篇\" class=\"headerlink\" title=\"题目：Magry的朋友很多 - 零食篇\"></a>题目：Magry的朋友很多 - 零食篇</h2><h3 id=\"题目描述\"><a href=\"#题目描述\" class=\"headerlink\" title=\"题目描述\"></a>题目描述</h3><p>Magry有个好朋友Ricardo快要过生日了。Ricardo突然想到可以借生日坑蒙拐骗点东西出来，于是就找了Magry要他买零食当生日礼物。</p>\n<p>Magry手上没那么多钱，不过想了想还是上了天猫超市搜了一波，被那么多吃的看的眼花缭乱头晕目眩不知所措，因为Ricardo只有一个要求，那就是东西尽量好吃，而且还不要有Ricardo不喜欢的东西。。。</p>\n<p>Magry已经知道的是：卖的零食总共有n种，不过比较坑爹的是一种零食一个用户限购一件；每种商品的价格为x元，好吃程度为w。另外，Magry已经知道在那些零食中有一部分是Ricardo不喜欢的（也许是忌口，总之这个和零食的好吃程度毫无关联，甚至对于一部分好吃程度为0甚至是负数的黑暗料理Ricardo也很有可能喜欢吃）。然后，Magry身上总共只有k元。</p>\n<p>现在，Magry想要的是：如何确定购买方案使得在Magry手上的k元不会被透支（即商品总额不大于k元）的情况下买到总的好吃程度最高并且没有Ricardo不喜欢的零食呢？<br><a id=\"more\"></a></p>\n<h3 id=\"输入\"><a href=\"#输入\" class=\"headerlink\" title=\"输入\"></a>输入</h3><p>多组测试数据。</p>\n<p>每组数据第一行为一个数，为商品种类数n，0≤n≤10000<br>接下来n行，每行3个整数x,w,t，每行分别表示一种商品，x代表商品价格，w代表东西的好吃程度，t表示Ricardo喜不喜欢这个东西，1表示喜欢，0表示不喜欢。其中1≤x≤1000，w在int范围内。</p>\n<p>还有最后一行，一个数，k，表示Magry手头的钱。0≤k≤100000</p>\n<h3 id=\"输出\"><a href=\"#输出\" class=\"headerlink\" title=\"输出\"></a>输出</h3><p>对于每组数据，输出一行，一个数，表示Magry在手头的k元不被透支的情况下所购商品的最大好吃程度。</p>\n<h3 id=\"输入样例\"><a href=\"#输入样例\" class=\"headerlink\" title=\"输入样例\"></a>输入样例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2</span><br><span class=\"line\">3 61 1</span><br><span class=\"line\">7 101 0</span><br><span class=\"line\">100</span><br><span class=\"line\">1</span><br><span class=\"line\">10 1 0</span><br><span class=\"line\">2</span><br></pre></td></tr></table></figure>\n<h3 id=\"输出样例\"><a href=\"#输出样例\" class=\"headerlink\" title=\"输出样例\"></a>输出样例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">61</span><br><span class=\"line\">0</span><br></pre></td></tr></table></figure>\n<h2 id=\"思路\"><a href=\"#思路\" class=\"headerlink\" title=\"思路\"></a>思路</h2><h3 id=\"关于-01-背包\"><a href=\"#关于-01-背包\" class=\"headerlink\" title=\"关于 01 背包\"></a>关于 01 背包</h3><p>顾名思义，01背包指放入背包的物品每一种只有一个，因此对于每一种物品都只有两个选择，放或者不放，所以我们可以遍历所有的物品，得出状态转移方程：f[m] = max(f[m], f[m-a[i].x]+a[i].w), 其中 f[m] 指花 m 元钱的时候能得到的最大好吃程度 ，a结构数组用来存放每一个物品的价格，好吃程度和喜不喜欢</p>\n<p>关键：我们在里面的循环要通过状态转移方程得出所有的f[m]值，而这个循环必须是从最大钱数 k 递减到 a[i].x， 这是为什么呢？<br>        因为对于每一个 m ,f[m]都是由钱数少于m的状态所得到的，所以如果有少到多，每一个物品都会出现放多个的情况(这就是完全背包的思路)<br>        相信聪明的你一定懂了！！！</p>\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><p>这里是本蒟蒻的代码~<br><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* </span></span><br><span class=\"line\"><span class=\"comment\"> Author: 王振</span></span><br><span class=\"line\"><span class=\"comment\"> Result: AC\tSubmission_id: 1838386</span></span><br><span class=\"line\"><span class=\"comment\"> Created at: Fri Sep 20 2019 22:24:18 GMT+0800 (CST)</span></span><br><span class=\"line\"><span class=\"comment\"> Problem_id: 474\tTime: 2670\tMemory: 4056</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\">#include &lt;algorithm&gt;</span><br><span class=\"line\">using namespace std;</span><br><span class=\"line\">struct thing&#123;</span><br><span class=\"line\">\tlong long x,w,t;</span><br><span class=\"line\">&#125;a[<span class=\"number\">10005</span>];</span><br><span class=\"line\">long long f[<span class=\"number\">100005</span>];</span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\tint n;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span>(cin&gt;&gt;n)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=n;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tcin&gt;&gt;a[i].x&gt;&gt;a[i].w&gt;&gt;a[i].t;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span>(a[i].t==<span class=\"number\">0</span>||a[i].w&lt;=<span class=\"number\">0</span>)</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\ti--;</span><br><span class=\"line\">\t\t\t\tn--;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tint k;</span><br><span class=\"line\">\t\tcin&gt;&gt;k;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;=k;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tf[i]=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=n;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">for</span>(int m=k;m&gt;=a[i].x;m--)</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\tf[m]=max(f[m],f[m-a[i].x]+a[i].w);</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tcout&lt;&lt;f[k]&lt;&lt;endl;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>感谢观看~</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"题目：Magry的朋友很多-零食篇\"><a href=\"#题目：Magry的朋友很多-零食篇\" class=\"headerlink\" title=\"题目：Magry的朋友很多 - 零食篇\"></a>题目：Magry的朋友很多 - 零食篇</h2><h3 id=\"题目描述\"><a href=\"#题目描述\" class=\"headerlink\" title=\"题目描述\"></a>题目描述</h3><p>Magry有个好朋友Ricardo快要过生日了。Ricardo突然想到可以借生日坑蒙拐骗点东西出来，于是就找了Magry要他买零食当生日礼物。</p>\n<p>Magry手上没那么多钱，不过想了想还是上了天猫超市搜了一波，被那么多吃的看的眼花缭乱头晕目眩不知所措，因为Ricardo只有一个要求，那就是东西尽量好吃，而且还不要有Ricardo不喜欢的东西。。。</p>\n<p>Magry已经知道的是：卖的零食总共有n种，不过比较坑爹的是一种零食一个用户限购一件；每种商品的价格为x元，好吃程度为w。另外，Magry已经知道在那些零食中有一部分是Ricardo不喜欢的（也许是忌口，总之这个和零食的好吃程度毫无关联，甚至对于一部分好吃程度为0甚至是负数的黑暗料理Ricardo也很有可能喜欢吃）。然后，Magry身上总共只有k元。</p>\n<p>现在，Magry想要的是：如何确定购买方案使得在Magry手上的k元不会被透支（即商品总额不大于k元）的情况下买到总的好吃程度最高并且没有Ricardo不喜欢的零食呢？<br></p>","more":"<p></p>\n<h3 id=\"输入\"><a href=\"#输入\" class=\"headerlink\" title=\"输入\"></a>输入</h3><p>多组测试数据。</p>\n<p>每组数据第一行为一个数，为商品种类数n，0≤n≤10000<br>接下来n行，每行3个整数x,w,t，每行分别表示一种商品，x代表商品价格，w代表东西的好吃程度，t表示Ricardo喜不喜欢这个东西，1表示喜欢，0表示不喜欢。其中1≤x≤1000，w在int范围内。</p>\n<p>还有最后一行，一个数，k，表示Magry手头的钱。0≤k≤100000</p>\n<h3 id=\"输出\"><a href=\"#输出\" class=\"headerlink\" title=\"输出\"></a>输出</h3><p>对于每组数据，输出一行，一个数，表示Magry在手头的k元不被透支的情况下所购商品的最大好吃程度。</p>\n<h3 id=\"输入样例\"><a href=\"#输入样例\" class=\"headerlink\" title=\"输入样例\"></a>输入样例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2</span><br><span class=\"line\">3 61 1</span><br><span class=\"line\">7 101 0</span><br><span class=\"line\">100</span><br><span class=\"line\">1</span><br><span class=\"line\">10 1 0</span><br><span class=\"line\">2</span><br></pre></td></tr></table></figure>\n<h3 id=\"输出样例\"><a href=\"#输出样例\" class=\"headerlink\" title=\"输出样例\"></a>输出样例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">61</span><br><span class=\"line\">0</span><br></pre></td></tr></table></figure>\n<h2 id=\"思路\"><a href=\"#思路\" class=\"headerlink\" title=\"思路\"></a>思路</h2><h3 id=\"关于-01-背包\"><a href=\"#关于-01-背包\" class=\"headerlink\" title=\"关于 01 背包\"></a>关于 01 背包</h3><p>顾名思义，01背包指放入背包的物品每一种只有一个，因此对于每一种物品都只有两个选择，放或者不放，所以我们可以遍历所有的物品，得出状态转移方程：f[m] = max(f[m], f[m-a[i].x]+a[i].w), 其中 f[m] 指花 m 元钱的时候能得到的最大好吃程度 ，a结构数组用来存放每一个物品的价格，好吃程度和喜不喜欢</p>\n<p>关键：我们在里面的循环要通过状态转移方程得出所有的f[m]值，而这个循环必须是从最大钱数 k 递减到 a[i].x， 这是为什么呢？<br>        因为对于每一个 m ,f[m]都是由钱数少于m的状态所得到的，所以如果有少到多，每一个物品都会出现放多个的情况(这就是完全背包的思路)<br>        相信聪明的你一定懂了！！！</p>\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><p>这里是本蒟蒻的代码~<br><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* </span></span><br><span class=\"line\"><span class=\"comment\"> Author: 王振</span></span><br><span class=\"line\"><span class=\"comment\"> Result: AC\tSubmission_id: 1838386</span></span><br><span class=\"line\"><span class=\"comment\"> Created at: Fri Sep 20 2019 22:24:18 GMT+0800 (CST)</span></span><br><span class=\"line\"><span class=\"comment\"> Problem_id: 474\tTime: 2670\tMemory: 4056</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\">#include &lt;algorithm&gt;</span><br><span class=\"line\">using namespace std;</span><br><span class=\"line\">struct thing&#123;</span><br><span class=\"line\">\tlong long x,w,t;</span><br><span class=\"line\">&#125;a[<span class=\"number\">10005</span>];</span><br><span class=\"line\">long long f[<span class=\"number\">100005</span>];</span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\tint n;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span>(cin&gt;&gt;n)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=n;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tcin&gt;&gt;a[i].x&gt;&gt;a[i].w&gt;&gt;a[i].t;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span>(a[i].t==<span class=\"number\">0</span>||a[i].w&lt;=<span class=\"number\">0</span>)</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\ti--;</span><br><span class=\"line\">\t\t\t\tn--;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tint k;</span><br><span class=\"line\">\t\tcin&gt;&gt;k;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;=k;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tf[i]=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=n;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">for</span>(int m=k;m&gt;=a[i].x;m--)</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\tf[m]=max(f[m],f[m-a[i].x]+a[i].w);</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tcout&lt;&lt;f[k]&lt;&lt;endl;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>感谢观看~</p>"},{"title":"Mobilenetv2_第一版","date":"2020-01-20T06:09:50.000Z","_content":"\n## Mobilenetv2_第一版\n\n第一版只是简单的实现了 Mobilenetv2 的结构，代码有些冗余，而且有许多需要改进的地方\n\n<!--more-->\n{% codeblock lang:JavaScript %}\nimport torch\nimport torch.utils.data as data\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision as tv\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nfrom torchvision.transforms import ToPILImage\nfrom torch.autograd import Variable\nfrom torch import optim\nimport os\nimport datetime\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1, stride=2)\n        self.bottleneck1 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, padding=1, stride=1),\n            nn.ReLU6(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(32, 32, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.ReLU6(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(32, 16, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck2 = nn.Sequential(\n            nn.Conv2d(16, 64, kernel_size=3, padding=1, stride=2),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck3 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck4 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck5 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck6 = nn.Sequential(\n            nn.Conv2d(64, 384, kernel_size=3, padding=1, stride=1),\n            nn.ReLU6(),\n            nn.BatchNorm2d(384),\n            nn.Conv2d(384, 384, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.ReLU6(),\n            nn.BatchNorm2d(384),\n            nn.Conv2d(384, 128, kernel_size=1, padding=0, stride=1)\n        )\n        self.conv2 = nn.Conv2d(128, 512, kernel_size=1, padding=0, stride=1)\n        self.pool1 = nn.AvgPool2d(kernel_size=7)\n        self.conv3 = nn.Conv2d(512, 512, kernel_size=1, padding=0, stride=1)\n        self.Dense = nn.Linear(512, 10)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bottleneck1(out)\n        out = self.bottleneck2(out)\n        out = self.bottleneck3(out)\n        out = self.bottleneck4(out)\n        out = self.bottleneck5(out)\n        out = self.bottleneck6(out)\n        out = self.conv2(out)\n        out = self.pool1(out)\n        out = self.conv3(out)\n        out = out.view(-1, 512)\n        print(out.size())\n        out = self.Dense(out)\n        return out\n\n\ntransform = transforms.ToTensor()\ntrain_dataset = datasets.MNIST(root=\"./mmnist/\", train=True, transform=transform, download=True)\ntest_dataset = datasets.MNIST(root=\"./mmnist/\", train=False, transform=transform, download=True)\ntrain_data_loader = data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\ntest_data_loader = data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n\n\nepoch_n = 5\nmodel = Model()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nfor epoch in range(epoch_n):\n    epoch_loss = 0.0\n    epoch_acc = 0.0\n    for batch in train_data_loader:\n        x_train, y_train = batch\n        y_pred = model(x_train)\n        optimizer.zero_grad()\n        loss = nn.functional.cross_entropy(y_pred, y_train)\n        loss.backward()\n        optimizer.step()\n\n    with torch.no_grad():\n        model.eval()\n        for batch in test_data_loader:\n            x_test, y_test = batch\n            y_pred = model(x_test)\n            loss = nn.functional.cross_entropy(y_pred, y_test)\n            epoch_loss += loss.item()\n            i = -1\n            for num in y_pred:\n                i += 1\n                index = -1\n                max_num = torch.max(num)\n                for nnum in num:\n                    index += 1\n                    if nnum == max_num:\n                        break\n                max_num = index\n                if max_num == y_test[i]:\n                    epoch_acc += 1\n    epoch_loss = epoch_loss * 64 / len(test_dataset)\n    epoch_acc = epoch_acc / len(test_dataset)\n    print(\"Epoch{}:Loss is:{:4f},Acc is:{:4f}\".format(epoch, epoch_loss, epoch_acc))\n\n\n{% endcodeblock %}\n\n## tky看完后说：\n1.写个validate函数吧，用test_dataloader测，记得开with torch.no_grad(): 和model.eval()，val集上的acc只比train集低一点就差不多成功了\n2.用matplotlib把训练过程每个batch的acc和loss画出来\n3.试一下把adam换成带momentum、带nestrov的sgd，并且调一个合适的学习率（lr）\n4.可以用cosannealing这个scheduler套住optimizer\n5.试一下把CEloss加上label smooth\n6.再练一下torch保存和加载模型：torch.save和torch.load 一般格式是torch.save(model.state_dict(), 'ckpt.pth.tar')\n好像是model.load    .pth.tar是常用后缀名    model.state_dict()返回一个字典，表示模型里面的各种东西，包括网络结构和参数张量\n\nPS：\nscheduler是学习率的调整器，是套在optimizer外面的一层壳，可以随着训练过程调整lr\n常用的sche有cos的、指数decay的、多段式decay的\n比如batchsize64，假设trainset有50000张照片，并且定义dataloader的时候drop_last参数是False，那么每个epoch有 上取整(50000 // 64) 即782个batch，比如你训10个epoch，那么总的batch数是7820\n所以在定义scheduler的时候传参最大迭代次数就是7820，然后每得到一个batch的时候就让scheduler.step()，这样刚好可以step()7820次，每次step函数都会让学习率变化一点点\n\ntky orz\n\n\n参考：https://zhuanlan.zhihu.com/p/33720450","source":"_posts/Mobilenetv2_第一版.md","raw":"---\ntitle: Mobilenetv2_第一版\ndate: 2020-01-20 14:09:50\ntags: [机器学习]\n---\n\n## Mobilenetv2_第一版\n\n第一版只是简单的实现了 Mobilenetv2 的结构，代码有些冗余，而且有许多需要改进的地方\n\n<!--more-->\n{% codeblock lang:JavaScript %}\nimport torch\nimport torch.utils.data as data\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision as tv\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nfrom torchvision.transforms import ToPILImage\nfrom torch.autograd import Variable\nfrom torch import optim\nimport os\nimport datetime\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1, stride=2)\n        self.bottleneck1 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, padding=1, stride=1),\n            nn.ReLU6(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(32, 32, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.ReLU6(),\n            nn.BatchNorm2d(32),\n            nn.Conv2d(32, 16, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck2 = nn.Sequential(\n            nn.Conv2d(16, 64, kernel_size=3, padding=1, stride=2),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck3 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck4 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck5 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.ReLU6(),\n            nn.BatchNorm2d(64),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck6 = nn.Sequential(\n            nn.Conv2d(64, 384, kernel_size=3, padding=1, stride=1),\n            nn.ReLU6(),\n            nn.BatchNorm2d(384),\n            nn.Conv2d(384, 384, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.ReLU6(),\n            nn.BatchNorm2d(384),\n            nn.Conv2d(384, 128, kernel_size=1, padding=0, stride=1)\n        )\n        self.conv2 = nn.Conv2d(128, 512, kernel_size=1, padding=0, stride=1)\n        self.pool1 = nn.AvgPool2d(kernel_size=7)\n        self.conv3 = nn.Conv2d(512, 512, kernel_size=1, padding=0, stride=1)\n        self.Dense = nn.Linear(512, 10)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bottleneck1(out)\n        out = self.bottleneck2(out)\n        out = self.bottleneck3(out)\n        out = self.bottleneck4(out)\n        out = self.bottleneck5(out)\n        out = self.bottleneck6(out)\n        out = self.conv2(out)\n        out = self.pool1(out)\n        out = self.conv3(out)\n        out = out.view(-1, 512)\n        print(out.size())\n        out = self.Dense(out)\n        return out\n\n\ntransform = transforms.ToTensor()\ntrain_dataset = datasets.MNIST(root=\"./mmnist/\", train=True, transform=transform, download=True)\ntest_dataset = datasets.MNIST(root=\"./mmnist/\", train=False, transform=transform, download=True)\ntrain_data_loader = data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\ntest_data_loader = data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=True)\n\n\nepoch_n = 5\nmodel = Model()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nfor epoch in range(epoch_n):\n    epoch_loss = 0.0\n    epoch_acc = 0.0\n    for batch in train_data_loader:\n        x_train, y_train = batch\n        y_pred = model(x_train)\n        optimizer.zero_grad()\n        loss = nn.functional.cross_entropy(y_pred, y_train)\n        loss.backward()\n        optimizer.step()\n\n    with torch.no_grad():\n        model.eval()\n        for batch in test_data_loader:\n            x_test, y_test = batch\n            y_pred = model(x_test)\n            loss = nn.functional.cross_entropy(y_pred, y_test)\n            epoch_loss += loss.item()\n            i = -1\n            for num in y_pred:\n                i += 1\n                index = -1\n                max_num = torch.max(num)\n                for nnum in num:\n                    index += 1\n                    if nnum == max_num:\n                        break\n                max_num = index\n                if max_num == y_test[i]:\n                    epoch_acc += 1\n    epoch_loss = epoch_loss * 64 / len(test_dataset)\n    epoch_acc = epoch_acc / len(test_dataset)\n    print(\"Epoch{}:Loss is:{:4f},Acc is:{:4f}\".format(epoch, epoch_loss, epoch_acc))\n\n\n{% endcodeblock %}\n\n## tky看完后说：\n1.写个validate函数吧，用test_dataloader测，记得开with torch.no_grad(): 和model.eval()，val集上的acc只比train集低一点就差不多成功了\n2.用matplotlib把训练过程每个batch的acc和loss画出来\n3.试一下把adam换成带momentum、带nestrov的sgd，并且调一个合适的学习率（lr）\n4.可以用cosannealing这个scheduler套住optimizer\n5.试一下把CEloss加上label smooth\n6.再练一下torch保存和加载模型：torch.save和torch.load 一般格式是torch.save(model.state_dict(), 'ckpt.pth.tar')\n好像是model.load    .pth.tar是常用后缀名    model.state_dict()返回一个字典，表示模型里面的各种东西，包括网络结构和参数张量\n\nPS：\nscheduler是学习率的调整器，是套在optimizer外面的一层壳，可以随着训练过程调整lr\n常用的sche有cos的、指数decay的、多段式decay的\n比如batchsize64，假设trainset有50000张照片，并且定义dataloader的时候drop_last参数是False，那么每个epoch有 上取整(50000 // 64) 即782个batch，比如你训10个epoch，那么总的batch数是7820\n所以在定义scheduler的时候传参最大迭代次数就是7820，然后每得到一个batch的时候就让scheduler.step()，这样刚好可以step()7820次，每次step函数都会让学习率变化一点点\n\ntky orz\n\n\n参考：https://zhuanlan.zhihu.com/p/33720450","slug":"Mobilenetv2_第一版","published":1,"updated":"2020-01-29T03:31:25.272Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh700j0002a0uzt2ees523","content":"<h2 id=\"Mobilenetv2-第一版\"><a href=\"#Mobilenetv2-第一版\" class=\"headerlink\" title=\"Mobilenetv2_第一版\"></a>Mobilenetv2_第一版</h2><p>第一版只是简单的实现了 Mobilenetv2 的结构，代码有些冗余，而且有许多需要改进的地方</p>\n<a id=\"more\"></a>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.utils.data <span class=\"keyword\">as</span> data</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision.transforms <span class=\"keyword\">import</span> ToPILImage</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> optim</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> datetime</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">class Model(nn.Module):</span><br><span class=\"line\">    def __init__(self):</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(Model, self).__init__()</span><br><span class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">2</span>)</span><br><span class=\"line\">        self.bottleneck1 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">16</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck2 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">16</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck3 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck4 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck5 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck6 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">384</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">384</span>, <span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">384</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">384</span>, <span class=\"number\">128</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">128</span>, <span class=\"number\">512</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.pool1 = nn.AvgPool2d(kernel_size=<span class=\"number\">7</span>)</span><br><span class=\"line\">        self.conv3 = nn.Conv2d(<span class=\"number\">512</span>, <span class=\"number\">512</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.Dense = nn.Linear(<span class=\"number\">512</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    def forward(self, x):</span><br><span class=\"line\">        out = self.conv1(x)</span><br><span class=\"line\">        out = self.bottleneck1(out)</span><br><span class=\"line\">        out = self.bottleneck2(out)</span><br><span class=\"line\">        out = self.bottleneck3(out)</span><br><span class=\"line\">        out = self.bottleneck4(out)</span><br><span class=\"line\">        out = self.bottleneck5(out)</span><br><span class=\"line\">        out = self.bottleneck6(out)</span><br><span class=\"line\">        out = self.conv2(out)</span><br><span class=\"line\">        out = self.pool1(out)</span><br><span class=\"line\">        out = self.conv3(out)</span><br><span class=\"line\">        out = out.view(<span class=\"number\">-1</span>, <span class=\"number\">512</span>)</span><br><span class=\"line\">        print(out.size())</span><br><span class=\"line\">        out = self.Dense(out)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">transform = transforms.ToTensor()</span><br><span class=\"line\">train_dataset = datasets.MNIST(root=<span class=\"string\">\"./mmnist/\"</span>, train=True, transform=transform, download=True)</span><br><span class=\"line\">test_dataset = datasets.MNIST(root=<span class=\"string\">\"./mmnist/\"</span>, train=False, transform=transform, download=True)</span><br><span class=\"line\">train_data_loader = data.DataLoader(dataset=train_dataset, batch_size=<span class=\"number\">64</span>, shuffle=True)</span><br><span class=\"line\">test_data_loader = data.DataLoader(dataset=test_dataset, batch_size=<span class=\"number\">64</span>, shuffle=True)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">epoch_n = <span class=\"number\">5</span></span><br><span class=\"line\">model = Model()</span><br><span class=\"line\">optimizer = torch.optim.Adam(model.parameters(), lr=<span class=\"number\">0.001</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(epoch_n):</span><br><span class=\"line\">    epoch_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">    epoch_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> batch <span class=\"keyword\">in</span> train_data_loader:</span><br><span class=\"line\">        x_train, y_train = batch</span><br><span class=\"line\">        y_pred = model(x_train)</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss = nn.functional.cross_entropy(y_pred, y_train)</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        model.eval()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> batch <span class=\"keyword\">in</span> test_data_loader:</span><br><span class=\"line\">            x_test, y_test = batch</span><br><span class=\"line\">            y_pred = model(x_test)</span><br><span class=\"line\">            loss = nn.functional.cross_entropy(y_pred, y_test)</span><br><span class=\"line\">            epoch_loss += loss.item()</span><br><span class=\"line\">            i = <span class=\"number\">-1</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> num <span class=\"keyword\">in</span> y_pred:</span><br><span class=\"line\">                i += <span class=\"number\">1</span></span><br><span class=\"line\">                index = <span class=\"number\">-1</span></span><br><span class=\"line\">                max_num = torch.max(num)</span><br><span class=\"line\">                <span class=\"keyword\">for</span> nnum <span class=\"keyword\">in</span> num:</span><br><span class=\"line\">                    index += <span class=\"number\">1</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> nnum == max_num:</span><br><span class=\"line\">                        <span class=\"keyword\">break</span></span><br><span class=\"line\">                max_num = index</span><br><span class=\"line\">                <span class=\"keyword\">if</span> max_num == y_test[i]:</span><br><span class=\"line\">                    epoch_acc += <span class=\"number\">1</span></span><br><span class=\"line\">    epoch_loss = epoch_loss * <span class=\"number\">64</span> / len(test_dataset)</span><br><span class=\"line\">    epoch_acc = epoch_acc / len(test_dataset)</span><br><span class=\"line\">    print(<span class=\"string\">\"Epoch&#123;&#125;:Loss is:&#123;:4f&#125;,Acc is:&#123;:4f&#125;\"</span>.format(epoch, epoch_loss, epoch_acc))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h2 id=\"tky看完后说：\"><a href=\"#tky看完后说：\" class=\"headerlink\" title=\"tky看完后说：\"></a>tky看完后说：</h2><p>1.写个validate函数吧，用test_dataloader测，记得开with torch.no_grad(): 和model.eval()，val集上的acc只比train集低一点就差不多成功了<br>2.用matplotlib把训练过程每个batch的acc和loss画出来<br>3.试一下把adam换成带momentum、带nestrov的sgd，并且调一个合适的学习率（lr）<br>4.可以用cosannealing这个scheduler套住optimizer<br>5.试一下把CEloss加上label smooth<br>6.再练一下torch保存和加载模型：torch.save和torch.load 一般格式是torch.save(model.state_dict(), ‘ckpt.pth.tar’)<br>好像是model.load    .pth.tar是常用后缀名    model.state_dict()返回一个字典，表示模型里面的各种东西，包括网络结构和参数张量</p>\n<p>PS：<br>scheduler是学习率的调整器，是套在optimizer外面的一层壳，可以随着训练过程调整lr<br>常用的sche有cos的、指数decay的、多段式decay的<br>比如batchsize64，假设trainset有50000张照片，并且定义dataloader的时候drop_last参数是False，那么每个epoch有 上取整(50000 // 64) 即782个batch，比如你训10个epoch，那么总的batch数是7820<br>所以在定义scheduler的时候传参最大迭代次数就是7820，然后每得到一个batch的时候就让scheduler.step()，这样刚好可以step()7820次，每次step函数都会让学习率变化一点点</p>\n<p>tky orz</p>\n<p>参考：<a href=\"https://zhuanlan.zhihu.com/p/33720450\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/33720450</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"Mobilenetv2-第一版\"><a href=\"#Mobilenetv2-第一版\" class=\"headerlink\" title=\"Mobilenetv2_第一版\"></a>Mobilenetv2_第一版</h2><p>第一版只是简单的实现了 Mobilenetv2 的结构，代码有些冗余，而且有许多需要改进的地方</p>","more":"<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.utils.data <span class=\"keyword\">as</span> data</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision.transforms <span class=\"keyword\">import</span> ToPILImage</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> optim</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> datetime</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">class Model(nn.Module):</span><br><span class=\"line\">    def __init__(self):</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(Model, self).__init__()</span><br><span class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">2</span>)</span><br><span class=\"line\">        self.bottleneck1 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">16</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck2 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">16</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck3 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck4 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck5 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck6 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">384</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">384</span>, <span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">384</span>),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">384</span>, <span class=\"number\">128</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">128</span>, <span class=\"number\">512</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.pool1 = nn.AvgPool2d(kernel_size=<span class=\"number\">7</span>)</span><br><span class=\"line\">        self.conv3 = nn.Conv2d(<span class=\"number\">512</span>, <span class=\"number\">512</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.Dense = nn.Linear(<span class=\"number\">512</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    def forward(self, x):</span><br><span class=\"line\">        out = self.conv1(x)</span><br><span class=\"line\">        out = self.bottleneck1(out)</span><br><span class=\"line\">        out = self.bottleneck2(out)</span><br><span class=\"line\">        out = self.bottleneck3(out)</span><br><span class=\"line\">        out = self.bottleneck4(out)</span><br><span class=\"line\">        out = self.bottleneck5(out)</span><br><span class=\"line\">        out = self.bottleneck6(out)</span><br><span class=\"line\">        out = self.conv2(out)</span><br><span class=\"line\">        out = self.pool1(out)</span><br><span class=\"line\">        out = self.conv3(out)</span><br><span class=\"line\">        out = out.view(<span class=\"number\">-1</span>, <span class=\"number\">512</span>)</span><br><span class=\"line\">        print(out.size())</span><br><span class=\"line\">        out = self.Dense(out)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">transform = transforms.ToTensor()</span><br><span class=\"line\">train_dataset = datasets.MNIST(root=<span class=\"string\">\"./mmnist/\"</span>, train=True, transform=transform, download=True)</span><br><span class=\"line\">test_dataset = datasets.MNIST(root=<span class=\"string\">\"./mmnist/\"</span>, train=False, transform=transform, download=True)</span><br><span class=\"line\">train_data_loader = data.DataLoader(dataset=train_dataset, batch_size=<span class=\"number\">64</span>, shuffle=True)</span><br><span class=\"line\">test_data_loader = data.DataLoader(dataset=test_dataset, batch_size=<span class=\"number\">64</span>, shuffle=True)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">epoch_n = <span class=\"number\">5</span></span><br><span class=\"line\">model = Model()</span><br><span class=\"line\">optimizer = torch.optim.Adam(model.parameters(), lr=<span class=\"number\">0.001</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(epoch_n):</span><br><span class=\"line\">    epoch_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">    epoch_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> batch <span class=\"keyword\">in</span> train_data_loader:</span><br><span class=\"line\">        x_train, y_train = batch</span><br><span class=\"line\">        y_pred = model(x_train)</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss = nn.functional.cross_entropy(y_pred, y_train)</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        model.eval()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> batch <span class=\"keyword\">in</span> test_data_loader:</span><br><span class=\"line\">            x_test, y_test = batch</span><br><span class=\"line\">            y_pred = model(x_test)</span><br><span class=\"line\">            loss = nn.functional.cross_entropy(y_pred, y_test)</span><br><span class=\"line\">            epoch_loss += loss.item()</span><br><span class=\"line\">            i = <span class=\"number\">-1</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> num <span class=\"keyword\">in</span> y_pred:</span><br><span class=\"line\">                i += <span class=\"number\">1</span></span><br><span class=\"line\">                index = <span class=\"number\">-1</span></span><br><span class=\"line\">                max_num = torch.max(num)</span><br><span class=\"line\">                <span class=\"keyword\">for</span> nnum <span class=\"keyword\">in</span> num:</span><br><span class=\"line\">                    index += <span class=\"number\">1</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> nnum == max_num:</span><br><span class=\"line\">                        <span class=\"keyword\">break</span></span><br><span class=\"line\">                max_num = index</span><br><span class=\"line\">                <span class=\"keyword\">if</span> max_num == y_test[i]:</span><br><span class=\"line\">                    epoch_acc += <span class=\"number\">1</span></span><br><span class=\"line\">    epoch_loss = epoch_loss * <span class=\"number\">64</span> / len(test_dataset)</span><br><span class=\"line\">    epoch_acc = epoch_acc / len(test_dataset)</span><br><span class=\"line\">    print(<span class=\"string\">\"Epoch&#123;&#125;:Loss is:&#123;:4f&#125;,Acc is:&#123;:4f&#125;\"</span>.format(epoch, epoch_loss, epoch_acc))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h2 id=\"tky看完后说：\"><a href=\"#tky看完后说：\" class=\"headerlink\" title=\"tky看完后说：\"></a>tky看完后说：</h2><p>1.写个validate函数吧，用test_dataloader测，记得开with torch.no_grad(): 和model.eval()，val集上的acc只比train集低一点就差不多成功了<br>2.用matplotlib把训练过程每个batch的acc和loss画出来<br>3.试一下把adam换成带momentum、带nestrov的sgd，并且调一个合适的学习率（lr）<br>4.可以用cosannealing这个scheduler套住optimizer<br>5.试一下把CEloss加上label smooth<br>6.再练一下torch保存和加载模型：torch.save和torch.load 一般格式是torch.save(model.state_dict(), ‘ckpt.pth.tar’)<br>好像是model.load    .pth.tar是常用后缀名    model.state_dict()返回一个字典，表示模型里面的各种东西，包括网络结构和参数张量</p>\n<p>PS：<br>scheduler是学习率的调整器，是套在optimizer外面的一层壳，可以随着训练过程调整lr<br>常用的sche有cos的、指数decay的、多段式decay的<br>比如batchsize64，假设trainset有50000张照片，并且定义dataloader的时候drop_last参数是False，那么每个epoch有 上取整(50000 // 64) 即782个batch，比如你训10个epoch，那么总的batch数是7820<br>所以在定义scheduler的时候传参最大迭代次数就是7820，然后每得到一个batch的时候就让scheduler.step()，这样刚好可以step()7820次，每次step函数都会让学习率变化一点点</p>\n<p>tky orz</p>\n<p>参考：<a href=\"https://zhuanlan.zhihu.com/p/33720450\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/33720450</a></p>"},{"title":"Mobilenetv2_第三版","date":"2020-01-29T11:06:51.000Z","_content":"\n## Mobilenet v2 第三版\n\n在这一版中，纠正了原来 Model 中的错误……\n<!--more-->\n\n{% codeblock lang:JavaScript %}\nimport torch\nimport torch.utils.data as data\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision as tv\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nfrom torchvision.transforms import ToPILImage\nfrom torch.autograd import Variable\nfrom torch import optim\nfrom tensorboardX import SummaryWriter\nimport os\nimport datetime\n\nmnist_mean = 0.1307\nmnist_std = 0.3081\nepoch_n = 5\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n\n        channels = [32, 64, 144, 192, 384]\n        strides = [1, 2, 1, 1]\n        ex_ch = [ch * 3 for ch in channels]\n\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1, channels[0], kernel_size=3, padding=1, stride=2, bias=False),\n            nn.BatchNorm2d(channels[0]),\n            nn.ReLU6()\n        )\n\n        # Bottleneck第一层和第三层都是pointwise卷积，也即kernel_size=1，groups=1的卷积，\n        # 第二层是depthwise卷积，也即kernel_size=3，groups=channels的卷积\n        self.bottleneck1 = nn.Sequential(\n            nn.Conv2d(channels[0], ex_ch[0], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(ex_ch[0]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[0], ex_ch[0], kernel_size=3, padding=1, stride=strides[0], groups=ex_ch[0], bias=False),\n            nn.BatchNorm2d(ex_ch[0]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[0], channels[1], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(channels[1])\n        )\n        self.bottleneck2 = nn.Sequential(\n            nn.Conv2d(channels[1], ex_ch[1], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(ex_ch[1]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[1], ex_ch[1], kernel_size=3, padding=1, stride=strides[1], groups=ex_ch[1], bias=False),\n            nn.BatchNorm2d(ex_ch[1]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[1], channels[2], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(channels[2])\n        )\n        self.bottleneck3 = nn.Sequential(\n            nn.Conv2d(channels[2], ex_ch[2], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(ex_ch[2]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[2], ex_ch[2], kernel_size=3, padding=1, stride=strides[2], groups=ex_ch[2], bias=False),\n            nn.BatchNorm2d(ex_ch[2]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[2], channels[3], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(channels[3])\n        )\n        self.bottleneck4 = nn.Sequential(\n            nn.Conv2d(channels[3], ex_ch[3], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(ex_ch[3]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[3], ex_ch[3], kernel_size=3, padding=1, stride=strides[3], groups=ex_ch[3], bias=False),\n            nn.BatchNorm2d(ex_ch[3]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[3], channels[4], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(channels[4])\n        )\n\n        self.last_ch = 512\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(channels[4], self.last_ch, kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(self.last_ch),\n            nn.ReLU6()\n        )\n        self.pool1 = nn.AvgPool2d(kernel_size=7)\n        self.Dense = nn.Linear(self.last_ch, 10)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bottleneck1(out)\n        out = self.bottleneck2(out)\n        out = self.bottleneck3(out)\n        out = self.bottleneck4(out)\n        out = self.conv2(out)\n        out = self.pool1(out)\n        out = out.view(-1, self.last_ch)\n        out = self.Dense(out)\n        return out\n\n\ndef get_trainloader(batch_size):\n    dataset = datasets.MNIST(root=\"./mmnist/\", train=True, download=True,\n                             transform=transforms.Compose([\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(\n                                     (mnist_mean,), (mnist_std,)\n                                 )\n                             ]))\n    return data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=2,\n        pin_memory=True,\n        drop_last=False,\n    )\n\n\ndef get_testloader(batch_size):\n    dataset = datasets.MNIST(root=\"./mmnist/\", train=False, download=True,\n                             transform=transforms.Compose([\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(\n                                     (mnist_mean,), (mnist_std,)\n                                 )\n                             ]))\n    return data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        shuffle=False,                   # 每个epoch是否混淆\n        num_workers=2,                   # 多进程并发装载\n        pin_memory=True,                 # 是否使用锁页内存\n        drop_last=False,                 # 是否丢弃最后一个不完整的batch\n    )\n\n\ndef train(train_data_loader, optimizer):\n    epoch_acc = 0.0\n    epoch_loss = 0.0\n    train_dataset_length = 0.0\n    tot_it = len(train_data_loader)\n    for it, (x_train, y_train) in enumerate(train_data_loader):\n        train_dataset_length += len(y_train)\n        y_pred = model(x_train)\n        optimizer.zero_grad()\n        loss = nn.functional.cross_entropy(y_pred, y_train)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n        y_pred = torch.argmax(y_pred, dim=1)\n        epoch_acc += y_pred.eq(y_train).sum().item()\n        print(it)\n\n        if it % 32 == 0:\n            print(f'it:{it}/{tot_it}, '\n                  f'Loss:{epoch_loss}/{it+1} = {epoch_loss/(it+1)}, '\n                  f'Acc:{epoch_acc}/{train_dataset_length} = {epoch_acc/train_dataset_length}')\n\n    print(\"train_Epoch:Loss is:{:4f},Acc is:{:4f}\".format(epoch_loss/tot_it, epoch_acc/train_dataset_length))\n\n\ndef validation(test_data_loader):\n    with torch.no_grad():\n        model.eval()\n        epoch_acc = 0.0\n        epoch_loss = 0.0\n        test_dataset_length = 0.0\n        tot_it = len(test_data_loader)\n        for it, (x_test, y_test) in enumerate(test_data_loader):\n            test_dataset_length += len(y_test)\n            y_pred = model(x_test)\n            loss = nn.functional.cross_entropy(y_pred, y_test)\n            epoch_loss += loss.item()\n            y_pred = torch.argmax(y_pred, dim=1)\n            epoch_acc += y_pred.eq(y_test).sum().item()\n\n            if it % 32 == 0:\n                print(f'it:{it}/{tot_it}, '\n                      f'Loss:{epoch_loss}/{it+1} = {epoch_loss / (it+1)}, '\n                      f'Acc:{epoch_acc}/{test_dataset_length} = {epoch_acc / test_dataset_length}')\n\n        model.train()\n        print(\"test_Epoch:Loss is:{:4f},Acc is:{:4f}\".format(epoch_loss/tot_it, epoch_acc/test_dataset_length))\n\n\nmodel = Model()\n\n\ndef main():\n    PATH = './Mobilenetv2.pth'\n    # pretrained_net = torch.load(PATH)\n    # model.load_state_dict(pretrained_net)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    train_data_loader = get_trainloader(64)\n    test_data_loader = get_testloader(64)\n    for epoch in range(epoch_n):\n        train(train_data_loader=train_data_loader, optimizer=optimizer)\n        validation(test_data_loader=test_data_loader)\n    torch.save(model.state_dict(), PATH)\n\n\nif __name__ == '__main__':\n    main()\n\n{% endcodeblock %}","source":"_posts/Mobilenetv2_第三版.md","raw":"---\ntitle: Mobilenetv2_第三版\ndate: 2020-01-29 19:06:51\ntags: [机器学习]\n---\n\n## Mobilenet v2 第三版\n\n在这一版中，纠正了原来 Model 中的错误……\n<!--more-->\n\n{% codeblock lang:JavaScript %}\nimport torch\nimport torch.utils.data as data\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision as tv\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nfrom torchvision.transforms import ToPILImage\nfrom torch.autograd import Variable\nfrom torch import optim\nfrom tensorboardX import SummaryWriter\nimport os\nimport datetime\n\nmnist_mean = 0.1307\nmnist_std = 0.3081\nepoch_n = 5\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n\n        channels = [32, 64, 144, 192, 384]\n        strides = [1, 2, 1, 1]\n        ex_ch = [ch * 3 for ch in channels]\n\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1, channels[0], kernel_size=3, padding=1, stride=2, bias=False),\n            nn.BatchNorm2d(channels[0]),\n            nn.ReLU6()\n        )\n\n        # Bottleneck第一层和第三层都是pointwise卷积，也即kernel_size=1，groups=1的卷积，\n        # 第二层是depthwise卷积，也即kernel_size=3，groups=channels的卷积\n        self.bottleneck1 = nn.Sequential(\n            nn.Conv2d(channels[0], ex_ch[0], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(ex_ch[0]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[0], ex_ch[0], kernel_size=3, padding=1, stride=strides[0], groups=ex_ch[0], bias=False),\n            nn.BatchNorm2d(ex_ch[0]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[0], channels[1], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(channels[1])\n        )\n        self.bottleneck2 = nn.Sequential(\n            nn.Conv2d(channels[1], ex_ch[1], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(ex_ch[1]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[1], ex_ch[1], kernel_size=3, padding=1, stride=strides[1], groups=ex_ch[1], bias=False),\n            nn.BatchNorm2d(ex_ch[1]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[1], channels[2], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(channels[2])\n        )\n        self.bottleneck3 = nn.Sequential(\n            nn.Conv2d(channels[2], ex_ch[2], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(ex_ch[2]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[2], ex_ch[2], kernel_size=3, padding=1, stride=strides[2], groups=ex_ch[2], bias=False),\n            nn.BatchNorm2d(ex_ch[2]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[2], channels[3], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(channels[3])\n        )\n        self.bottleneck4 = nn.Sequential(\n            nn.Conv2d(channels[3], ex_ch[3], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(ex_ch[3]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[3], ex_ch[3], kernel_size=3, padding=1, stride=strides[3], groups=ex_ch[3], bias=False),\n            nn.BatchNorm2d(ex_ch[3]),\n            nn.ReLU6(),\n            nn.Conv2d(ex_ch[3], channels[4], kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(channels[4])\n        )\n\n        self.last_ch = 512\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(channels[4], self.last_ch, kernel_size=1, padding=0, stride=1, bias=False),\n            nn.BatchNorm2d(self.last_ch),\n            nn.ReLU6()\n        )\n        self.pool1 = nn.AvgPool2d(kernel_size=7)\n        self.Dense = nn.Linear(self.last_ch, 10)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bottleneck1(out)\n        out = self.bottleneck2(out)\n        out = self.bottleneck3(out)\n        out = self.bottleneck4(out)\n        out = self.conv2(out)\n        out = self.pool1(out)\n        out = out.view(-1, self.last_ch)\n        out = self.Dense(out)\n        return out\n\n\ndef get_trainloader(batch_size):\n    dataset = datasets.MNIST(root=\"./mmnist/\", train=True, download=True,\n                             transform=transforms.Compose([\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(\n                                     (mnist_mean,), (mnist_std,)\n                                 )\n                             ]))\n    return data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=2,\n        pin_memory=True,\n        drop_last=False,\n    )\n\n\ndef get_testloader(batch_size):\n    dataset = datasets.MNIST(root=\"./mmnist/\", train=False, download=True,\n                             transform=transforms.Compose([\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(\n                                     (mnist_mean,), (mnist_std,)\n                                 )\n                             ]))\n    return data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        shuffle=False,                   # 每个epoch是否混淆\n        num_workers=2,                   # 多进程并发装载\n        pin_memory=True,                 # 是否使用锁页内存\n        drop_last=False,                 # 是否丢弃最后一个不完整的batch\n    )\n\n\ndef train(train_data_loader, optimizer):\n    epoch_acc = 0.0\n    epoch_loss = 0.0\n    train_dataset_length = 0.0\n    tot_it = len(train_data_loader)\n    for it, (x_train, y_train) in enumerate(train_data_loader):\n        train_dataset_length += len(y_train)\n        y_pred = model(x_train)\n        optimizer.zero_grad()\n        loss = nn.functional.cross_entropy(y_pred, y_train)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n        y_pred = torch.argmax(y_pred, dim=1)\n        epoch_acc += y_pred.eq(y_train).sum().item()\n        print(it)\n\n        if it % 32 == 0:\n            print(f'it:{it}/{tot_it}, '\n                  f'Loss:{epoch_loss}/{it+1} = {epoch_loss/(it+1)}, '\n                  f'Acc:{epoch_acc}/{train_dataset_length} = {epoch_acc/train_dataset_length}')\n\n    print(\"train_Epoch:Loss is:{:4f},Acc is:{:4f}\".format(epoch_loss/tot_it, epoch_acc/train_dataset_length))\n\n\ndef validation(test_data_loader):\n    with torch.no_grad():\n        model.eval()\n        epoch_acc = 0.0\n        epoch_loss = 0.0\n        test_dataset_length = 0.0\n        tot_it = len(test_data_loader)\n        for it, (x_test, y_test) in enumerate(test_data_loader):\n            test_dataset_length += len(y_test)\n            y_pred = model(x_test)\n            loss = nn.functional.cross_entropy(y_pred, y_test)\n            epoch_loss += loss.item()\n            y_pred = torch.argmax(y_pred, dim=1)\n            epoch_acc += y_pred.eq(y_test).sum().item()\n\n            if it % 32 == 0:\n                print(f'it:{it}/{tot_it}, '\n                      f'Loss:{epoch_loss}/{it+1} = {epoch_loss / (it+1)}, '\n                      f'Acc:{epoch_acc}/{test_dataset_length} = {epoch_acc / test_dataset_length}')\n\n        model.train()\n        print(\"test_Epoch:Loss is:{:4f},Acc is:{:4f}\".format(epoch_loss/tot_it, epoch_acc/test_dataset_length))\n\n\nmodel = Model()\n\n\ndef main():\n    PATH = './Mobilenetv2.pth'\n    # pretrained_net = torch.load(PATH)\n    # model.load_state_dict(pretrained_net)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    train_data_loader = get_trainloader(64)\n    test_data_loader = get_testloader(64)\n    for epoch in range(epoch_n):\n        train(train_data_loader=train_data_loader, optimizer=optimizer)\n        validation(test_data_loader=test_data_loader)\n    torch.save(model.state_dict(), PATH)\n\n\nif __name__ == '__main__':\n    main()\n\n{% endcodeblock %}","slug":"Mobilenetv2_第三版","published":1,"updated":"2020-01-29T12:08:19.250Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh700r0005a0uzr9shzlkd","content":"<h2 id=\"Mobilenet-v2-第三版\"><a href=\"#Mobilenet-v2-第三版\" class=\"headerlink\" title=\"Mobilenet v2 第三版\"></a>Mobilenet v2 第三版</h2><p>在这一版中，纠正了原来 Model 中的错误……<br><a id=\"more\"></a></p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.utils.data <span class=\"keyword\">as</span> data</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision.transforms <span class=\"keyword\">import</span> ToPILImage</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> optim</span><br><span class=\"line\"><span class=\"keyword\">from</span> tensorboardX <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> datetime</span><br><span class=\"line\"></span><br><span class=\"line\">mnist_mean = <span class=\"number\">0.1307</span></span><br><span class=\"line\">mnist_std = <span class=\"number\">0.3081</span></span><br><span class=\"line\">epoch_n = <span class=\"number\">5</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">class Model(nn.Module):</span><br><span class=\"line\">    def __init__(self):</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(Model, self).__init__()</span><br><span class=\"line\"></span><br><span class=\"line\">        channels = [<span class=\"number\">32</span>, <span class=\"number\">64</span>, <span class=\"number\">144</span>, <span class=\"number\">192</span>, <span class=\"number\">384</span>]</span><br><span class=\"line\">        strides = [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>]</span><br><span class=\"line\">        ex_ch = [ch * <span class=\"number\">3</span> <span class=\"keyword\">for</span> ch <span class=\"keyword\">in</span> channels]</span><br><span class=\"line\"></span><br><span class=\"line\">        self.conv1 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">1</span>, channels[<span class=\"number\">0</span>], kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">2</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(channels[<span class=\"number\">0</span>]),</span><br><span class=\"line\">            nn.ReLU6()</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        # Bottleneck第一层和第三层都是pointwise卷积，也即kernel_size=1，groups=1的卷积，</span><br><span class=\"line\">        # 第二层是depthwise卷积，也即kernel_size=3，groups=channels的卷积</span><br><span class=\"line\">        self.bottleneck1 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(channels[<span class=\"number\">0</span>], ex_ch[<span class=\"number\">0</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">0</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">0</span>], ex_ch[<span class=\"number\">0</span>], kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=strides[<span class=\"number\">0</span>], groups=ex_ch[<span class=\"number\">0</span>], bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">0</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">0</span>], channels[<span class=\"number\">1</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(channels[<span class=\"number\">1</span>])</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck2 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(channels[<span class=\"number\">1</span>], ex_ch[<span class=\"number\">1</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">1</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">1</span>], ex_ch[<span class=\"number\">1</span>], kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=strides[<span class=\"number\">1</span>], groups=ex_ch[<span class=\"number\">1</span>], bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">1</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">1</span>], channels[<span class=\"number\">2</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(channels[<span class=\"number\">2</span>])</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck3 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(channels[<span class=\"number\">2</span>], ex_ch[<span class=\"number\">2</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">2</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">2</span>], ex_ch[<span class=\"number\">2</span>], kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=strides[<span class=\"number\">2</span>], groups=ex_ch[<span class=\"number\">2</span>], bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">2</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">2</span>], channels[<span class=\"number\">3</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(channels[<span class=\"number\">3</span>])</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck4 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(channels[<span class=\"number\">3</span>], ex_ch[<span class=\"number\">3</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">3</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">3</span>], ex_ch[<span class=\"number\">3</span>], kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=strides[<span class=\"number\">3</span>], groups=ex_ch[<span class=\"number\">3</span>], bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">3</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">3</span>], channels[<span class=\"number\">4</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(channels[<span class=\"number\">4</span>])</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        self.last_ch = <span class=\"number\">512</span></span><br><span class=\"line\">        self.conv2 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(channels[<span class=\"number\">4</span>], self.last_ch, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(self.last_ch),</span><br><span class=\"line\">            nn.ReLU6()</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.pool1 = nn.AvgPool2d(kernel_size=<span class=\"number\">7</span>)</span><br><span class=\"line\">        self.Dense = nn.Linear(self.last_ch, <span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    def forward(self, x):</span><br><span class=\"line\">        out = self.conv1(x)</span><br><span class=\"line\">        out = self.bottleneck1(out)</span><br><span class=\"line\">        out = self.bottleneck2(out)</span><br><span class=\"line\">        out = self.bottleneck3(out)</span><br><span class=\"line\">        out = self.bottleneck4(out)</span><br><span class=\"line\">        out = self.conv2(out)</span><br><span class=\"line\">        out = self.pool1(out)</span><br><span class=\"line\">        out = out.view(<span class=\"number\">-1</span>, self.last_ch)</span><br><span class=\"line\">        out = self.Dense(out)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def get_trainloader(batch_size):</span><br><span class=\"line\">    dataset = datasets.MNIST(root=<span class=\"string\">\"./mmnist/\"</span>, train=True, download=True,</span><br><span class=\"line\">                             transform=transforms.Compose([</span><br><span class=\"line\">                                 transforms.ToTensor(),</span><br><span class=\"line\">                                 transforms.Normalize(</span><br><span class=\"line\">                                     (mnist_mean,), (mnist_std,)</span><br><span class=\"line\">                                 )</span><br><span class=\"line\">                             ]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data.DataLoader(</span><br><span class=\"line\">        dataset=dataset,</span><br><span class=\"line\">        batch_size=batch_size,</span><br><span class=\"line\">        shuffle=True,</span><br><span class=\"line\">        num_workers=<span class=\"number\">2</span>,</span><br><span class=\"line\">        pin_memory=True,</span><br><span class=\"line\">        drop_last=False,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def get_testloader(batch_size):</span><br><span class=\"line\">    dataset = datasets.MNIST(root=<span class=\"string\">\"./mmnist/\"</span>, train=False, download=True,</span><br><span class=\"line\">                             transform=transforms.Compose([</span><br><span class=\"line\">                                 transforms.ToTensor(),</span><br><span class=\"line\">                                 transforms.Normalize(</span><br><span class=\"line\">                                     (mnist_mean,), (mnist_std,)</span><br><span class=\"line\">                                 )</span><br><span class=\"line\">                             ]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data.DataLoader(</span><br><span class=\"line\">        dataset=dataset,</span><br><span class=\"line\">        batch_size=batch_size,</span><br><span class=\"line\">        shuffle=False,                   # 每个epoch是否混淆</span><br><span class=\"line\">        num_workers=2,                   # 多进程并发装载</span><br><span class=\"line\">        pin_memory=True,                 # 是否使用锁页内存</span><br><span class=\"line\">        drop_last=False,                 # 是否丢弃最后一个不完整的batch</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def train(train_data_loader, optimizer):</span><br><span class=\"line\">    epoch_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\">    epoch_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">    train_dataset_length = <span class=\"number\">0.0</span></span><br><span class=\"line\">    tot_it = len(train_data_loader)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> it, (x_train, y_train) <span class=\"keyword\">in</span> enumerate(train_data_loader):</span><br><span class=\"line\">        train_dataset_length += len(y_train)</span><br><span class=\"line\">        y_pred = model(x_train)</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss = nn.functional.cross_entropy(y_pred, y_train)</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\">        epoch_loss += loss.item()</span><br><span class=\"line\">        y_pred = torch.argmax(y_pred, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        epoch_acc += y_pred.eq(y_train).sum().item()</span><br><span class=\"line\">        print(it)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> it % <span class=\"number\">32</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            print(f<span class=\"string\">'it:&#123;it&#125;/&#123;tot_it&#125;, '</span></span><br><span class=\"line\">                  f<span class=\"string\">'Loss:&#123;epoch_loss&#125;/&#123;it+1&#125; = &#123;epoch_loss/(it+1)&#125;, '</span></span><br><span class=\"line\">                  f<span class=\"string\">'Acc:&#123;epoch_acc&#125;/&#123;train_dataset_length&#125; = &#123;epoch_acc/train_dataset_length&#125;'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    print(<span class=\"string\">\"train_Epoch:Loss is:&#123;:4f&#125;,Acc is:&#123;:4f&#125;\"</span>.format(epoch_loss/tot_it, epoch_acc/train_dataset_length))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def validation(test_data_loader):</span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        model.eval()</span><br><span class=\"line\">        epoch_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\">        epoch_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">        test_dataset_length = <span class=\"number\">0.0</span></span><br><span class=\"line\">        tot_it = len(test_data_loader)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> it, (x_test, y_test) <span class=\"keyword\">in</span> enumerate(test_data_loader):</span><br><span class=\"line\">            test_dataset_length += len(y_test)</span><br><span class=\"line\">            y_pred = model(x_test)</span><br><span class=\"line\">            loss = nn.functional.cross_entropy(y_pred, y_test)</span><br><span class=\"line\">            epoch_loss += loss.item()</span><br><span class=\"line\">            y_pred = torch.argmax(y_pred, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">            epoch_acc += y_pred.eq(y_test).sum().item()</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> it % <span class=\"number\">32</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">                print(f<span class=\"string\">'it:&#123;it&#125;/&#123;tot_it&#125;, '</span></span><br><span class=\"line\">                      f<span class=\"string\">'Loss:&#123;epoch_loss&#125;/&#123;it+1&#125; = &#123;epoch_loss / (it+1)&#125;, '</span></span><br><span class=\"line\">                      f<span class=\"string\">'Acc:&#123;epoch_acc&#125;/&#123;test_dataset_length&#125; = &#123;epoch_acc / test_dataset_length&#125;'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        model.train()</span><br><span class=\"line\">        print(<span class=\"string\">\"test_Epoch:Loss is:&#123;:4f&#125;,Acc is:&#123;:4f&#125;\"</span>.format(epoch_loss/tot_it, epoch_acc/test_dataset_length))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">model = Model()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def main():</span><br><span class=\"line\">    PATH = <span class=\"string\">'./Mobilenetv2.pth'</span></span><br><span class=\"line\">    # pretrained_net = torch.load(PATH)</span><br><span class=\"line\">    # model.load_state_dict(pretrained_net)</span><br><span class=\"line\">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class=\"number\">0.001</span>)</span><br><span class=\"line\">    train_data_loader = get_trainloader(<span class=\"number\">64</span>)</span><br><span class=\"line\">    test_data_loader = get_testloader(<span class=\"number\">64</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(epoch_n):</span><br><span class=\"line\">        train(train_data_loader=train_data_loader, optimizer=optimizer)</span><br><span class=\"line\">        validation(test_data_loader=test_data_loader)</span><br><span class=\"line\">    torch.save(model.state_dict(), PATH)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    main()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<h2 id=\"Mobilenet-v2-第三版\"><a href=\"#Mobilenet-v2-第三版\" class=\"headerlink\" title=\"Mobilenet v2 第三版\"></a>Mobilenet v2 第三版</h2><p>在这一版中，纠正了原来 Model 中的错误……<br></p>","more":"<p></p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.utils.data <span class=\"keyword\">as</span> data</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision.transforms <span class=\"keyword\">import</span> ToPILImage</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> optim</span><br><span class=\"line\"><span class=\"keyword\">from</span> tensorboardX <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> datetime</span><br><span class=\"line\"></span><br><span class=\"line\">mnist_mean = <span class=\"number\">0.1307</span></span><br><span class=\"line\">mnist_std = <span class=\"number\">0.3081</span></span><br><span class=\"line\">epoch_n = <span class=\"number\">5</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">class Model(nn.Module):</span><br><span class=\"line\">    def __init__(self):</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(Model, self).__init__()</span><br><span class=\"line\"></span><br><span class=\"line\">        channels = [<span class=\"number\">32</span>, <span class=\"number\">64</span>, <span class=\"number\">144</span>, <span class=\"number\">192</span>, <span class=\"number\">384</span>]</span><br><span class=\"line\">        strides = [<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>]</span><br><span class=\"line\">        ex_ch = [ch * <span class=\"number\">3</span> <span class=\"keyword\">for</span> ch <span class=\"keyword\">in</span> channels]</span><br><span class=\"line\"></span><br><span class=\"line\">        self.conv1 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">1</span>, channels[<span class=\"number\">0</span>], kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">2</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(channels[<span class=\"number\">0</span>]),</span><br><span class=\"line\">            nn.ReLU6()</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        # Bottleneck第一层和第三层都是pointwise卷积，也即kernel_size=1，groups=1的卷积，</span><br><span class=\"line\">        # 第二层是depthwise卷积，也即kernel_size=3，groups=channels的卷积</span><br><span class=\"line\">        self.bottleneck1 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(channels[<span class=\"number\">0</span>], ex_ch[<span class=\"number\">0</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">0</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">0</span>], ex_ch[<span class=\"number\">0</span>], kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=strides[<span class=\"number\">0</span>], groups=ex_ch[<span class=\"number\">0</span>], bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">0</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">0</span>], channels[<span class=\"number\">1</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(channels[<span class=\"number\">1</span>])</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck2 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(channels[<span class=\"number\">1</span>], ex_ch[<span class=\"number\">1</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">1</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">1</span>], ex_ch[<span class=\"number\">1</span>], kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=strides[<span class=\"number\">1</span>], groups=ex_ch[<span class=\"number\">1</span>], bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">1</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">1</span>], channels[<span class=\"number\">2</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(channels[<span class=\"number\">2</span>])</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck3 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(channels[<span class=\"number\">2</span>], ex_ch[<span class=\"number\">2</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">2</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">2</span>], ex_ch[<span class=\"number\">2</span>], kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=strides[<span class=\"number\">2</span>], groups=ex_ch[<span class=\"number\">2</span>], bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">2</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">2</span>], channels[<span class=\"number\">3</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(channels[<span class=\"number\">3</span>])</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck4 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(channels[<span class=\"number\">3</span>], ex_ch[<span class=\"number\">3</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">3</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">3</span>], ex_ch[<span class=\"number\">3</span>], kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=strides[<span class=\"number\">3</span>], groups=ex_ch[<span class=\"number\">3</span>], bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(ex_ch[<span class=\"number\">3</span>]),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(ex_ch[<span class=\"number\">3</span>], channels[<span class=\"number\">4</span>], kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(channels[<span class=\"number\">4</span>])</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        self.last_ch = <span class=\"number\">512</span></span><br><span class=\"line\">        self.conv2 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(channels[<span class=\"number\">4</span>], self.last_ch, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>, bias=False),</span><br><span class=\"line\">            nn.BatchNorm2d(self.last_ch),</span><br><span class=\"line\">            nn.ReLU6()</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.pool1 = nn.AvgPool2d(kernel_size=<span class=\"number\">7</span>)</span><br><span class=\"line\">        self.Dense = nn.Linear(self.last_ch, <span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    def forward(self, x):</span><br><span class=\"line\">        out = self.conv1(x)</span><br><span class=\"line\">        out = self.bottleneck1(out)</span><br><span class=\"line\">        out = self.bottleneck2(out)</span><br><span class=\"line\">        out = self.bottleneck3(out)</span><br><span class=\"line\">        out = self.bottleneck4(out)</span><br><span class=\"line\">        out = self.conv2(out)</span><br><span class=\"line\">        out = self.pool1(out)</span><br><span class=\"line\">        out = out.view(<span class=\"number\">-1</span>, self.last_ch)</span><br><span class=\"line\">        out = self.Dense(out)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def get_trainloader(batch_size):</span><br><span class=\"line\">    dataset = datasets.MNIST(root=<span class=\"string\">\"./mmnist/\"</span>, train=True, download=True,</span><br><span class=\"line\">                             transform=transforms.Compose([</span><br><span class=\"line\">                                 transforms.ToTensor(),</span><br><span class=\"line\">                                 transforms.Normalize(</span><br><span class=\"line\">                                     (mnist_mean,), (mnist_std,)</span><br><span class=\"line\">                                 )</span><br><span class=\"line\">                             ]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data.DataLoader(</span><br><span class=\"line\">        dataset=dataset,</span><br><span class=\"line\">        batch_size=batch_size,</span><br><span class=\"line\">        shuffle=True,</span><br><span class=\"line\">        num_workers=<span class=\"number\">2</span>,</span><br><span class=\"line\">        pin_memory=True,</span><br><span class=\"line\">        drop_last=False,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def get_testloader(batch_size):</span><br><span class=\"line\">    dataset = datasets.MNIST(root=<span class=\"string\">\"./mmnist/\"</span>, train=False, download=True,</span><br><span class=\"line\">                             transform=transforms.Compose([</span><br><span class=\"line\">                                 transforms.ToTensor(),</span><br><span class=\"line\">                                 transforms.Normalize(</span><br><span class=\"line\">                                     (mnist_mean,), (mnist_std,)</span><br><span class=\"line\">                                 )</span><br><span class=\"line\">                             ]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data.DataLoader(</span><br><span class=\"line\">        dataset=dataset,</span><br><span class=\"line\">        batch_size=batch_size,</span><br><span class=\"line\">        shuffle=False,                   # 每个epoch是否混淆</span><br><span class=\"line\">        num_workers=2,                   # 多进程并发装载</span><br><span class=\"line\">        pin_memory=True,                 # 是否使用锁页内存</span><br><span class=\"line\">        drop_last=False,                 # 是否丢弃最后一个不完整的batch</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def train(train_data_loader, optimizer):</span><br><span class=\"line\">    epoch_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\">    epoch_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">    train_dataset_length = <span class=\"number\">0.0</span></span><br><span class=\"line\">    tot_it = len(train_data_loader)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> it, (x_train, y_train) <span class=\"keyword\">in</span> enumerate(train_data_loader):</span><br><span class=\"line\">        train_dataset_length += len(y_train)</span><br><span class=\"line\">        y_pred = model(x_train)</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss = nn.functional.cross_entropy(y_pred, y_train)</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\">        epoch_loss += loss.item()</span><br><span class=\"line\">        y_pred = torch.argmax(y_pred, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">        epoch_acc += y_pred.eq(y_train).sum().item()</span><br><span class=\"line\">        print(it)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> it % <span class=\"number\">32</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">            print(f<span class=\"string\">'it:&#123;it&#125;/&#123;tot_it&#125;, '</span></span><br><span class=\"line\">                  f<span class=\"string\">'Loss:&#123;epoch_loss&#125;/&#123;it+1&#125; = &#123;epoch_loss/(it+1)&#125;, '</span></span><br><span class=\"line\">                  f<span class=\"string\">'Acc:&#123;epoch_acc&#125;/&#123;train_dataset_length&#125; = &#123;epoch_acc/train_dataset_length&#125;'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    print(<span class=\"string\">\"train_Epoch:Loss is:&#123;:4f&#125;,Acc is:&#123;:4f&#125;\"</span>.format(epoch_loss/tot_it, epoch_acc/train_dataset_length))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def validation(test_data_loader):</span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        model.eval()</span><br><span class=\"line\">        epoch_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\">        epoch_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">        test_dataset_length = <span class=\"number\">0.0</span></span><br><span class=\"line\">        tot_it = len(test_data_loader)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> it, (x_test, y_test) <span class=\"keyword\">in</span> enumerate(test_data_loader):</span><br><span class=\"line\">            test_dataset_length += len(y_test)</span><br><span class=\"line\">            y_pred = model(x_test)</span><br><span class=\"line\">            loss = nn.functional.cross_entropy(y_pred, y_test)</span><br><span class=\"line\">            epoch_loss += loss.item()</span><br><span class=\"line\">            y_pred = torch.argmax(y_pred, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">            epoch_acc += y_pred.eq(y_test).sum().item()</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> it % <span class=\"number\">32</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">                print(f<span class=\"string\">'it:&#123;it&#125;/&#123;tot_it&#125;, '</span></span><br><span class=\"line\">                      f<span class=\"string\">'Loss:&#123;epoch_loss&#125;/&#123;it+1&#125; = &#123;epoch_loss / (it+1)&#125;, '</span></span><br><span class=\"line\">                      f<span class=\"string\">'Acc:&#123;epoch_acc&#125;/&#123;test_dataset_length&#125; = &#123;epoch_acc / test_dataset_length&#125;'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        model.train()</span><br><span class=\"line\">        print(<span class=\"string\">\"test_Epoch:Loss is:&#123;:4f&#125;,Acc is:&#123;:4f&#125;\"</span>.format(epoch_loss/tot_it, epoch_acc/test_dataset_length))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">model = Model()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def main():</span><br><span class=\"line\">    PATH = <span class=\"string\">'./Mobilenetv2.pth'</span></span><br><span class=\"line\">    # pretrained_net = torch.load(PATH)</span><br><span class=\"line\">    # model.load_state_dict(pretrained_net)</span><br><span class=\"line\">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class=\"number\">0.001</span>)</span><br><span class=\"line\">    train_data_loader = get_trainloader(<span class=\"number\">64</span>)</span><br><span class=\"line\">    test_data_loader = get_testloader(<span class=\"number\">64</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(epoch_n):</span><br><span class=\"line\">        train(train_data_loader=train_data_loader, optimizer=optimizer)</span><br><span class=\"line\">        validation(test_data_loader=test_data_loader)</span><br><span class=\"line\">    torch.save(model.state_dict(), PATH)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    main()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>"},{"title":"Mobilenetv2_第二版","date":"2020-01-29T03:26:23.000Z","_content":"\n## Mobilenet v2 第二版\n\n在这一版中，优化了数据加载类，将创建训练数据加载类，测试数据加载类，训练和测试分别写成了一个函数，有利于管理和修改，最后写main函数可以使模型多进程并发装载，加快训练速度\n<!--more-->\n\n{% codeblock lang:JavaScript %}\nimport torch\nimport torch.utils.data as data\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision as tv\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nfrom torchvision.transforms import ToPILImage\nfrom torch.autograd import Variable\nfrom torch import optim\nimport os\nimport datetime\n\nmnist_mean = 0.1307\nmnist_std = 0.3081\nepoch_n = 5\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1, stride=2)\n        self.bottleneck1 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, padding=1, stride=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU6(),\n            nn.Conv2d(32, 32, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.BatchNorm2d(32),\n            nn.ReLU6(),\n            nn.Conv2d(32, 16, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck2 = nn.Sequential(\n            nn.Conv2d(16, 64, kernel_size=3, padding=1, stride=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck3 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck4 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck5 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck6 = nn.Sequential(\n            nn.Conv2d(64, 384, kernel_size=3, padding=1, stride=1),\n            nn.BatchNorm2d(384),\n            nn.ReLU6(),\n            nn.Conv2d(384, 384, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.BatchNorm2d(384),\n            nn.ReLU6(),\n            nn.Conv2d(384, 128, kernel_size=1, padding=0, stride=1)\n        )\n        self.conv2 = nn.Conv2d(128, 512, kernel_size=1, padding=0, stride=1)\n        self.pool1 = nn.AvgPool2d(kernel_size=7)\n        self.conv3 = nn.Conv2d(512, 512, kernel_size=1, padding=0, stride=1)\n        self.Dense = nn.Linear(512, 10)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bottleneck1(out)\n        out = self.bottleneck2(out)\n        out = self.bottleneck3(out)\n        out = self.bottleneck4(out)\n        out = self.bottleneck5(out)\n        out = self.bottleneck6(out)\n        out = self.conv2(out)\n        out = self.pool1(out)\n        out = self.conv3(out)\n        out = out.view(-1, 512)\n        out = self.Dense(out)\n        return out\n\n\ndef get_trainloader(batch_size):\n    dataset = datasets.MNIST(root=\"./mmnist/\", train=True, download=True,\n                             transform=transforms.Compose([\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(\n                                     (mnist_mean,), (mnist_std,)\n                                 )\n                             ]))\n    return data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=2,\n        pin_memory=True,\n        drop_last=False,\n    )\n\n\ndef get_testloader(batch_size):\n    dataset = datasets.MNIST(root=\"./mmnist/\", train=False, download=True,\n                             transform=transforms.Compose([\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(\n                                     (mnist_mean,), (mnist_std,)\n                                 )\n                             ]))\n    return data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        shuffle=False,                   # 每个epoch是否混淆\n        num_workers=2,                   # 多进程并发装载\n        pin_memory=True,                 # 是否使用锁页内存\n        drop_last=False,                 # 是否丢弃最后一个不完整的batch\n    ), len(dataset)\n\n\ndef train(train_data_loader, optimizer):\n    for batch in train_data_loader:\n        x_train, y_train = batch\n        y_pred = model(x_train)\n        optimizer.zero_grad()\n        loss = nn.functional.cross_entropy(y_pred, y_train)\n        loss.backward()\n        optimizer.step()\n\n\ndef validation(test_data_loader, test_dataset_length):\n    with torch.no_grad():\n        model.eval()\n        epoch_acc = 0.0\n        epoch_loss = 0.0\n        for batch in test_data_loader:\n            x_test, y_test = batch\n            y_pred = model(x_test)\n            loss = nn.functional.cross_entropy(y_pred, y_test)\n            epoch_loss += loss.item()\n            y_pred = torch.argmax(y_pred, dim=1)\n            epoch_acc += y_pred.eq(y_test).sum().item()\n        epoch_loss = epoch_loss * 64 / test_dataset_length\n        epoch_acc = epoch_acc / test_dataset_length\n        print(\"Epoch:Loss is:{:4f},Acc is:{:4f}\".format(epoch_loss, epoch_acc))\n        model.train()\n\n\nmodel = Model()\n\n\ndef main():\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    train_data_loader = get_trainloader(64)\n    test_data_loader, dataset_length = get_testloader(64)\n    for epoch in range(epoch_n):\n        train(train_data_loader=train_data_loader, optimizer=optimizer)\n        validation(test_data_loader=test_data_loader, test_dataset_length=dataset_length)\n\n\nif __name__ == '__main__':\n    main()\n\n{% endcodeblock %}","source":"_posts/Mobilenetv2_第二版.md","raw":"---\ntitle: Mobilenetv2_第二版\ndate: 2020-01-29 11:26:23\ntags: [机器学习]\n---\n\n## Mobilenet v2 第二版\n\n在这一版中，优化了数据加载类，将创建训练数据加载类，测试数据加载类，训练和测试分别写成了一个函数，有利于管理和修改，最后写main函数可以使模型多进程并发装载，加快训练速度\n<!--more-->\n\n{% codeblock lang:JavaScript %}\nimport torch\nimport torch.utils.data as data\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision as tv\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nfrom torchvision.transforms import ToPILImage\nfrom torch.autograd import Variable\nfrom torch import optim\nimport os\nimport datetime\n\nmnist_mean = 0.1307\nmnist_std = 0.3081\nepoch_n = 5\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1, stride=2)\n        self.bottleneck1 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, padding=1, stride=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU6(),\n            nn.Conv2d(32, 32, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.BatchNorm2d(32),\n            nn.ReLU6(),\n            nn.Conv2d(32, 16, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck2 = nn.Sequential(\n            nn.Conv2d(16, 64, kernel_size=3, padding=1, stride=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck3 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck4 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck5 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.BatchNorm2d(64),\n            nn.ReLU6(),\n            nn.Conv2d(64, 64, kernel_size=1, padding=0, stride=1)\n        )\n        self.bottleneck6 = nn.Sequential(\n            nn.Conv2d(64, 384, kernel_size=3, padding=1, stride=1),\n            nn.BatchNorm2d(384),\n            nn.ReLU6(),\n            nn.Conv2d(384, 384, kernel_size=3, padding=1, stride=1, groups=32),\n            nn.BatchNorm2d(384),\n            nn.ReLU6(),\n            nn.Conv2d(384, 128, kernel_size=1, padding=0, stride=1)\n        )\n        self.conv2 = nn.Conv2d(128, 512, kernel_size=1, padding=0, stride=1)\n        self.pool1 = nn.AvgPool2d(kernel_size=7)\n        self.conv3 = nn.Conv2d(512, 512, kernel_size=1, padding=0, stride=1)\n        self.Dense = nn.Linear(512, 10)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bottleneck1(out)\n        out = self.bottleneck2(out)\n        out = self.bottleneck3(out)\n        out = self.bottleneck4(out)\n        out = self.bottleneck5(out)\n        out = self.bottleneck6(out)\n        out = self.conv2(out)\n        out = self.pool1(out)\n        out = self.conv3(out)\n        out = out.view(-1, 512)\n        out = self.Dense(out)\n        return out\n\n\ndef get_trainloader(batch_size):\n    dataset = datasets.MNIST(root=\"./mmnist/\", train=True, download=True,\n                             transform=transforms.Compose([\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(\n                                     (mnist_mean,), (mnist_std,)\n                                 )\n                             ]))\n    return data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=2,\n        pin_memory=True,\n        drop_last=False,\n    )\n\n\ndef get_testloader(batch_size):\n    dataset = datasets.MNIST(root=\"./mmnist/\", train=False, download=True,\n                             transform=transforms.Compose([\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(\n                                     (mnist_mean,), (mnist_std,)\n                                 )\n                             ]))\n    return data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        shuffle=False,                   # 每个epoch是否混淆\n        num_workers=2,                   # 多进程并发装载\n        pin_memory=True,                 # 是否使用锁页内存\n        drop_last=False,                 # 是否丢弃最后一个不完整的batch\n    ), len(dataset)\n\n\ndef train(train_data_loader, optimizer):\n    for batch in train_data_loader:\n        x_train, y_train = batch\n        y_pred = model(x_train)\n        optimizer.zero_grad()\n        loss = nn.functional.cross_entropy(y_pred, y_train)\n        loss.backward()\n        optimizer.step()\n\n\ndef validation(test_data_loader, test_dataset_length):\n    with torch.no_grad():\n        model.eval()\n        epoch_acc = 0.0\n        epoch_loss = 0.0\n        for batch in test_data_loader:\n            x_test, y_test = batch\n            y_pred = model(x_test)\n            loss = nn.functional.cross_entropy(y_pred, y_test)\n            epoch_loss += loss.item()\n            y_pred = torch.argmax(y_pred, dim=1)\n            epoch_acc += y_pred.eq(y_test).sum().item()\n        epoch_loss = epoch_loss * 64 / test_dataset_length\n        epoch_acc = epoch_acc / test_dataset_length\n        print(\"Epoch:Loss is:{:4f},Acc is:{:4f}\".format(epoch_loss, epoch_acc))\n        model.train()\n\n\nmodel = Model()\n\n\ndef main():\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    train_data_loader = get_trainloader(64)\n    test_data_loader, dataset_length = get_testloader(64)\n    for epoch in range(epoch_n):\n        train(train_data_loader=train_data_loader, optimizer=optimizer)\n        validation(test_data_loader=test_data_loader, test_dataset_length=dataset_length)\n\n\nif __name__ == '__main__':\n    main()\n\n{% endcodeblock %}","slug":"Mobilenetv2_第二版","published":1,"updated":"2020-01-29T11:07:16.775Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh700z0007a0uz8m47qx3o","content":"<h2 id=\"Mobilenet-v2-第二版\"><a href=\"#Mobilenet-v2-第二版\" class=\"headerlink\" title=\"Mobilenet v2 第二版\"></a>Mobilenet v2 第二版</h2><p>在这一版中，优化了数据加载类，将创建训练数据加载类，测试数据加载类，训练和测试分别写成了一个函数，有利于管理和修改，最后写main函数可以使模型多进程并发装载，加快训练速度<br><a id=\"more\"></a></p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.utils.data <span class=\"keyword\">as</span> data</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision.transforms <span class=\"keyword\">import</span> ToPILImage</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> optim</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> datetime</span><br><span class=\"line\"></span><br><span class=\"line\">mnist_mean = <span class=\"number\">0.1307</span></span><br><span class=\"line\">mnist_std = <span class=\"number\">0.3081</span></span><br><span class=\"line\">epoch_n = <span class=\"number\">5</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">class Model(nn.Module):</span><br><span class=\"line\">    def __init__(self):</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(Model, self).__init__()</span><br><span class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">2</span>)</span><br><span class=\"line\">        self.bottleneck1 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">16</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck2 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">16</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck3 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck4 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck5 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck6 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">384</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">384</span>, <span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">384</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">384</span>, <span class=\"number\">128</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">128</span>, <span class=\"number\">512</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.pool1 = nn.AvgPool2d(kernel_size=<span class=\"number\">7</span>)</span><br><span class=\"line\">        self.conv3 = nn.Conv2d(<span class=\"number\">512</span>, <span class=\"number\">512</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.Dense = nn.Linear(<span class=\"number\">512</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    def forward(self, x):</span><br><span class=\"line\">        out = self.conv1(x)</span><br><span class=\"line\">        out = self.bottleneck1(out)</span><br><span class=\"line\">        out = self.bottleneck2(out)</span><br><span class=\"line\">        out = self.bottleneck3(out)</span><br><span class=\"line\">        out = self.bottleneck4(out)</span><br><span class=\"line\">        out = self.bottleneck5(out)</span><br><span class=\"line\">        out = self.bottleneck6(out)</span><br><span class=\"line\">        out = self.conv2(out)</span><br><span class=\"line\">        out = self.pool1(out)</span><br><span class=\"line\">        out = self.conv3(out)</span><br><span class=\"line\">        out = out.view(<span class=\"number\">-1</span>, <span class=\"number\">512</span>)</span><br><span class=\"line\">        out = self.Dense(out)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def get_trainloader(batch_size):</span><br><span class=\"line\">    dataset = datasets.MNIST(root=<span class=\"string\">\"./mmnist/\"</span>, train=True, download=True,</span><br><span class=\"line\">                             transform=transforms.Compose([</span><br><span class=\"line\">                                 transforms.ToTensor(),</span><br><span class=\"line\">                                 transforms.Normalize(</span><br><span class=\"line\">                                     (mnist_mean,), (mnist_std,)</span><br><span class=\"line\">                                 )</span><br><span class=\"line\">                             ]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data.DataLoader(</span><br><span class=\"line\">        dataset=dataset,</span><br><span class=\"line\">        batch_size=batch_size,</span><br><span class=\"line\">        shuffle=True,</span><br><span class=\"line\">        num_workers=<span class=\"number\">2</span>,</span><br><span class=\"line\">        pin_memory=True,</span><br><span class=\"line\">        drop_last=False,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def get_testloader(batch_size):</span><br><span class=\"line\">    dataset = datasets.MNIST(root=<span class=\"string\">\"./mmnist/\"</span>, train=False, download=True,</span><br><span class=\"line\">                             transform=transforms.Compose([</span><br><span class=\"line\">                                 transforms.ToTensor(),</span><br><span class=\"line\">                                 transforms.Normalize(</span><br><span class=\"line\">                                     (mnist_mean,), (mnist_std,)</span><br><span class=\"line\">                                 )</span><br><span class=\"line\">                             ]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data.DataLoader(</span><br><span class=\"line\">        dataset=dataset,</span><br><span class=\"line\">        batch_size=batch_size,</span><br><span class=\"line\">        shuffle=False,                   # 每个epoch是否混淆</span><br><span class=\"line\">        num_workers=2,                   # 多进程并发装载</span><br><span class=\"line\">        pin_memory=True,                 # 是否使用锁页内存</span><br><span class=\"line\">        drop_last=False,                 # 是否丢弃最后一个不完整的batch</span><br><span class=\"line\">    ), len(dataset)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def train(train_data_loader, optimizer):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> batch <span class=\"keyword\">in</span> train_data_loader:</span><br><span class=\"line\">        x_train, y_train = batch</span><br><span class=\"line\">        y_pred = model(x_train)</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss = nn.functional.cross_entropy(y_pred, y_train)</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def validation(test_data_loader, test_dataset_length):</span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        model.eval()</span><br><span class=\"line\">        epoch_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\">        epoch_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> batch <span class=\"keyword\">in</span> test_data_loader:</span><br><span class=\"line\">            x_test, y_test = batch</span><br><span class=\"line\">            y_pred = model(x_test)</span><br><span class=\"line\">            loss = nn.functional.cross_entropy(y_pred, y_test)</span><br><span class=\"line\">            epoch_loss += loss.item()</span><br><span class=\"line\">            y_pred = torch.argmax(y_pred, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">            epoch_acc += y_pred.eq(y_test).sum().item()</span><br><span class=\"line\">        epoch_loss = epoch_loss * <span class=\"number\">64</span> / test_dataset_length</span><br><span class=\"line\">        epoch_acc = epoch_acc / test_dataset_length</span><br><span class=\"line\">        print(<span class=\"string\">\"Epoch:Loss is:&#123;:4f&#125;,Acc is:&#123;:4f&#125;\"</span>.format(epoch_loss, epoch_acc))</span><br><span class=\"line\">        model.train()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">model = Model()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def main():</span><br><span class=\"line\">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class=\"number\">0.001</span>)</span><br><span class=\"line\">    train_data_loader = get_trainloader(<span class=\"number\">64</span>)</span><br><span class=\"line\">    test_data_loader, dataset_length = get_testloader(<span class=\"number\">64</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(epoch_n):</span><br><span class=\"line\">        train(train_data_loader=train_data_loader, optimizer=optimizer)</span><br><span class=\"line\">        validation(test_data_loader=test_data_loader, test_dataset_length=dataset_length)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    main()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<h2 id=\"Mobilenet-v2-第二版\"><a href=\"#Mobilenet-v2-第二版\" class=\"headerlink\" title=\"Mobilenet v2 第二版\"></a>Mobilenet v2 第二版</h2><p>在这一版中，优化了数据加载类，将创建训练数据加载类，测试数据加载类，训练和测试分别写成了一个函数，有利于管理和修改，最后写main函数可以使模型多进程并发装载，加快训练速度<br></p>","more":"<p></p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.utils.data <span class=\"keyword\">as</span> data</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn.functional <span class=\"keyword\">as</span> F</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms, datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> torchvision.transforms <span class=\"keyword\">import</span> ToPILImage</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> optim</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> datetime</span><br><span class=\"line\"></span><br><span class=\"line\">mnist_mean = <span class=\"number\">0.1307</span></span><br><span class=\"line\">mnist_std = <span class=\"number\">0.3081</span></span><br><span class=\"line\">epoch_n = <span class=\"number\">5</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">class Model(nn.Module):</span><br><span class=\"line\">    def __init__(self):</span><br><span class=\"line\">        <span class=\"keyword\">super</span>(Model, self).__init__()</span><br><span class=\"line\">        self.conv1 = nn.Conv2d(<span class=\"number\">1</span>, <span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">2</span>)</span><br><span class=\"line\">        self.bottleneck1 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">32</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">16</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck2 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">16</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck3 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck4 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck5 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">64</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.bottleneck6 = nn.Sequential(</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">64</span>, <span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">384</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">384</span>, <span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>, stride=<span class=\"number\">1</span>, groups=<span class=\"number\">32</span>),</span><br><span class=\"line\">            nn.BatchNorm2d(<span class=\"number\">384</span>),</span><br><span class=\"line\">            nn.ReLU6(),</span><br><span class=\"line\">            nn.Conv2d(<span class=\"number\">384</span>, <span class=\"number\">128</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\">        self.conv2 = nn.Conv2d(<span class=\"number\">128</span>, <span class=\"number\">512</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.pool1 = nn.AvgPool2d(kernel_size=<span class=\"number\">7</span>)</span><br><span class=\"line\">        self.conv3 = nn.Conv2d(<span class=\"number\">512</span>, <span class=\"number\">512</span>, kernel_size=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>, stride=<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.Dense = nn.Linear(<span class=\"number\">512</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    def forward(self, x):</span><br><span class=\"line\">        out = self.conv1(x)</span><br><span class=\"line\">        out = self.bottleneck1(out)</span><br><span class=\"line\">        out = self.bottleneck2(out)</span><br><span class=\"line\">        out = self.bottleneck3(out)</span><br><span class=\"line\">        out = self.bottleneck4(out)</span><br><span class=\"line\">        out = self.bottleneck5(out)</span><br><span class=\"line\">        out = self.bottleneck6(out)</span><br><span class=\"line\">        out = self.conv2(out)</span><br><span class=\"line\">        out = self.pool1(out)</span><br><span class=\"line\">        out = self.conv3(out)</span><br><span class=\"line\">        out = out.view(<span class=\"number\">-1</span>, <span class=\"number\">512</span>)</span><br><span class=\"line\">        out = self.Dense(out)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def get_trainloader(batch_size):</span><br><span class=\"line\">    dataset = datasets.MNIST(root=<span class=\"string\">\"./mmnist/\"</span>, train=True, download=True,</span><br><span class=\"line\">                             transform=transforms.Compose([</span><br><span class=\"line\">                                 transforms.ToTensor(),</span><br><span class=\"line\">                                 transforms.Normalize(</span><br><span class=\"line\">                                     (mnist_mean,), (mnist_std,)</span><br><span class=\"line\">                                 )</span><br><span class=\"line\">                             ]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data.DataLoader(</span><br><span class=\"line\">        dataset=dataset,</span><br><span class=\"line\">        batch_size=batch_size,</span><br><span class=\"line\">        shuffle=True,</span><br><span class=\"line\">        num_workers=<span class=\"number\">2</span>,</span><br><span class=\"line\">        pin_memory=True,</span><br><span class=\"line\">        drop_last=False,</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def get_testloader(batch_size):</span><br><span class=\"line\">    dataset = datasets.MNIST(root=<span class=\"string\">\"./mmnist/\"</span>, train=False, download=True,</span><br><span class=\"line\">                             transform=transforms.Compose([</span><br><span class=\"line\">                                 transforms.ToTensor(),</span><br><span class=\"line\">                                 transforms.Normalize(</span><br><span class=\"line\">                                     (mnist_mean,), (mnist_std,)</span><br><span class=\"line\">                                 )</span><br><span class=\"line\">                             ]))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data.DataLoader(</span><br><span class=\"line\">        dataset=dataset,</span><br><span class=\"line\">        batch_size=batch_size,</span><br><span class=\"line\">        shuffle=False,                   # 每个epoch是否混淆</span><br><span class=\"line\">        num_workers=2,                   # 多进程并发装载</span><br><span class=\"line\">        pin_memory=True,                 # 是否使用锁页内存</span><br><span class=\"line\">        drop_last=False,                 # 是否丢弃最后一个不完整的batch</span><br><span class=\"line\">    ), len(dataset)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def train(train_data_loader, optimizer):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> batch <span class=\"keyword\">in</span> train_data_loader:</span><br><span class=\"line\">        x_train, y_train = batch</span><br><span class=\"line\">        y_pred = model(x_train)</span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        loss = nn.functional.cross_entropy(y_pred, y_train)</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def validation(test_data_loader, test_dataset_length):</span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        model.eval()</span><br><span class=\"line\">        epoch_acc = <span class=\"number\">0.0</span></span><br><span class=\"line\">        epoch_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> batch <span class=\"keyword\">in</span> test_data_loader:</span><br><span class=\"line\">            x_test, y_test = batch</span><br><span class=\"line\">            y_pred = model(x_test)</span><br><span class=\"line\">            loss = nn.functional.cross_entropy(y_pred, y_test)</span><br><span class=\"line\">            epoch_loss += loss.item()</span><br><span class=\"line\">            y_pred = torch.argmax(y_pred, dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">            epoch_acc += y_pred.eq(y_test).sum().item()</span><br><span class=\"line\">        epoch_loss = epoch_loss * <span class=\"number\">64</span> / test_dataset_length</span><br><span class=\"line\">        epoch_acc = epoch_acc / test_dataset_length</span><br><span class=\"line\">        print(<span class=\"string\">\"Epoch:Loss is:&#123;:4f&#125;,Acc is:&#123;:4f&#125;\"</span>.format(epoch_loss, epoch_acc))</span><br><span class=\"line\">        model.train()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">model = Model()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">def main():</span><br><span class=\"line\">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class=\"number\">0.001</span>)</span><br><span class=\"line\">    train_data_loader = get_trainloader(<span class=\"number\">64</span>)</span><br><span class=\"line\">    test_data_loader, dataset_length = get_testloader(<span class=\"number\">64</span>)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(epoch_n):</span><br><span class=\"line\">        train(train_data_loader=train_data_loader, optimizer=optimizer)</span><br><span class=\"line\">        validation(test_data_loader=test_data_loader, test_dataset_length=dataset_length)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    main()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>"},{"title":"git操作","date":"2020-01-30T05:08:33.000Z","_content":"\n## the first step\n\n进入用git管理的文件夹中 cd\n添加用户名 user.name 和用户email user.email:\ngit config --global user.name '你的用户名'\ngit config --global user.email '你的邮箱'\n\n### 创建版本库\n\ngit init\n\n### 查看当前文件夹中的所有文件\n\nls           要想查看被隐藏的文件，使用  ls -a\n\n### 建立一个新的名为 \"1.py\" 的文件\n\ntouch 1.py\n\n### \n\n","source":"_posts/git操作.md","raw":"---\ntitle: git操作\ndate: 2020-01-30 13:08:33\ntags:\n---\n\n## the first step\n\n进入用git管理的文件夹中 cd\n添加用户名 user.name 和用户email user.email:\ngit config --global user.name '你的用户名'\ngit config --global user.email '你的邮箱'\n\n### 创建版本库\n\ngit init\n\n### 查看当前文件夹中的所有文件\n\nls           要想查看被隐藏的文件，使用  ls -a\n\n### 建立一个新的名为 \"1.py\" 的文件\n\ntouch 1.py\n\n### \n\n","slug":"git操作","published":1,"updated":"2020-09-07T01:33:11.956Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh70110008a0uzss9oqbq6","content":"<h2 id=\"the-first-step\"><a href=\"#the-first-step\" class=\"headerlink\" title=\"the first step\"></a>the first step</h2><p>进入用git管理的文件夹中 cd<br>添加用户名 user.name 和用户email user.email:<br>git config —global user.name ‘你的用户名’<br>git config —global user.email ‘你的邮箱’</p>\n<h3 id=\"创建版本库\"><a href=\"#创建版本库\" class=\"headerlink\" title=\"创建版本库\"></a>创建版本库</h3><p>git init</p>\n<h3 id=\"查看当前文件夹中的所有文件\"><a href=\"#查看当前文件夹中的所有文件\" class=\"headerlink\" title=\"查看当前文件夹中的所有文件\"></a>查看当前文件夹中的所有文件</h3><p>ls           要想查看被隐藏的文件，使用  ls -a</p>\n<h3 id=\"建立一个新的名为-“1-py”-的文件\"><a href=\"#建立一个新的名为-“1-py”-的文件\" class=\"headerlink\" title=\"建立一个新的名为 “1.py” 的文件\"></a>建立一个新的名为 “1.py” 的文件</h3><p>touch 1.py</p>\n<h3 id><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h3>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"the-first-step\"><a href=\"#the-first-step\" class=\"headerlink\" title=\"the first step\"></a>the first step</h2><p>进入用git管理的文件夹中 cd<br>添加用户名 user.name 和用户email user.email:<br>git config —global user.name ‘你的用户名’<br>git config —global user.email ‘你的邮箱’</p>\n<h3 id=\"创建版本库\"><a href=\"#创建版本库\" class=\"headerlink\" title=\"创建版本库\"></a>创建版本库</h3><p>git init</p>\n<h3 id=\"查看当前文件夹中的所有文件\"><a href=\"#查看当前文件夹中的所有文件\" class=\"headerlink\" title=\"查看当前文件夹中的所有文件\"></a>查看当前文件夹中的所有文件</h3><p>ls           要想查看被隐藏的文件，使用  ls -a</p>\n<h3 id=\"建立一个新的名为-“1-py”-的文件\"><a href=\"#建立一个新的名为-“1-py”-的文件\" class=\"headerlink\" title=\"建立一个新的名为 “1.py” 的文件\"></a>建立一个新的名为 “1.py” 的文件</h3><p>touch 1.py</p>\n<h3 id><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h3>"},{"title":"STL容器的总结","date":"2019-09-29T06:58:49.000Z","_content":"\n# 什么是 STL\n\nSTL 是 standard template library 的简写，是标准模板库\nSTL 里面有许多容器和函数，可以让我们快速的写出一些的数据结构或者实现一些功能\nSTL 真的太棒了~~~\n在此篇文章里，我记录了部分容器的使用方法\n对于函数的使用，将会在下一篇中记录\n\n<!--more-->\n## STL -- vector\n\n### 解释\n\nvector 是一个数组的模板\n\n### 用法\n\n{% codeblock lang:JavaScript %}\nvector <int> v;\nvector <int> v1(v);\nv.push_back(value); //在尾部加入一个数据\nv.pop_back();  //删除最后一个数据\nv.clear();     //清除容器中所有数据\nv.empty();     //判断容器是否为空\nv.size();      //返回容器中实际数据的个数\nv[a].swap(v[b])//交换元素\nv.begin();     //返回第一个元素的地址\nv.front();     //返回第一个元素的值\nv.end();       //返回最后一个元素的地址\nv.back();      //返回最后一个元素的值\nv.erase(pos)  v.erase(begin,end)\nv.insert(pos,value)\nv.insert(pos,n,value)\n{% endcodeblock %}\n\n## STL -- queue/priority_queue/stack\n\n### 解释\n\nqueue 是一个队列的模板\npriority_queue 是一个优先队列的模板\nstack 是一个栈的模板\n\n### 用法\n\n{% codeblock lang:JavaScript %}\nqueue <int> q;  stack <int> q;\nq.push(x);\nq.pop();\nq.top();\nq.front();\nq.back();\nq.empty();\nq.size();\n{% endcodeblock %}\n\n### 优先队列 -- priority_queue\n\n{% codeblock lang:JavaScript %}\npriority_queue <int> q;\npriority_queue <int,vector <int>，greater <int>> q;\n用法同queue\n{% endcodeblock %}\n\n## STL -- list\n\n### 解释\n\nlist 是一个双向链表的模板\n\n### 用法\n\n{% codeblock lang:JavaScript %}\n begin()和end()\n front()和back()\n push_back() 和push_front()\n empty()\n clear()\n insert(pos,num)\n erase(pos)\n sort()                  //将链表排序，默认升序\n remove(num)             //删除链表中匹配num的元素。\n reverse()               // 逆置list\n merge()   l1.merge(l2)  //合并两个链表，合并后l1拥有l1和l2的元素，默认升序排列\n{% endcodeblock %}\n\n## STL -- set\n\n### 解释\n\nset 是一个红黑树（一种平衡树）的模板，自带去重效果\n\n### 用法\n\n{% codeblock lang:JavaScript %}\nbegin()     　　 //返回set容器的第一个元素\nend() 　　　　 //返回set容器的最后一个元素\nclear()   　　     //删除set容器中的所有的元素\nempty() 　　　//判断set容器是否为空\nmax_size() 　 //返回set容器可能包含的元素最大个数\nsize() 　　　　//返回当前set容器中的元素个数\nfind(x)        //返回x的地址，若没有则返回end()\n{% endcodeblock %}\n\n## STL -- map\n\n### 解释\n\nmap 提供的是一种键值对容器，里面的数据都是成对出现的, 每一对中的第一个值称之为关键字(key)，每个关键字只能在map中出现一次；第二个称之为该关键字的对应值。\n\n### 方法\n\n{% codeblock lang:JavaScript %}\nmap <int, string> ID_Name;  // 即一个 ID 对应一个名字，其中 ID 为 int 类型，名字为 string 类型\n\n// 使用{}赋值是从c++11开始的，因此编译器版本过低时会报错，如visual studio 2012\nmap <int, string> ID_Name = {\n                { 2015, \"Jim\" },\n                { 2016, \"Tom\" },\n                { 2017, \"Bob\" } };\n插入：\n    使用[ ]进行单个插入，ID_Name[2015] = \"Tom\";  // 如果已经存在键值2015，则会作赋值修改操作，如果没有则插入（2015不是数组下标\n    // 插入单个值\n    mymap.insert(std::pair<char, int>('a', 100));\n    // 列表形式插入\n    anothermap.insert({ { 'd', 100 }, {'e', 200} });\n取值：\n    Map中元素取值主要有at和[ ]两种操作，at会作下标检查，而[]不会。\n容量查询：\n    // 查询map是否为空\n    bool empty();\n\n    // 查询map中键值对的数量\n    size_t size();\n\n    // 查询map所能包含的最大键值对数量，和系统和应用库有关。\n    // 此外，这并不意味着用户一定可以存这么多，很可能还没达到就已经开辟内存失败了\n    size_t max_size();\n\n    // 查询关键字为key的元素的个数，在map里结果非0即1\n    size_t count( const Key& key ) const;       // 例：map.count(\"a\")\n删除：\n    // 删除迭代器指向位置的键值对，并返回一个指向下一元素的迭代器\n    iterator erase( iterator pos )\n\n    // 删除一定范围内的元素，并返回一个指向下一元素的迭代器\n    iterator erase( const_iterator first, const_iterator last );\n\n    // 根据Key来进行删除， 返回删除的元素数量，在map里结果非0即1\n    size_t erase( const key_type& key );\n\n    // 清空map，清空后的size为0\n    void clear();\n查找：\n    // 关键字查询，找到则返回指向该关键字的迭代器，否则返回指向end的迭代器\n    // 根据map的类型，返回的迭代器为 iterator 或者 const_iterator\n    iterator find (const key_type& k);\n    const_iterator find (const key_type& k) const;\n{% endcodeblock %}\n\n## STL -- pair\n\n### 解释\n\npair 是一个储存键值对的容器\n\n### 用法\n\n{% codeblock lang:JavaScript %}\npair <string,double> product1 (\"tomatoes\",3.25);\npair <string,double> product2;\npair <string,double> product3;\n \nproduct2.first =\"lightbulbs\"; // type of first is string\nproduct2.second =0.99; // type of second is double\n \nproduct3 = make_pair (\"shoes\",20.0);\n{% endcodeblock %}\n\n## STL -- iterator\n\n### 解释\n\niterator 是迭代器    可以用来接收容器的地址，如 begin(),end() 等的返回值\n\n### 用法\n\n{% codeblock lang:JavaScript %}\nvector <int> v;\nvector <int>::iterator it;\nwhile(it = v.begin(); it != v.end(); it++)\n{\n    //进行操作\n}\n{% endcodeblock %}\n\n## 特殊说明\n\n若在容器中存放结构，例如：\nstruct edge{\n    int v,w;\n}e;\n应该如此：vector <edge> v;   注意尖括号内应为结构原来的名称\n\n此外，若容器为 set 容器，则结构中必须重载小于号，若 set <edge,greater <int> >，则要重载大于号\nset 中只能有两个参数，vector <int>和 greater <int> 不能同时写进去，而 priority_queue 可以","source":"_posts/STL容器的总结.md","raw":"---\ntitle: STL容器的总结\ndate: 2019-09-29 14:58:49\ntags:\n    - STL\n---\n\n# 什么是 STL\n\nSTL 是 standard template library 的简写，是标准模板库\nSTL 里面有许多容器和函数，可以让我们快速的写出一些的数据结构或者实现一些功能\nSTL 真的太棒了~~~\n在此篇文章里，我记录了部分容器的使用方法\n对于函数的使用，将会在下一篇中记录\n\n<!--more-->\n## STL -- vector\n\n### 解释\n\nvector 是一个数组的模板\n\n### 用法\n\n{% codeblock lang:JavaScript %}\nvector <int> v;\nvector <int> v1(v);\nv.push_back(value); //在尾部加入一个数据\nv.pop_back();  //删除最后一个数据\nv.clear();     //清除容器中所有数据\nv.empty();     //判断容器是否为空\nv.size();      //返回容器中实际数据的个数\nv[a].swap(v[b])//交换元素\nv.begin();     //返回第一个元素的地址\nv.front();     //返回第一个元素的值\nv.end();       //返回最后一个元素的地址\nv.back();      //返回最后一个元素的值\nv.erase(pos)  v.erase(begin,end)\nv.insert(pos,value)\nv.insert(pos,n,value)\n{% endcodeblock %}\n\n## STL -- queue/priority_queue/stack\n\n### 解释\n\nqueue 是一个队列的模板\npriority_queue 是一个优先队列的模板\nstack 是一个栈的模板\n\n### 用法\n\n{% codeblock lang:JavaScript %}\nqueue <int> q;  stack <int> q;\nq.push(x);\nq.pop();\nq.top();\nq.front();\nq.back();\nq.empty();\nq.size();\n{% endcodeblock %}\n\n### 优先队列 -- priority_queue\n\n{% codeblock lang:JavaScript %}\npriority_queue <int> q;\npriority_queue <int,vector <int>，greater <int>> q;\n用法同queue\n{% endcodeblock %}\n\n## STL -- list\n\n### 解释\n\nlist 是一个双向链表的模板\n\n### 用法\n\n{% codeblock lang:JavaScript %}\n begin()和end()\n front()和back()\n push_back() 和push_front()\n empty()\n clear()\n insert(pos,num)\n erase(pos)\n sort()                  //将链表排序，默认升序\n remove(num)             //删除链表中匹配num的元素。\n reverse()               // 逆置list\n merge()   l1.merge(l2)  //合并两个链表，合并后l1拥有l1和l2的元素，默认升序排列\n{% endcodeblock %}\n\n## STL -- set\n\n### 解释\n\nset 是一个红黑树（一种平衡树）的模板，自带去重效果\n\n### 用法\n\n{% codeblock lang:JavaScript %}\nbegin()     　　 //返回set容器的第一个元素\nend() 　　　　 //返回set容器的最后一个元素\nclear()   　　     //删除set容器中的所有的元素\nempty() 　　　//判断set容器是否为空\nmax_size() 　 //返回set容器可能包含的元素最大个数\nsize() 　　　　//返回当前set容器中的元素个数\nfind(x)        //返回x的地址，若没有则返回end()\n{% endcodeblock %}\n\n## STL -- map\n\n### 解释\n\nmap 提供的是一种键值对容器，里面的数据都是成对出现的, 每一对中的第一个值称之为关键字(key)，每个关键字只能在map中出现一次；第二个称之为该关键字的对应值。\n\n### 方法\n\n{% codeblock lang:JavaScript %}\nmap <int, string> ID_Name;  // 即一个 ID 对应一个名字，其中 ID 为 int 类型，名字为 string 类型\n\n// 使用{}赋值是从c++11开始的，因此编译器版本过低时会报错，如visual studio 2012\nmap <int, string> ID_Name = {\n                { 2015, \"Jim\" },\n                { 2016, \"Tom\" },\n                { 2017, \"Bob\" } };\n插入：\n    使用[ ]进行单个插入，ID_Name[2015] = \"Tom\";  // 如果已经存在键值2015，则会作赋值修改操作，如果没有则插入（2015不是数组下标\n    // 插入单个值\n    mymap.insert(std::pair<char, int>('a', 100));\n    // 列表形式插入\n    anothermap.insert({ { 'd', 100 }, {'e', 200} });\n取值：\n    Map中元素取值主要有at和[ ]两种操作，at会作下标检查，而[]不会。\n容量查询：\n    // 查询map是否为空\n    bool empty();\n\n    // 查询map中键值对的数量\n    size_t size();\n\n    // 查询map所能包含的最大键值对数量，和系统和应用库有关。\n    // 此外，这并不意味着用户一定可以存这么多，很可能还没达到就已经开辟内存失败了\n    size_t max_size();\n\n    // 查询关键字为key的元素的个数，在map里结果非0即1\n    size_t count( const Key& key ) const;       // 例：map.count(\"a\")\n删除：\n    // 删除迭代器指向位置的键值对，并返回一个指向下一元素的迭代器\n    iterator erase( iterator pos )\n\n    // 删除一定范围内的元素，并返回一个指向下一元素的迭代器\n    iterator erase( const_iterator first, const_iterator last );\n\n    // 根据Key来进行删除， 返回删除的元素数量，在map里结果非0即1\n    size_t erase( const key_type& key );\n\n    // 清空map，清空后的size为0\n    void clear();\n查找：\n    // 关键字查询，找到则返回指向该关键字的迭代器，否则返回指向end的迭代器\n    // 根据map的类型，返回的迭代器为 iterator 或者 const_iterator\n    iterator find (const key_type& k);\n    const_iterator find (const key_type& k) const;\n{% endcodeblock %}\n\n## STL -- pair\n\n### 解释\n\npair 是一个储存键值对的容器\n\n### 用法\n\n{% codeblock lang:JavaScript %}\npair <string,double> product1 (\"tomatoes\",3.25);\npair <string,double> product2;\npair <string,double> product3;\n \nproduct2.first =\"lightbulbs\"; // type of first is string\nproduct2.second =0.99; // type of second is double\n \nproduct3 = make_pair (\"shoes\",20.0);\n{% endcodeblock %}\n\n## STL -- iterator\n\n### 解释\n\niterator 是迭代器    可以用来接收容器的地址，如 begin(),end() 等的返回值\n\n### 用法\n\n{% codeblock lang:JavaScript %}\nvector <int> v;\nvector <int>::iterator it;\nwhile(it = v.begin(); it != v.end(); it++)\n{\n    //进行操作\n}\n{% endcodeblock %}\n\n## 特殊说明\n\n若在容器中存放结构，例如：\nstruct edge{\n    int v,w;\n}e;\n应该如此：vector <edge> v;   注意尖括号内应为结构原来的名称\n\n此外，若容器为 set 容器，则结构中必须重载小于号，若 set <edge,greater <int> >，则要重载大于号\nset 中只能有两个参数，vector <int>和 greater <int> 不能同时写进去，而 priority_queue 可以","slug":"STL容器的总结","published":1,"updated":"2020-09-07T01:33:09.319Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh7013000aa0uzw85g9maf","content":"<h1 id=\"什么是-STL\"><a href=\"#什么是-STL\" class=\"headerlink\" title=\"什么是 STL\"></a>什么是 STL</h1><p>STL 是 standard template library 的简写，是标准模板库<br>STL 里面有许多容器和函数，可以让我们快速的写出一些的数据结构或者实现一些功能<br>STL 真的太棒了~~~<br>在此篇文章里，我记录了部分容器的使用方法<br>对于函数的使用，将会在下一篇中记录</p>\n<a id=\"more\"></a>\n<h2 id=\"STL-—-vector\"><a href=\"#STL-—-vector\" class=\"headerlink\" title=\"STL — vector\"></a>STL — vector</h2><h3 id=\"解释\"><a href=\"#解释\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>vector 是一个数组的模板</p>\n<h3 id=\"用法\"><a href=\"#用法\" class=\"headerlink\" title=\"用法\"></a>用法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vector &lt;int&gt; v;</span><br><span class=\"line\">vector &lt;int&gt; v1(v);</span><br><span class=\"line\">v.push_back(value); <span class=\"comment\">//在尾部加入一个数据</span></span><br><span class=\"line\">v.pop_back();  <span class=\"comment\">//删除最后一个数据</span></span><br><span class=\"line\">v.clear();     <span class=\"comment\">//清除容器中所有数据</span></span><br><span class=\"line\">v.empty();     <span class=\"comment\">//判断容器是否为空</span></span><br><span class=\"line\">v.size();      <span class=\"comment\">//返回容器中实际数据的个数</span></span><br><span class=\"line\">v[a].swap(v[b])<span class=\"comment\">//交换元素</span></span><br><span class=\"line\">v.begin();     <span class=\"comment\">//返回第一个元素的地址</span></span><br><span class=\"line\">v.front();     <span class=\"comment\">//返回第一个元素的值</span></span><br><span class=\"line\">v.end();       <span class=\"comment\">//返回最后一个元素的地址</span></span><br><span class=\"line\">v.back();      <span class=\"comment\">//返回最后一个元素的值</span></span><br><span class=\"line\">v.erase(pos)  v.erase(begin,end)</span><br><span class=\"line\">v.insert(pos,value)</span><br><span class=\"line\">v.insert(pos,n,value)</span><br></pre></td></tr></table></figure>\n<h2 id=\"STL-—-queue-priority-queue-stack\"><a href=\"#STL-—-queue-priority-queue-stack\" class=\"headerlink\" title=\"STL — queue/priority_queue/stack\"></a>STL — queue/priority_queue/stack</h2><h3 id=\"解释-1\"><a href=\"#解释-1\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>queue 是一个队列的模板<br>priority_queue 是一个优先队列的模板<br>stack 是一个栈的模板</p>\n<h3 id=\"用法-1\"><a href=\"#用法-1\" class=\"headerlink\" title=\"用法\"></a>用法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">queue &lt;int&gt; q;  stack &lt;int&gt; q;</span><br><span class=\"line\">q.push(x);</span><br><span class=\"line\">q.pop();</span><br><span class=\"line\">q.top();</span><br><span class=\"line\">q.front();</span><br><span class=\"line\">q.back();</span><br><span class=\"line\">q.empty();</span><br><span class=\"line\">q.size();</span><br></pre></td></tr></table></figure>\n<h3 id=\"优先队列-—-priority-queue\"><a href=\"#优先队列-—-priority-queue\" class=\"headerlink\" title=\"优先队列 — priority_queue\"></a>优先队列 — priority_queue</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">priority_queue &lt;int&gt; q;</span><br><span class=\"line\">priority_queue &lt;int,vector &lt;int&gt;，greater &lt;int&gt;&gt; q;</span><br><span class=\"line\">用法同queue</span><br></pre></td></tr></table></figure>\n<h2 id=\"STL-—-list\"><a href=\"#STL-—-list\" class=\"headerlink\" title=\"STL — list\"></a>STL — list</h2><h3 id=\"解释-2\"><a href=\"#解释-2\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>list 是一个双向链表的模板</p>\n<h3 id=\"用法-2\"><a href=\"#用法-2\" class=\"headerlink\" title=\"用法\"></a>用法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">begin()和end()</span><br><span class=\"line\">front()和back()</span><br><span class=\"line\">push_back() 和push_front()</span><br><span class=\"line\">empty()</span><br><span class=\"line\">clear()</span><br><span class=\"line\">insert(pos,num)</span><br><span class=\"line\">erase(pos)</span><br><span class=\"line\">sort()                  <span class=\"comment\">//将链表排序，默认升序</span></span><br><span class=\"line\">remove(num)             <span class=\"comment\">//删除链表中匹配num的元素。</span></span><br><span class=\"line\">reverse()               <span class=\"comment\">// 逆置list</span></span><br><span class=\"line\">merge()   l1.merge(l2)  <span class=\"comment\">//合并两个链表，合并后l1拥有l1和l2的元素，默认升序排列</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"STL-—-set\"><a href=\"#STL-—-set\" class=\"headerlink\" title=\"STL — set\"></a>STL — set</h2><h3 id=\"解释-3\"><a href=\"#解释-3\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>set 是一个红黑树（一种平衡树）的模板，自带去重效果</p>\n<h3 id=\"用法-3\"><a href=\"#用法-3\" class=\"headerlink\" title=\"用法\"></a>用法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">begin()     　　 <span class=\"comment\">//返回set容器的第一个元素</span></span><br><span class=\"line\">end() 　　　　 <span class=\"comment\">//返回set容器的最后一个元素</span></span><br><span class=\"line\">clear()   　　     <span class=\"comment\">//删除set容器中的所有的元素</span></span><br><span class=\"line\">empty() 　　　<span class=\"comment\">//判断set容器是否为空</span></span><br><span class=\"line\">max_size() 　 <span class=\"comment\">//返回set容器可能包含的元素最大个数</span></span><br><span class=\"line\">size() 　　　　<span class=\"comment\">//返回当前set容器中的元素个数</span></span><br><span class=\"line\">find(x)        <span class=\"comment\">//返回x的地址，若没有则返回end()</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"STL-—-map\"><a href=\"#STL-—-map\" class=\"headerlink\" title=\"STL — map\"></a>STL — map</h2><h3 id=\"解释-4\"><a href=\"#解释-4\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>map 提供的是一种键值对容器，里面的数据都是成对出现的, 每一对中的第一个值称之为关键字(key)，每个关键字只能在map中出现一次；第二个称之为该关键字的对应值。</p>\n<h3 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">map &lt;int, string&gt; ID_Name;  <span class=\"comment\">// 即一个 ID 对应一个名字，其中 ID 为 int 类型，名字为 string 类型</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 使用&#123;&#125;赋值是从c++11开始的，因此编译器版本过低时会报错，如visual studio 2012</span></span><br><span class=\"line\">map &lt;int, string&gt; ID_Name = &#123;</span><br><span class=\"line\">                &#123; <span class=\"number\">2015</span>, <span class=\"string\">\"Jim\"</span> &#125;,</span><br><span class=\"line\">                &#123; <span class=\"number\">2016</span>, <span class=\"string\">\"Tom\"</span> &#125;,</span><br><span class=\"line\">                &#123; <span class=\"number\">2017</span>, <span class=\"string\">\"Bob\"</span> &#125; &#125;;</span><br><span class=\"line\">插入：</span><br><span class=\"line\">    使用[ ]进行单个插入，ID_Name[<span class=\"number\">2015</span>] = <span class=\"string\">\"Tom\"</span>;  <span class=\"comment\">// 如果已经存在键值2015，则会作赋值修改操作，如果没有则插入（2015不是数组下标</span></span><br><span class=\"line\">    <span class=\"comment\">// 插入单个值</span></span><br><span class=\"line\">    mymap.insert(std::pair&lt;char, int&gt;(<span class=\"string\">'a'</span>, <span class=\"number\">100</span>));</span><br><span class=\"line\">    <span class=\"comment\">// 列表形式插入</span></span><br><span class=\"line\">    anothermap.insert(&#123; &#123; <span class=\"string\">'d'</span>, <span class=\"number\">100</span> &#125;, &#123;<span class=\"string\">'e'</span>, <span class=\"number\">200</span>&#125; &#125;);</span><br><span class=\"line\">取值：</span><br><span class=\"line\">    <span class=\"built_in\">Map</span>中元素取值主要有at和[ ]两种操作，at会作下标检查，而[]不会。</span><br><span class=\"line\">容量查询：</span><br><span class=\"line\">    <span class=\"comment\">// 查询map是否为空</span></span><br><span class=\"line\">    bool empty();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 查询map中键值对的数量</span></span><br><span class=\"line\">    size_t size();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 查询map所能包含的最大键值对数量，和系统和应用库有关。</span></span><br><span class=\"line\">    <span class=\"comment\">// 此外，这并不意味着用户一定可以存这么多，很可能还没达到就已经开辟内存失败了</span></span><br><span class=\"line\">    size_t max_size();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 查询关键字为key的元素的个数，在map里结果非0即1</span></span><br><span class=\"line\">    size_t count( <span class=\"keyword\">const</span> Key&amp; key ) <span class=\"keyword\">const</span>;       <span class=\"comment\">// 例：map.count(\"a\")</span></span><br><span class=\"line\">删除：</span><br><span class=\"line\">    <span class=\"comment\">// 删除迭代器指向位置的键值对，并返回一个指向下一元素的迭代器</span></span><br><span class=\"line\">    iterator erase( iterator pos )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 删除一定范围内的元素，并返回一个指向下一元素的迭代器</span></span><br><span class=\"line\">    iterator erase( const_iterator first, const_iterator last );</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 根据Key来进行删除， 返回删除的元素数量，在map里结果非0即1</span></span><br><span class=\"line\">    size_t erase( <span class=\"keyword\">const</span> key_type&amp; key );</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 清空map，清空后的size为0</span></span><br><span class=\"line\">    <span class=\"keyword\">void</span> clear();</span><br><span class=\"line\">查找：</span><br><span class=\"line\">    <span class=\"comment\">// 关键字查询，找到则返回指向该关键字的迭代器，否则返回指向end的迭代器</span></span><br><span class=\"line\">    <span class=\"comment\">// 根据map的类型，返回的迭代器为 iterator 或者 const_iterator</span></span><br><span class=\"line\">    iterator find (<span class=\"keyword\">const</span> key_type&amp; k);</span><br><span class=\"line\">    const_iterator find (<span class=\"keyword\">const</span> key_type&amp; k) <span class=\"keyword\">const</span>;</span><br></pre></td></tr></table></figure>\n<h2 id=\"STL-—-pair\"><a href=\"#STL-—-pair\" class=\"headerlink\" title=\"STL — pair\"></a>STL — pair</h2><h3 id=\"解释-5\"><a href=\"#解释-5\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>pair 是一个储存键值对的容器</p>\n<h3 id=\"用法-4\"><a href=\"#用法-4\" class=\"headerlink\" title=\"用法\"></a>用法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pair &lt;string,double&gt; product1 (<span class=\"string\">\"tomatoes\"</span>,<span class=\"number\">3.25</span>);</span><br><span class=\"line\">pair &lt;string,double&gt; product2;</span><br><span class=\"line\">pair &lt;string,double&gt; product3;</span><br><span class=\"line\"> </span><br><span class=\"line\">product2.first =<span class=\"string\">\"lightbulbs\"</span>; <span class=\"comment\">// type of first is string</span></span><br><span class=\"line\">product2.second =<span class=\"number\">0.99</span>; <span class=\"comment\">// type of second is double</span></span><br><span class=\"line\"> </span><br><span class=\"line\">product3 = make_pair (<span class=\"string\">\"shoes\"</span>,<span class=\"number\">20.0</span>);</span><br></pre></td></tr></table></figure>\n<h2 id=\"STL-—-iterator\"><a href=\"#STL-—-iterator\" class=\"headerlink\" title=\"STL — iterator\"></a>STL — iterator</h2><h3 id=\"解释-6\"><a href=\"#解释-6\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>iterator 是迭代器    可以用来接收容器的地址，如 begin(),end() 等的返回值</p>\n<h3 id=\"用法-5\"><a href=\"#用法-5\" class=\"headerlink\" title=\"用法\"></a>用法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vector &lt;int&gt; v;</span><br><span class=\"line\">vector &lt;int&gt;::iterator it;</span><br><span class=\"line\"><span class=\"keyword\">while</span>(it = v.begin(); it != v.end(); it++)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">//进行操作</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"特殊说明\"><a href=\"#特殊说明\" class=\"headerlink\" title=\"特殊说明\"></a>特殊说明</h2><p>若在容器中存放结构，例如：<br>struct edge{<br>    int v,w;<br>}e;<br>应该如此：vector <edge> v;   注意尖括号内应为结构原来的名称</edge></p>\n<p>此外，若容器为 set 容器，则结构中必须重载小于号，若 set <edge,greater <int> &gt;，则要重载大于号<br>set 中只能有两个参数，vector <int>和 greater <int> 不能同时写进去，而 priority_queue 可以</int></int></edge,greater></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"什么是-STL\"><a href=\"#什么是-STL\" class=\"headerlink\" title=\"什么是 STL\"></a>什么是 STL</h1><p>STL 是 standard template library 的简写，是标准模板库<br>STL 里面有许多容器和函数，可以让我们快速的写出一些的数据结构或者实现一些功能<br>STL 真的太棒了~~~<br>在此篇文章里，我记录了部分容器的使用方法<br>对于函数的使用，将会在下一篇中记录</p>","more":"<h2 id=\"STL-—-vector\"><a href=\"#STL-—-vector\" class=\"headerlink\" title=\"STL — vector\"></a>STL — vector</h2><h3 id=\"解释\"><a href=\"#解释\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>vector 是一个数组的模板</p>\n<h3 id=\"用法\"><a href=\"#用法\" class=\"headerlink\" title=\"用法\"></a>用法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vector &lt;int&gt; v;</span><br><span class=\"line\">vector &lt;int&gt; v1(v);</span><br><span class=\"line\">v.push_back(value); <span class=\"comment\">//在尾部加入一个数据</span></span><br><span class=\"line\">v.pop_back();  <span class=\"comment\">//删除最后一个数据</span></span><br><span class=\"line\">v.clear();     <span class=\"comment\">//清除容器中所有数据</span></span><br><span class=\"line\">v.empty();     <span class=\"comment\">//判断容器是否为空</span></span><br><span class=\"line\">v.size();      <span class=\"comment\">//返回容器中实际数据的个数</span></span><br><span class=\"line\">v[a].swap(v[b])<span class=\"comment\">//交换元素</span></span><br><span class=\"line\">v.begin();     <span class=\"comment\">//返回第一个元素的地址</span></span><br><span class=\"line\">v.front();     <span class=\"comment\">//返回第一个元素的值</span></span><br><span class=\"line\">v.end();       <span class=\"comment\">//返回最后一个元素的地址</span></span><br><span class=\"line\">v.back();      <span class=\"comment\">//返回最后一个元素的值</span></span><br><span class=\"line\">v.erase(pos)  v.erase(begin,end)</span><br><span class=\"line\">v.insert(pos,value)</span><br><span class=\"line\">v.insert(pos,n,value)</span><br></pre></td></tr></table></figure>\n<h2 id=\"STL-—-queue-priority-queue-stack\"><a href=\"#STL-—-queue-priority-queue-stack\" class=\"headerlink\" title=\"STL — queue/priority_queue/stack\"></a>STL — queue/priority_queue/stack</h2><h3 id=\"解释-1\"><a href=\"#解释-1\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>queue 是一个队列的模板<br>priority_queue 是一个优先队列的模板<br>stack 是一个栈的模板</p>\n<h3 id=\"用法-1\"><a href=\"#用法-1\" class=\"headerlink\" title=\"用法\"></a>用法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">queue &lt;int&gt; q;  stack &lt;int&gt; q;</span><br><span class=\"line\">q.push(x);</span><br><span class=\"line\">q.pop();</span><br><span class=\"line\">q.top();</span><br><span class=\"line\">q.front();</span><br><span class=\"line\">q.back();</span><br><span class=\"line\">q.empty();</span><br><span class=\"line\">q.size();</span><br></pre></td></tr></table></figure>\n<h3 id=\"优先队列-—-priority-queue\"><a href=\"#优先队列-—-priority-queue\" class=\"headerlink\" title=\"优先队列 — priority_queue\"></a>优先队列 — priority_queue</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">priority_queue &lt;int&gt; q;</span><br><span class=\"line\">priority_queue &lt;int,vector &lt;int&gt;，greater &lt;int&gt;&gt; q;</span><br><span class=\"line\">用法同queue</span><br></pre></td></tr></table></figure>\n<h2 id=\"STL-—-list\"><a href=\"#STL-—-list\" class=\"headerlink\" title=\"STL — list\"></a>STL — list</h2><h3 id=\"解释-2\"><a href=\"#解释-2\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>list 是一个双向链表的模板</p>\n<h3 id=\"用法-2\"><a href=\"#用法-2\" class=\"headerlink\" title=\"用法\"></a>用法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">begin()和end()</span><br><span class=\"line\">front()和back()</span><br><span class=\"line\">push_back() 和push_front()</span><br><span class=\"line\">empty()</span><br><span class=\"line\">clear()</span><br><span class=\"line\">insert(pos,num)</span><br><span class=\"line\">erase(pos)</span><br><span class=\"line\">sort()                  <span class=\"comment\">//将链表排序，默认升序</span></span><br><span class=\"line\">remove(num)             <span class=\"comment\">//删除链表中匹配num的元素。</span></span><br><span class=\"line\">reverse()               <span class=\"comment\">// 逆置list</span></span><br><span class=\"line\">merge()   l1.merge(l2)  <span class=\"comment\">//合并两个链表，合并后l1拥有l1和l2的元素，默认升序排列</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"STL-—-set\"><a href=\"#STL-—-set\" class=\"headerlink\" title=\"STL — set\"></a>STL — set</h2><h3 id=\"解释-3\"><a href=\"#解释-3\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>set 是一个红黑树（一种平衡树）的模板，自带去重效果</p>\n<h3 id=\"用法-3\"><a href=\"#用法-3\" class=\"headerlink\" title=\"用法\"></a>用法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">begin()     　　 <span class=\"comment\">//返回set容器的第一个元素</span></span><br><span class=\"line\">end() 　　　　 <span class=\"comment\">//返回set容器的最后一个元素</span></span><br><span class=\"line\">clear()   　　     <span class=\"comment\">//删除set容器中的所有的元素</span></span><br><span class=\"line\">empty() 　　　<span class=\"comment\">//判断set容器是否为空</span></span><br><span class=\"line\">max_size() 　 <span class=\"comment\">//返回set容器可能包含的元素最大个数</span></span><br><span class=\"line\">size() 　　　　<span class=\"comment\">//返回当前set容器中的元素个数</span></span><br><span class=\"line\">find(x)        <span class=\"comment\">//返回x的地址，若没有则返回end()</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"STL-—-map\"><a href=\"#STL-—-map\" class=\"headerlink\" title=\"STL — map\"></a>STL — map</h2><h3 id=\"解释-4\"><a href=\"#解释-4\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>map 提供的是一种键值对容器，里面的数据都是成对出现的, 每一对中的第一个值称之为关键字(key)，每个关键字只能在map中出现一次；第二个称之为该关键字的对应值。</p>\n<h3 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">map &lt;int, string&gt; ID_Name;  <span class=\"comment\">// 即一个 ID 对应一个名字，其中 ID 为 int 类型，名字为 string 类型</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 使用&#123;&#125;赋值是从c++11开始的，因此编译器版本过低时会报错，如visual studio 2012</span></span><br><span class=\"line\">map &lt;int, string&gt; ID_Name = &#123;</span><br><span class=\"line\">                &#123; <span class=\"number\">2015</span>, <span class=\"string\">\"Jim\"</span> &#125;,</span><br><span class=\"line\">                &#123; <span class=\"number\">2016</span>, <span class=\"string\">\"Tom\"</span> &#125;,</span><br><span class=\"line\">                &#123; <span class=\"number\">2017</span>, <span class=\"string\">\"Bob\"</span> &#125; &#125;;</span><br><span class=\"line\">插入：</span><br><span class=\"line\">    使用[ ]进行单个插入，ID_Name[<span class=\"number\">2015</span>] = <span class=\"string\">\"Tom\"</span>;  <span class=\"comment\">// 如果已经存在键值2015，则会作赋值修改操作，如果没有则插入（2015不是数组下标</span></span><br><span class=\"line\">    <span class=\"comment\">// 插入单个值</span></span><br><span class=\"line\">    mymap.insert(std::pair&lt;char, int&gt;(<span class=\"string\">'a'</span>, <span class=\"number\">100</span>));</span><br><span class=\"line\">    <span class=\"comment\">// 列表形式插入</span></span><br><span class=\"line\">    anothermap.insert(&#123; &#123; <span class=\"string\">'d'</span>, <span class=\"number\">100</span> &#125;, &#123;<span class=\"string\">'e'</span>, <span class=\"number\">200</span>&#125; &#125;);</span><br><span class=\"line\">取值：</span><br><span class=\"line\">    <span class=\"built_in\">Map</span>中元素取值主要有at和[ ]两种操作，at会作下标检查，而[]不会。</span><br><span class=\"line\">容量查询：</span><br><span class=\"line\">    <span class=\"comment\">// 查询map是否为空</span></span><br><span class=\"line\">    bool empty();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 查询map中键值对的数量</span></span><br><span class=\"line\">    size_t size();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 查询map所能包含的最大键值对数量，和系统和应用库有关。</span></span><br><span class=\"line\">    <span class=\"comment\">// 此外，这并不意味着用户一定可以存这么多，很可能还没达到就已经开辟内存失败了</span></span><br><span class=\"line\">    size_t max_size();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 查询关键字为key的元素的个数，在map里结果非0即1</span></span><br><span class=\"line\">    size_t count( <span class=\"keyword\">const</span> Key&amp; key ) <span class=\"keyword\">const</span>;       <span class=\"comment\">// 例：map.count(\"a\")</span></span><br><span class=\"line\">删除：</span><br><span class=\"line\">    <span class=\"comment\">// 删除迭代器指向位置的键值对，并返回一个指向下一元素的迭代器</span></span><br><span class=\"line\">    iterator erase( iterator pos )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 删除一定范围内的元素，并返回一个指向下一元素的迭代器</span></span><br><span class=\"line\">    iterator erase( const_iterator first, const_iterator last );</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 根据Key来进行删除， 返回删除的元素数量，在map里结果非0即1</span></span><br><span class=\"line\">    size_t erase( <span class=\"keyword\">const</span> key_type&amp; key );</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 清空map，清空后的size为0</span></span><br><span class=\"line\">    <span class=\"keyword\">void</span> clear();</span><br><span class=\"line\">查找：</span><br><span class=\"line\">    <span class=\"comment\">// 关键字查询，找到则返回指向该关键字的迭代器，否则返回指向end的迭代器</span></span><br><span class=\"line\">    <span class=\"comment\">// 根据map的类型，返回的迭代器为 iterator 或者 const_iterator</span></span><br><span class=\"line\">    iterator find (<span class=\"keyword\">const</span> key_type&amp; k);</span><br><span class=\"line\">    const_iterator find (<span class=\"keyword\">const</span> key_type&amp; k) <span class=\"keyword\">const</span>;</span><br></pre></td></tr></table></figure>\n<h2 id=\"STL-—-pair\"><a href=\"#STL-—-pair\" class=\"headerlink\" title=\"STL — pair\"></a>STL — pair</h2><h3 id=\"解释-5\"><a href=\"#解释-5\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>pair 是一个储存键值对的容器</p>\n<h3 id=\"用法-4\"><a href=\"#用法-4\" class=\"headerlink\" title=\"用法\"></a>用法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pair &lt;string,double&gt; product1 (<span class=\"string\">\"tomatoes\"</span>,<span class=\"number\">3.25</span>);</span><br><span class=\"line\">pair &lt;string,double&gt; product2;</span><br><span class=\"line\">pair &lt;string,double&gt; product3;</span><br><span class=\"line\"> </span><br><span class=\"line\">product2.first =<span class=\"string\">\"lightbulbs\"</span>; <span class=\"comment\">// type of first is string</span></span><br><span class=\"line\">product2.second =<span class=\"number\">0.99</span>; <span class=\"comment\">// type of second is double</span></span><br><span class=\"line\"> </span><br><span class=\"line\">product3 = make_pair (<span class=\"string\">\"shoes\"</span>,<span class=\"number\">20.0</span>);</span><br></pre></td></tr></table></figure>\n<h2 id=\"STL-—-iterator\"><a href=\"#STL-—-iterator\" class=\"headerlink\" title=\"STL — iterator\"></a>STL — iterator</h2><h3 id=\"解释-6\"><a href=\"#解释-6\" class=\"headerlink\" title=\"解释\"></a>解释</h3><p>iterator 是迭代器    可以用来接收容器的地址，如 begin(),end() 等的返回值</p>\n<h3 id=\"用法-5\"><a href=\"#用法-5\" class=\"headerlink\" title=\"用法\"></a>用法</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vector &lt;int&gt; v;</span><br><span class=\"line\">vector &lt;int&gt;::iterator it;</span><br><span class=\"line\"><span class=\"keyword\">while</span>(it = v.begin(); it != v.end(); it++)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">//进行操作</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"特殊说明\"><a href=\"#特殊说明\" class=\"headerlink\" title=\"特殊说明\"></a>特殊说明</h2><p>若在容器中存放结构，例如：<br>struct edge{<br>    int v,w;<br>}e;<br>应该如此：vector <edge> v;   注意尖括号内应为结构原来的名称</edge></p>\n<p>此外，若容器为 set 容器，则结构中必须重载小于号，若 set <edge,greater <int> &gt;，则要重载大于号<br>set 中只能有两个参数，vector <int>和 greater <int> 不能同时写进去，而 priority_queue 可以</int></int></edge,greater></p>"},{"title":"torch操作总结","date":"2020-01-23T06:18:50.000Z","_content":"\n### 在学习过程中记录一些需要用到的关于 torch（可能还有其他库） 的操作\n\n在这里慢慢积累一下各种操作，希望大家能在这篇里有所收获\n\n<!--more-->\n#### torch.argmax  求数组中某个维度的最大值的下标\n\n{% codeblock lang:JavaScript %}\n\nx = torch.randn(5, 2)\nprint(x)\ny = torch.argmax(x, dim=1)     # dim的值为几就代表求第几维的最大值（从0开始）\nprint(y)\n\noutput:\n\ntensor([[-0.5390, -0.3401],\n        [-1.9364,  0.1501],\n        [ 1.6209,  0.3534],\n        [ 1.2624,  2.0758],\n        [ 1.6152,  0.6949]])\ntensor([1, 1, 0, 1, 0])\n\n{% endcodeblock %}\n\n#### 存取模型\n\n{% codeblock lang:JavaScript %}\n\n仅保存和加载模型参数(推荐使用)\n\nmodel = Model()\nPATH = './Mobilenetv2.pth'\ntorch.save(model.state_dict(), PATH)\n\nPATH = './Mobilenetv2.pth'\npretrained_net = torch.load(PATH)\nmodel.load_state_dict(pretrained_net)\n\n{% endcodeblock %}","source":"_posts/torch操作总结.md","raw":"---\ntitle: torch操作总结\ndate: 2020-01-23 14:18:50\ntags: [机器学习]\n---\n\n### 在学习过程中记录一些需要用到的关于 torch（可能还有其他库） 的操作\n\n在这里慢慢积累一下各种操作，希望大家能在这篇里有所收获\n\n<!--more-->\n#### torch.argmax  求数组中某个维度的最大值的下标\n\n{% codeblock lang:JavaScript %}\n\nx = torch.randn(5, 2)\nprint(x)\ny = torch.argmax(x, dim=1)     # dim的值为几就代表求第几维的最大值（从0开始）\nprint(y)\n\noutput:\n\ntensor([[-0.5390, -0.3401],\n        [-1.9364,  0.1501],\n        [ 1.6209,  0.3534],\n        [ 1.2624,  2.0758],\n        [ 1.6152,  0.6949]])\ntensor([1, 1, 0, 1, 0])\n\n{% endcodeblock %}\n\n#### 存取模型\n\n{% codeblock lang:JavaScript %}\n\n仅保存和加载模型参数(推荐使用)\n\nmodel = Model()\nPATH = './Mobilenetv2.pth'\ntorch.save(model.state_dict(), PATH)\n\nPATH = './Mobilenetv2.pth'\npretrained_net = torch.load(PATH)\nmodel.load_state_dict(pretrained_net)\n\n{% endcodeblock %}","slug":"torch操作总结","published":1,"updated":"2020-01-24T09:53:59.930Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh7015000ba0uz1czx8bcy","content":"<h3 id=\"在学习过程中记录一些需要用到的关于-torch（可能还有其他库）-的操作\"><a href=\"#在学习过程中记录一些需要用到的关于-torch（可能还有其他库）-的操作\" class=\"headerlink\" title=\"在学习过程中记录一些需要用到的关于 torch（可能还有其他库） 的操作\"></a>在学习过程中记录一些需要用到的关于 torch（可能还有其他库） 的操作</h3><p>在这里慢慢积累一下各种操作，希望大家能在这篇里有所收获</p>\n<a id=\"more\"></a>\n<h4 id=\"torch-argmax-求数组中某个维度的最大值的下标\"><a href=\"#torch-argmax-求数组中某个维度的最大值的下标\" class=\"headerlink\" title=\"torch.argmax  求数组中某个维度的最大值的下标\"></a>torch.argmax  求数组中某个维度的最大值的下标</h4><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">x = torch.randn(<span class=\"number\">5</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">print(x)</span><br><span class=\"line\">y = torch.argmax(x, dim=1)     # dim的值为几就代表求第几维的最大值（从0开始）</span><br><span class=\"line\">print(y)</span><br><span class=\"line\"></span><br><span class=\"line\">output:</span><br><span class=\"line\"></span><br><span class=\"line\">tensor([[<span class=\"number\">-0.5390</span>, <span class=\"number\">-0.3401</span>],</span><br><span class=\"line\">        [<span class=\"number\">-1.9364</span>,  <span class=\"number\">0.1501</span>],</span><br><span class=\"line\">        [ <span class=\"number\">1.6209</span>,  <span class=\"number\">0.3534</span>],</span><br><span class=\"line\">        [ <span class=\"number\">1.2624</span>,  <span class=\"number\">2.0758</span>],</span><br><span class=\"line\">        [ <span class=\"number\">1.6152</span>,  <span class=\"number\">0.6949</span>]])</span><br><span class=\"line\">tensor([<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h4 id=\"存取模型\"><a href=\"#存取模型\" class=\"headerlink\" title=\"存取模型\"></a>存取模型</h4><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">仅保存和加载模型参数(推荐使用)</span><br><span class=\"line\"></span><br><span class=\"line\">model = Model()</span><br><span class=\"line\">PATH = <span class=\"string\">'./Mobilenetv2.pth'</span></span><br><span class=\"line\">torch.save(model.state_dict(), PATH)</span><br><span class=\"line\"></span><br><span class=\"line\">PATH = <span class=\"string\">'./Mobilenetv2.pth'</span></span><br><span class=\"line\">pretrained_net = torch.load(PATH)</span><br><span class=\"line\">model.load_state_dict(pretrained_net)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<h3 id=\"在学习过程中记录一些需要用到的关于-torch（可能还有其他库）-的操作\"><a href=\"#在学习过程中记录一些需要用到的关于-torch（可能还有其他库）-的操作\" class=\"headerlink\" title=\"在学习过程中记录一些需要用到的关于 torch（可能还有其他库） 的操作\"></a>在学习过程中记录一些需要用到的关于 torch（可能还有其他库） 的操作</h3><p>在这里慢慢积累一下各种操作，希望大家能在这篇里有所收获</p>","more":"<h4 id=\"torch-argmax-求数组中某个维度的最大值的下标\"><a href=\"#torch-argmax-求数组中某个维度的最大值的下标\" class=\"headerlink\" title=\"torch.argmax  求数组中某个维度的最大值的下标\"></a>torch.argmax  求数组中某个维度的最大值的下标</h4><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">x = torch.randn(<span class=\"number\">5</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">print(x)</span><br><span class=\"line\">y = torch.argmax(x, dim=1)     # dim的值为几就代表求第几维的最大值（从0开始）</span><br><span class=\"line\">print(y)</span><br><span class=\"line\"></span><br><span class=\"line\">output:</span><br><span class=\"line\"></span><br><span class=\"line\">tensor([[<span class=\"number\">-0.5390</span>, <span class=\"number\">-0.3401</span>],</span><br><span class=\"line\">        [<span class=\"number\">-1.9364</span>,  <span class=\"number\">0.1501</span>],</span><br><span class=\"line\">        [ <span class=\"number\">1.6209</span>,  <span class=\"number\">0.3534</span>],</span><br><span class=\"line\">        [ <span class=\"number\">1.2624</span>,  <span class=\"number\">2.0758</span>],</span><br><span class=\"line\">        [ <span class=\"number\">1.6152</span>,  <span class=\"number\">0.6949</span>]])</span><br><span class=\"line\">tensor([<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h4 id=\"存取模型\"><a href=\"#存取模型\" class=\"headerlink\" title=\"存取模型\"></a>存取模型</h4><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">仅保存和加载模型参数(推荐使用)</span><br><span class=\"line\"></span><br><span class=\"line\">model = Model()</span><br><span class=\"line\">PATH = <span class=\"string\">'./Mobilenetv2.pth'</span></span><br><span class=\"line\">torch.save(model.state_dict(), PATH)</span><br><span class=\"line\"></span><br><span class=\"line\">PATH = <span class=\"string\">'./Mobilenetv2.pth'</span></span><br><span class=\"line\">pretrained_net = torch.load(PATH)</span><br><span class=\"line\">model.load_state_dict(pretrained_net)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>"},{"title":"单/多源最短路","date":"2019-09-24T06:25:09.000Z","_content":"\n## 单/多源最短路的三种算法 -- dijkstra & spfa & floyd\n\n### 什么是最短路\n\n单源最短路：计算图中一个点到其他各点的最短距离\n多源最短路：计算图中多个点到其他各点的最短距离\n\n### 单源最短路 -- dijkstra 算法\n\n#### 算法描述\n\nmain 函数：用vector数组存边，初始化一维数组 dist 来表示起点到其他各点的距离（到自己为 0，其他点为 INF），将初始边（目标点为起点，权值为 0）加入到优先队列 queue 中\ndijkstra 函数：抛出优先队列的 top 边，若这个边的权值比现在到这个目标点的权值大（说明起点到该点的长度又更新了，而且那个边肯定在这个边前面），就跳过，否则就疏松以这个点为起点的所有边，若通过这个点，起始点到其他的点的距离有减小的，则把路径减小的目标点和减小后的距离加入到优先队列中，重复操作\n<!--more-->\n#### 算法应用\n\n说明：这个题有点意思（\n\n##### 题目描述\n知识点：最短路，最短路的优化\n\n贝克兰德有n个城镇，这些城镇之间有m条道路连接，每条道路有一个长度l。\n\nzf在其中k个城镇设置了治安点。当一个城镇发生事件时，任意一个治安点都可以派人前往。但是为了节省资源，往往会选择距离最近的治安点。\n\n那么请问，对于每一个城镇，最近的治安点距离为多少。\n\n##### 思路\n\n这个题要求算部分点到其他点的最短距离，因此看起来是一个多源最短路，但是你如果执行多次 dijkstra 你就超时了，所以我们要多设立一个虚拟点 s，把所有的治安点往这个虚拟点上拉一条距离为 0的边（无向），以这个点为起点计算到其他点的最短路即满足要求\n\n##### 代码\n\n{% codeblock lang:JavaScript %}\n/* \n Author: 王振\n Result: AC\tSubmission_id: 1833390\n Created at: Fri Sep 13 2019 21:01:55 GMT+0800 (CST)\n Problem_id: 2378\tTime: 540\tMemory: 5508\n*/\n\n#include <iostream>\n#include <queue>\n#include <vector>\n#include <algorithm>\nusing namespace std;\nint n,m,s;\nint dist[1005];\nstruct line{\n    int w;\n    int v;\n    bool operator <(const line&b) const\n    {\n    \treturn w>b.w;\n\t}\n}list;\n\nvector <line> vec[1005];\npriority_queue <line> q;\n\nvoid dijkstra(int p)\n{\n\tlist.v=p;\n\tlist.w=0;\n\tq.push(list);\n\twhile(!q.empty())\n\t{\n\t\tstruct line k=q.top();\n\t\tq.pop();\n\t\tif(k.w>dist[k.v])\n\t\t{\n\t\t\tcontinue;\n\t\t}else\n\t\t{\n\t\t\tfor(int i=0;i<vec[k.v].size();i++)\n\t\t\t{\n\t\t\t\tstruct line j=vec[k.v][i];\n\t\t\t\tif(dist[j.v]>dist[k.v]+j.w)\n\t\t\t\t{\n\t\t\t\t\tdist[j.v]=dist[k.v]+j.w;\n\t\t\t\t\tlist.v=j.v;\n\t\t\t\t\tlist.w=dist[j.v];\n\t\t\t\t\tq.push(list);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\nint main()\n{\n\tint t;\n\tcin>>t;\n\twhile(t--)\n\t{\n\t\tint u,v,w;\n\t\tscanf(\"%d%d%d\",&n,&m,&s);\n\t\tfor(int i=1;i<=n+1;i++)\n\t\t{\n\t\t\twhile(!vec[i].empty())\n\t\t\t{\n\t\t\t\tvec[i].pop_back();\n\t\t\t}\n\t\t}\n\t\tfor(int i=1;i<=n+1;i++)\n\t\t{\n\t\t\tdist[i]=10000000;\n\t\t}\n\t\tfor(int i=1;i<=s;i++)\n\t\t{\n\t\t\tscanf(\"%d\",&u);\n\t\t\tlist.w=0;\n\t\t\tlist.v=u;\n\t\t\tvec[n+1].push_back(list);\n\t\t\tlist.v=n+1;\n\t\t\tvec[u].push_back(list);\n\t\t}\n\t\tfor(int i=1;i<=m;i++)\n\t\t{\n\t\t\tscanf(\"%d%d%d\",&u,&v,&w);\n\t\t\tlist.v=v;\n\t\t\tlist.w=w;\n\t\t\tvec[u].push_back(list);\n\t\t\tlist.v=u;\n\t\t\tvec[v].push_back(list);\n\t\t}\n\t\tdist[n+1]=0;\n\t\tdijkstra(n+1);\n\t\tfor(int i=1;i<=n;i++)\n\t\t{\n\t\t\tprintf(\"%d \",dist[i]);\n\t\t}\n\t\tprintf(\"\\n\");\n\t}\n\treturn 0;\n}\n\n{% endcodeblock %}\n\n### 单源最短路 -- spfa 算法  可以判断负环！\n\n#### 算法描述\n\n将某个点的序号 x 作为 spfa 函数的输入，则从这个点开始进行单源最短路，如果点 v 通过当前点 u 到输入点 x 的距离变小，那么更新距离值，并且如果 v 不在队列中，就将 v 加入到队列里，对于每个点记录它们加入队列的次数，如果大于总点数 n ,就判定为当前图中存在负环。\n\n#### 题目描述\n\n知识点：最短路\n\n克莱恩在一场冒险中得到了得到了一个破损的魔法阵，这个魔法阵是一个有n个点m条边的有向有环图，任意两点之间最多只有一条边，每条边有一个能量值a（可能是负数，别问问就是magical），不存在负环。\n\n克莱恩试图去修补这个魔法阵。已知，这个魔法阵缺少了3条边，且已经知道这3条边的起点和终点（有向）。对于每条边，克莱恩要赋予其一个能量值c，为了避免邪神出现，修补过程以及结束后也不能出现负环。\n\n请问每次的最小花费是多少(保证有解，可以是负数)。\n\n#### 题目思路\n\n修补过程及结束后不能出现负环，则枚举边权来找到最大的可以使图中出现负环的权值，那么给这个权值加一图中就没有负环（其实可以二分权值直接找到答案）\n\n#### 代码示例\n\n{% codeblock lang:JavaScript %}\n/* \n Author: 王振\n Result: AC\tSubmission_id: 1833275\n Created at: Fri Sep 13 2019 16:22:27 GMT+0800 (CST)\n Problem_id: 2376\tTime: 790\tMemory: 3228\n*/\n\n#include <iostream>\n#include <queue>\n#include <algorithm>\n#include <vector>\n#include <cmath>\nusing namespace std;\n\nstruct edge{\n\tint v,w;\n}e;\n\nvector <edge> v[305];\nqueue <int> q;\nint n,m;\nint flag=0;                // 有无负环的标志，有负环 flag=1 \nint num[305];              // 存储每个点加入队列的次数 \nint visit[305];\t\t\t   // 如果某个点在队列中，那么visit[i]=1，反之为0 \nint dist[305];\t\t\t   // 存储距离 \n\nvoid spfa(int x)\n{\n\tfor(int i=0;i<n;i++)          // 初始化 \n\t{\n\t\tnum[i]=0;\n\t\tvisit[i]=0;\n\t\tif(i!=x) dist[i]=10000000;\n\t}\n\twhile(!q.empty())\n\t{\n\t\tint a=q.front();\n\t\tvisit[a]=0;\n\t\tq.pop();\n\t\tfor(int i=0;i<v[a].size();i++)\n\t\t{\n\t\t\tint c=v[a][i].v;\n\t\t\tif(dist[c]>dist[a]+v[a][i].w)    // 距离小于当前距离，更新，如果这个点不在队列中则加入队列，且这个点的访问次数+1 \n\t\t\t{\n\t\t\t\tdist[c]=dist[a]+v[a][i].w;\n\t\t\t\tif(visit[c]==0)\n\t\t\t\t{\n\t\t\t\t\tnum[c]++; \n\t\t\t\t\tq.push(c);\n\t\t\t\t\tvisit[c]=1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor(int i=0;i<n;i++)\n\t\t{\n\t\t\tif(num[i]>n)            // 如果对一个点访问次数 >n 则判定为存在负环 \n\t\t\t{\n\t\t\t\tflag=1;\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n}\n\nint main()\n{\n\tcin>>n>>m;\n\tint x,y,z;\n\tfor(int i=0;i<m;i++)         // 输入边 \n\t{\n\t\tcin>>x>>y>>z;\n\t\te.v=y;\n\t\te.w=z;\n\t\tv[x].push_back(e);\n\t}\n\tfor(int i=0;i<3;i++)\n\t{\n\t\tflag=0;\n\t\tcin>>x>>y;\n\t\te.v=y;\n\t\te.w=1000;\n\t\tv[x].push_back(e);\n\t\twhile(flag==0)        // 若没有负环则边权减小直到有负环为止\n\t\t{\n\t\t\tq.push(x);\n\t\t\te.w--;\n\t\t\tv[x].pop_back();\n\t\t\tv[x].push_back(e);\n\t\t\tspfa(x);\n\t\t}\n\t\tv[x].pop_back();      //此时的边权为最大的有负环的权值，加一则没有负环\n\t\te.w++;\n\t\tv[x].push_back(e);\n\t\tcout<<e.w<<endl;\n\t}\n\treturn 0;\n}\n{% endcodeblock %}\n\n### 多源最短路 -- floyd 算法\n\n#### 算法描述\n\nfloyd 算法很简单，先在邻接矩阵中将直接相连的边的权值更新，然后对于任意两个点，以任意一个点为中介，更新两个点之间的权值，注意将当成中介的点放在最外面的循环，如若不然，可以将这三个循环执行三遍，则不用管i,j,k的顺序\n\n#### 代码示例\n\n{% codeblock lang:JavaScript %}\n\nfor(int k=1;k<=n;k++)\n{\n\tfor(int i=1;i<=n;i++)\n\t{\n\t\tfor(int j=1;j<=n;j++)\n\t\t{\n\t\t\tif(dist[i][j]>dist[i][k]+dist[k][j])\n\t\t\t{\n\t\t\t\tdist[i][j]=dist[i][k]+dist[k][j];\n\t\t\t}\n\t\t}\n\t}\n}\n\n{% endcodeblock %}","source":"_posts/最短路算法.md","raw":"---\ntitle: 单/多源最短路\ndate: 2019-09-24 14:25:09\ntags:\n    - 数据结构\n---\n\n## 单/多源最短路的三种算法 -- dijkstra & spfa & floyd\n\n### 什么是最短路\n\n单源最短路：计算图中一个点到其他各点的最短距离\n多源最短路：计算图中多个点到其他各点的最短距离\n\n### 单源最短路 -- dijkstra 算法\n\n#### 算法描述\n\nmain 函数：用vector数组存边，初始化一维数组 dist 来表示起点到其他各点的距离（到自己为 0，其他点为 INF），将初始边（目标点为起点，权值为 0）加入到优先队列 queue 中\ndijkstra 函数：抛出优先队列的 top 边，若这个边的权值比现在到这个目标点的权值大（说明起点到该点的长度又更新了，而且那个边肯定在这个边前面），就跳过，否则就疏松以这个点为起点的所有边，若通过这个点，起始点到其他的点的距离有减小的，则把路径减小的目标点和减小后的距离加入到优先队列中，重复操作\n<!--more-->\n#### 算法应用\n\n说明：这个题有点意思（\n\n##### 题目描述\n知识点：最短路，最短路的优化\n\n贝克兰德有n个城镇，这些城镇之间有m条道路连接，每条道路有一个长度l。\n\nzf在其中k个城镇设置了治安点。当一个城镇发生事件时，任意一个治安点都可以派人前往。但是为了节省资源，往往会选择距离最近的治安点。\n\n那么请问，对于每一个城镇，最近的治安点距离为多少。\n\n##### 思路\n\n这个题要求算部分点到其他点的最短距离，因此看起来是一个多源最短路，但是你如果执行多次 dijkstra 你就超时了，所以我们要多设立一个虚拟点 s，把所有的治安点往这个虚拟点上拉一条距离为 0的边（无向），以这个点为起点计算到其他点的最短路即满足要求\n\n##### 代码\n\n{% codeblock lang:JavaScript %}\n/* \n Author: 王振\n Result: AC\tSubmission_id: 1833390\n Created at: Fri Sep 13 2019 21:01:55 GMT+0800 (CST)\n Problem_id: 2378\tTime: 540\tMemory: 5508\n*/\n\n#include <iostream>\n#include <queue>\n#include <vector>\n#include <algorithm>\nusing namespace std;\nint n,m,s;\nint dist[1005];\nstruct line{\n    int w;\n    int v;\n    bool operator <(const line&b) const\n    {\n    \treturn w>b.w;\n\t}\n}list;\n\nvector <line> vec[1005];\npriority_queue <line> q;\n\nvoid dijkstra(int p)\n{\n\tlist.v=p;\n\tlist.w=0;\n\tq.push(list);\n\twhile(!q.empty())\n\t{\n\t\tstruct line k=q.top();\n\t\tq.pop();\n\t\tif(k.w>dist[k.v])\n\t\t{\n\t\t\tcontinue;\n\t\t}else\n\t\t{\n\t\t\tfor(int i=0;i<vec[k.v].size();i++)\n\t\t\t{\n\t\t\t\tstruct line j=vec[k.v][i];\n\t\t\t\tif(dist[j.v]>dist[k.v]+j.w)\n\t\t\t\t{\n\t\t\t\t\tdist[j.v]=dist[k.v]+j.w;\n\t\t\t\t\tlist.v=j.v;\n\t\t\t\t\tlist.w=dist[j.v];\n\t\t\t\t\tq.push(list);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\nint main()\n{\n\tint t;\n\tcin>>t;\n\twhile(t--)\n\t{\n\t\tint u,v,w;\n\t\tscanf(\"%d%d%d\",&n,&m,&s);\n\t\tfor(int i=1;i<=n+1;i++)\n\t\t{\n\t\t\twhile(!vec[i].empty())\n\t\t\t{\n\t\t\t\tvec[i].pop_back();\n\t\t\t}\n\t\t}\n\t\tfor(int i=1;i<=n+1;i++)\n\t\t{\n\t\t\tdist[i]=10000000;\n\t\t}\n\t\tfor(int i=1;i<=s;i++)\n\t\t{\n\t\t\tscanf(\"%d\",&u);\n\t\t\tlist.w=0;\n\t\t\tlist.v=u;\n\t\t\tvec[n+1].push_back(list);\n\t\t\tlist.v=n+1;\n\t\t\tvec[u].push_back(list);\n\t\t}\n\t\tfor(int i=1;i<=m;i++)\n\t\t{\n\t\t\tscanf(\"%d%d%d\",&u,&v,&w);\n\t\t\tlist.v=v;\n\t\t\tlist.w=w;\n\t\t\tvec[u].push_back(list);\n\t\t\tlist.v=u;\n\t\t\tvec[v].push_back(list);\n\t\t}\n\t\tdist[n+1]=0;\n\t\tdijkstra(n+1);\n\t\tfor(int i=1;i<=n;i++)\n\t\t{\n\t\t\tprintf(\"%d \",dist[i]);\n\t\t}\n\t\tprintf(\"\\n\");\n\t}\n\treturn 0;\n}\n\n{% endcodeblock %}\n\n### 单源最短路 -- spfa 算法  可以判断负环！\n\n#### 算法描述\n\n将某个点的序号 x 作为 spfa 函数的输入，则从这个点开始进行单源最短路，如果点 v 通过当前点 u 到输入点 x 的距离变小，那么更新距离值，并且如果 v 不在队列中，就将 v 加入到队列里，对于每个点记录它们加入队列的次数，如果大于总点数 n ,就判定为当前图中存在负环。\n\n#### 题目描述\n\n知识点：最短路\n\n克莱恩在一场冒险中得到了得到了一个破损的魔法阵，这个魔法阵是一个有n个点m条边的有向有环图，任意两点之间最多只有一条边，每条边有一个能量值a（可能是负数，别问问就是magical），不存在负环。\n\n克莱恩试图去修补这个魔法阵。已知，这个魔法阵缺少了3条边，且已经知道这3条边的起点和终点（有向）。对于每条边，克莱恩要赋予其一个能量值c，为了避免邪神出现，修补过程以及结束后也不能出现负环。\n\n请问每次的最小花费是多少(保证有解，可以是负数)。\n\n#### 题目思路\n\n修补过程及结束后不能出现负环，则枚举边权来找到最大的可以使图中出现负环的权值，那么给这个权值加一图中就没有负环（其实可以二分权值直接找到答案）\n\n#### 代码示例\n\n{% codeblock lang:JavaScript %}\n/* \n Author: 王振\n Result: AC\tSubmission_id: 1833275\n Created at: Fri Sep 13 2019 16:22:27 GMT+0800 (CST)\n Problem_id: 2376\tTime: 790\tMemory: 3228\n*/\n\n#include <iostream>\n#include <queue>\n#include <algorithm>\n#include <vector>\n#include <cmath>\nusing namespace std;\n\nstruct edge{\n\tint v,w;\n}e;\n\nvector <edge> v[305];\nqueue <int> q;\nint n,m;\nint flag=0;                // 有无负环的标志，有负环 flag=1 \nint num[305];              // 存储每个点加入队列的次数 \nint visit[305];\t\t\t   // 如果某个点在队列中，那么visit[i]=1，反之为0 \nint dist[305];\t\t\t   // 存储距离 \n\nvoid spfa(int x)\n{\n\tfor(int i=0;i<n;i++)          // 初始化 \n\t{\n\t\tnum[i]=0;\n\t\tvisit[i]=0;\n\t\tif(i!=x) dist[i]=10000000;\n\t}\n\twhile(!q.empty())\n\t{\n\t\tint a=q.front();\n\t\tvisit[a]=0;\n\t\tq.pop();\n\t\tfor(int i=0;i<v[a].size();i++)\n\t\t{\n\t\t\tint c=v[a][i].v;\n\t\t\tif(dist[c]>dist[a]+v[a][i].w)    // 距离小于当前距离，更新，如果这个点不在队列中则加入队列，且这个点的访问次数+1 \n\t\t\t{\n\t\t\t\tdist[c]=dist[a]+v[a][i].w;\n\t\t\t\tif(visit[c]==0)\n\t\t\t\t{\n\t\t\t\t\tnum[c]++; \n\t\t\t\t\tq.push(c);\n\t\t\t\t\tvisit[c]=1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor(int i=0;i<n;i++)\n\t\t{\n\t\t\tif(num[i]>n)            // 如果对一个点访问次数 >n 则判定为存在负环 \n\t\t\t{\n\t\t\t\tflag=1;\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n}\n\nint main()\n{\n\tcin>>n>>m;\n\tint x,y,z;\n\tfor(int i=0;i<m;i++)         // 输入边 \n\t{\n\t\tcin>>x>>y>>z;\n\t\te.v=y;\n\t\te.w=z;\n\t\tv[x].push_back(e);\n\t}\n\tfor(int i=0;i<3;i++)\n\t{\n\t\tflag=0;\n\t\tcin>>x>>y;\n\t\te.v=y;\n\t\te.w=1000;\n\t\tv[x].push_back(e);\n\t\twhile(flag==0)        // 若没有负环则边权减小直到有负环为止\n\t\t{\n\t\t\tq.push(x);\n\t\t\te.w--;\n\t\t\tv[x].pop_back();\n\t\t\tv[x].push_back(e);\n\t\t\tspfa(x);\n\t\t}\n\t\tv[x].pop_back();      //此时的边权为最大的有负环的权值，加一则没有负环\n\t\te.w++;\n\t\tv[x].push_back(e);\n\t\tcout<<e.w<<endl;\n\t}\n\treturn 0;\n}\n{% endcodeblock %}\n\n### 多源最短路 -- floyd 算法\n\n#### 算法描述\n\nfloyd 算法很简单，先在邻接矩阵中将直接相连的边的权值更新，然后对于任意两个点，以任意一个点为中介，更新两个点之间的权值，注意将当成中介的点放在最外面的循环，如若不然，可以将这三个循环执行三遍，则不用管i,j,k的顺序\n\n#### 代码示例\n\n{% codeblock lang:JavaScript %}\n\nfor(int k=1;k<=n;k++)\n{\n\tfor(int i=1;i<=n;i++)\n\t{\n\t\tfor(int j=1;j<=n;j++)\n\t\t{\n\t\t\tif(dist[i][j]>dist[i][k]+dist[k][j])\n\t\t\t{\n\t\t\t\tdist[i][j]=dist[i][k]+dist[k][j];\n\t\t\t}\n\t\t}\n\t}\n}\n\n{% endcodeblock %}","slug":"最短路算法","published":1,"updated":"2019-11-25T16:20:20.509Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh701g000da0uzb9e0qdsp","content":"<h2 id=\"单-多源最短路的三种算法-—-dijkstra-amp-spfa-amp-floyd\"><a href=\"#单-多源最短路的三种算法-—-dijkstra-amp-spfa-amp-floyd\" class=\"headerlink\" title=\"单/多源最短路的三种算法 — dijkstra &amp; spfa &amp; floyd\"></a>单/多源最短路的三种算法 — dijkstra &amp; spfa &amp; floyd</h2><h3 id=\"什么是最短路\"><a href=\"#什么是最短路\" class=\"headerlink\" title=\"什么是最短路\"></a>什么是最短路</h3><p>单源最短路：计算图中一个点到其他各点的最短距离<br>多源最短路：计算图中多个点到其他各点的最短距离</p>\n<h3 id=\"单源最短路-—-dijkstra-算法\"><a href=\"#单源最短路-—-dijkstra-算法\" class=\"headerlink\" title=\"单源最短路 — dijkstra 算法\"></a>单源最短路 — dijkstra 算法</h3><h4 id=\"算法描述\"><a href=\"#算法描述\" class=\"headerlink\" title=\"算法描述\"></a>算法描述</h4><p>main 函数：用vector数组存边，初始化一维数组 dist 来表示起点到其他各点的距离（到自己为 0，其他点为 INF），将初始边（目标点为起点，权值为 0）加入到优先队列 queue 中<br>dijkstra 函数：抛出优先队列的 top 边，若这个边的权值比现在到这个目标点的权值大（说明起点到该点的长度又更新了，而且那个边肯定在这个边前面），就跳过，否则就疏松以这个点为起点的所有边，若通过这个点，起始点到其他的点的距离有减小的，则把路径减小的目标点和减小后的距离加入到优先队列中，重复操作<br><a id=\"more\"></a></p>\n<h4 id=\"算法应用\"><a href=\"#算法应用\" class=\"headerlink\" title=\"算法应用\"></a>算法应用</h4><p>说明：这个题有点意思（</p>\n<h5 id=\"题目描述\"><a href=\"#题目描述\" class=\"headerlink\" title=\"题目描述\"></a>题目描述</h5><p>知识点：最短路，最短路的优化</p>\n<p>贝克兰德有n个城镇，这些城镇之间有m条道路连接，每条道路有一个长度l。</p>\n<p>zf在其中k个城镇设置了治安点。当一个城镇发生事件时，任意一个治安点都可以派人前往。但是为了节省资源，往往会选择距离最近的治安点。</p>\n<p>那么请问，对于每一个城镇，最近的治安点距离为多少。</p>\n<h5 id=\"思路\"><a href=\"#思路\" class=\"headerlink\" title=\"思路\"></a>思路</h5><p>这个题要求算部分点到其他点的最短距离，因此看起来是一个多源最短路，但是你如果执行多次 dijkstra 你就超时了，所以我们要多设立一个虚拟点 s，把所有的治安点往这个虚拟点上拉一条距离为 0的边（无向），以这个点为起点计算到其他点的最短路即满足要求</p>\n<h5 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h5><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* </span></span><br><span class=\"line\"><span class=\"comment\"> Author: 王振</span></span><br><span class=\"line\"><span class=\"comment\"> Result: AC\tSubmission_id: 1833390</span></span><br><span class=\"line\"><span class=\"comment\"> Created at: Fri Sep 13 2019 21:01:55 GMT+0800 (CST)</span></span><br><span class=\"line\"><span class=\"comment\"> Problem_id: 2378\tTime: 540\tMemory: 5508</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\">#include &lt;queue&gt;</span><br><span class=\"line\">#include &lt;vector&gt;</span><br><span class=\"line\">#include &lt;algorithm&gt;</span><br><span class=\"line\">using namespace std;</span><br><span class=\"line\">int n,m,s;</span><br><span class=\"line\">int dist[<span class=\"number\">1005</span>];</span><br><span class=\"line\">struct line&#123;</span><br><span class=\"line\">    int w;</span><br><span class=\"line\">    int v;</span><br><span class=\"line\">    bool operator &lt;(<span class=\"keyword\">const</span> line&amp;b) <span class=\"keyword\">const</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">return</span> w&gt;b.w;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;list;</span><br><span class=\"line\"></span><br><span class=\"line\">vector &lt;line&gt; vec[<span class=\"number\">1005</span>];</span><br><span class=\"line\">priority_queue &lt;line&gt; q;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> dijkstra(int p)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\tlist.v=p;</span><br><span class=\"line\">\tlist.w=<span class=\"number\">0</span>;</span><br><span class=\"line\">\tq.push(list);</span><br><span class=\"line\">\t<span class=\"keyword\">while</span>(!q.empty())</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tstruct line k=q.top();</span><br><span class=\"line\">\t\tq.pop();</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span>(k.w&gt;dist[k.v])</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">continue</span>;</span><br><span class=\"line\">\t\t&#125;<span class=\"keyword\">else</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;vec[k.v].size();i++)</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\tstruct line j=vec[k.v][i];</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">if</span>(dist[j.v]&gt;dist[k.v]+j.w)</span><br><span class=\"line\">\t\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\t\tdist[j.v]=dist[k.v]+j.w;</span><br><span class=\"line\">\t\t\t\t\tlist.v=j.v;</span><br><span class=\"line\">\t\t\t\t\tlist.w=dist[j.v];</span><br><span class=\"line\">\t\t\t\t\tq.push(list);</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\tint t;</span><br><span class=\"line\">\tcin&gt;&gt;t;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span>(t--)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tint u,v,w;</span><br><span class=\"line\">\t\tscanf(<span class=\"string\">\"%d%d%d\"</span>,&amp;n,&amp;m,&amp;s);</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=n+<span class=\"number\">1</span>;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">while</span>(!vec[i].empty())</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\tvec[i].pop_back();</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=n+<span class=\"number\">1</span>;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tdist[i]=<span class=\"number\">10000000</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=s;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tscanf(<span class=\"string\">\"%d\"</span>,&amp;u);</span><br><span class=\"line\">\t\t\tlist.w=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\t\tlist.v=u;</span><br><span class=\"line\">\t\t\tvec[n+<span class=\"number\">1</span>].push_back(list);</span><br><span class=\"line\">\t\t\tlist.v=n+<span class=\"number\">1</span>;</span><br><span class=\"line\">\t\t\tvec[u].push_back(list);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=m;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tscanf(<span class=\"string\">\"%d%d%d\"</span>,&amp;u,&amp;v,&amp;w);</span><br><span class=\"line\">\t\t\tlist.v=v;</span><br><span class=\"line\">\t\t\tlist.w=w;</span><br><span class=\"line\">\t\t\tvec[u].push_back(list);</span><br><span class=\"line\">\t\t\tlist.v=u;</span><br><span class=\"line\">\t\t\tvec[v].push_back(list);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tdist[n+<span class=\"number\">1</span>]=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\tdijkstra(n+<span class=\"number\">1</span>);</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=n;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tprintf(<span class=\"string\">\"%d \"</span>,dist[i]);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tprintf(<span class=\"string\">\"\\n\"</span>);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"单源最短路-—-spfa-算法-可以判断负环！\"><a href=\"#单源最短路-—-spfa-算法-可以判断负环！\" class=\"headerlink\" title=\"单源最短路 — spfa 算法  可以判断负环！\"></a>单源最短路 — spfa 算法  可以判断负环！</h3><h4 id=\"算法描述-1\"><a href=\"#算法描述-1\" class=\"headerlink\" title=\"算法描述\"></a>算法描述</h4><p>将某个点的序号 x 作为 spfa 函数的输入，则从这个点开始进行单源最短路，如果点 v 通过当前点 u 到输入点 x 的距离变小，那么更新距离值，并且如果 v 不在队列中，就将 v 加入到队列里，对于每个点记录它们加入队列的次数，如果大于总点数 n ,就判定为当前图中存在负环。</p>\n<h4 id=\"题目描述-1\"><a href=\"#题目描述-1\" class=\"headerlink\" title=\"题目描述\"></a>题目描述</h4><p>知识点：最短路</p>\n<p>克莱恩在一场冒险中得到了得到了一个破损的魔法阵，这个魔法阵是一个有n个点m条边的有向有环图，任意两点之间最多只有一条边，每条边有一个能量值a（可能是负数，别问问就是magical），不存在负环。</p>\n<p>克莱恩试图去修补这个魔法阵。已知，这个魔法阵缺少了3条边，且已经知道这3条边的起点和终点（有向）。对于每条边，克莱恩要赋予其一个能量值c，为了避免邪神出现，修补过程以及结束后也不能出现负环。</p>\n<p>请问每次的最小花费是多少(保证有解，可以是负数)。</p>\n<h4 id=\"题目思路\"><a href=\"#题目思路\" class=\"headerlink\" title=\"题目思路\"></a>题目思路</h4><p>修补过程及结束后不能出现负环，则枚举边权来找到最大的可以使图中出现负环的权值，那么给这个权值加一图中就没有负环（其实可以二分权值直接找到答案）</p>\n<h4 id=\"代码示例\"><a href=\"#代码示例\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* </span></span><br><span class=\"line\"><span class=\"comment\"> Author: 王振</span></span><br><span class=\"line\"><span class=\"comment\"> Result: AC\tSubmission_id: 1833275</span></span><br><span class=\"line\"><span class=\"comment\"> Created at: Fri Sep 13 2019 16:22:27 GMT+0800 (CST)</span></span><br><span class=\"line\"><span class=\"comment\"> Problem_id: 2376\tTime: 790\tMemory: 3228</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\">#include &lt;queue&gt;</span><br><span class=\"line\">#include &lt;algorithm&gt;</span><br><span class=\"line\">#include &lt;vector&gt;</span><br><span class=\"line\">#include &lt;cmath&gt;</span><br><span class=\"line\">using namespace std;</span><br><span class=\"line\"></span><br><span class=\"line\">struct edge&#123;</span><br><span class=\"line\">\tint v,w;</span><br><span class=\"line\">&#125;e;</span><br><span class=\"line\"></span><br><span class=\"line\">vector &lt;edge&gt; v[<span class=\"number\">305</span>];</span><br><span class=\"line\">queue &lt;int&gt; q;</span><br><span class=\"line\">int n,m;</span><br><span class=\"line\">int flag=<span class=\"number\">0</span>;                <span class=\"comment\">// 有无负环的标志，有负环 flag=1 </span></span><br><span class=\"line\">int num[<span class=\"number\">305</span>];              <span class=\"comment\">// 存储每个点加入队列的次数 </span></span><br><span class=\"line\">int visit[<span class=\"number\">305</span>];\t\t\t   <span class=\"comment\">// 如果某个点在队列中，那么visit[i]=1，反之为0 </span></span><br><span class=\"line\">int dist[<span class=\"number\">305</span>];\t\t\t   <span class=\"comment\">// 存储距离 </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> spfa(int x)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;n;i++)          <span class=\"comment\">// 初始化 </span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tnum[i]=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\tvisit[i]=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span>(i!=x) dist[i]=<span class=\"number\">10000000</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span>(!q.empty())</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tint a=q.front();</span><br><span class=\"line\">\t\tvisit[a]=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\tq.pop();</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;v[a].size();i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tint c=v[a][i].v;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span>(dist[c]&gt;dist[a]+v[a][i].w)    <span class=\"comment\">// 距离小于当前距离，更新，如果这个点不在队列中则加入队列，且这个点的访问次数+1 </span></span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\tdist[c]=dist[a]+v[a][i].w;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">if</span>(visit[c]==<span class=\"number\">0</span>)</span><br><span class=\"line\">\t\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\t\tnum[c]++; </span><br><span class=\"line\">\t\t\t\t\tq.push(c);</span><br><span class=\"line\">\t\t\t\t\tvisit[c]=<span class=\"number\">1</span>;</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;n;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span>(num[i]&gt;n)            <span class=\"comment\">// 如果对一个点访问次数 &gt;n 则判定为存在负环 </span></span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\tflag=<span class=\"number\">1</span>;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">return</span>;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\tcin&gt;&gt;n&gt;&gt;m;</span><br><span class=\"line\">\tint x,y,z;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;m;i++)         <span class=\"comment\">// 输入边 </span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tcin&gt;&gt;x&gt;&gt;y&gt;&gt;z;</span><br><span class=\"line\">\t\te.v=y;</span><br><span class=\"line\">\t\te.w=z;</span><br><span class=\"line\">\t\tv[x].push_back(e);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;<span class=\"number\">3</span>;i++)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tflag=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\tcin&gt;&gt;x&gt;&gt;y;</span><br><span class=\"line\">\t\te.v=y;</span><br><span class=\"line\">\t\te.w=<span class=\"number\">1000</span>;</span><br><span class=\"line\">\t\tv[x].push_back(e);</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span>(flag==<span class=\"number\">0</span>)        <span class=\"comment\">// 若没有负环则边权减小直到有负环为止</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tq.push(x);</span><br><span class=\"line\">\t\t\te.w--;</span><br><span class=\"line\">\t\t\tv[x].pop_back();</span><br><span class=\"line\">\t\t\tv[x].push_back(e);</span><br><span class=\"line\">\t\t\tspfa(x);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tv[x].pop_back();      <span class=\"comment\">//此时的边权为最大的有负环的权值，加一则没有负环</span></span><br><span class=\"line\">\t\te.w++;</span><br><span class=\"line\">\t\tv[x].push_back(e);</span><br><span class=\"line\">\t\tcout&lt;&lt;e.w&lt;&lt;endl;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"多源最短路-—-floyd-算法\"><a href=\"#多源最短路-—-floyd-算法\" class=\"headerlink\" title=\"多源最短路 — floyd 算法\"></a>多源最短路 — floyd 算法</h3><h4 id=\"算法描述-2\"><a href=\"#算法描述-2\" class=\"headerlink\" title=\"算法描述\"></a>算法描述</h4><p>floyd 算法很简单，先在邻接矩阵中将直接相连的边的权值更新，然后对于任意两个点，以任意一个点为中介，更新两个点之间的权值，注意将当成中介的点放在最外面的循环，如若不然，可以将这三个循环执行三遍，则不用管i,j,k的顺序</p>\n<h4 id=\"代码示例-1\"><a href=\"#代码示例-1\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span>(int k=<span class=\"number\">1</span>;k&lt;=n;k++)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=n;i++)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int j=<span class=\"number\">1</span>;j&lt;=n;j++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span>(dist[i][j]&gt;dist[i][k]+dist[k][j])</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\tdist[i][j]=dist[i][k]+dist[k][j];</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<h2 id=\"单-多源最短路的三种算法-—-dijkstra-amp-spfa-amp-floyd\"><a href=\"#单-多源最短路的三种算法-—-dijkstra-amp-spfa-amp-floyd\" class=\"headerlink\" title=\"单/多源最短路的三种算法 — dijkstra &amp; spfa &amp; floyd\"></a>单/多源最短路的三种算法 — dijkstra &amp; spfa &amp; floyd</h2><h3 id=\"什么是最短路\"><a href=\"#什么是最短路\" class=\"headerlink\" title=\"什么是最短路\"></a>什么是最短路</h3><p>单源最短路：计算图中一个点到其他各点的最短距离<br>多源最短路：计算图中多个点到其他各点的最短距离</p>\n<h3 id=\"单源最短路-—-dijkstra-算法\"><a href=\"#单源最短路-—-dijkstra-算法\" class=\"headerlink\" title=\"单源最短路 — dijkstra 算法\"></a>单源最短路 — dijkstra 算法</h3><h4 id=\"算法描述\"><a href=\"#算法描述\" class=\"headerlink\" title=\"算法描述\"></a>算法描述</h4><p>main 函数：用vector数组存边，初始化一维数组 dist 来表示起点到其他各点的距离（到自己为 0，其他点为 INF），将初始边（目标点为起点，权值为 0）加入到优先队列 queue 中<br>dijkstra 函数：抛出优先队列的 top 边，若这个边的权值比现在到这个目标点的权值大（说明起点到该点的长度又更新了，而且那个边肯定在这个边前面），就跳过，否则就疏松以这个点为起点的所有边，若通过这个点，起始点到其他的点的距离有减小的，则把路径减小的目标点和减小后的距离加入到优先队列中，重复操作<br></p>","more":"<p></p>\n<h4 id=\"算法应用\"><a href=\"#算法应用\" class=\"headerlink\" title=\"算法应用\"></a>算法应用</h4><p>说明：这个题有点意思（</p>\n<h5 id=\"题目描述\"><a href=\"#题目描述\" class=\"headerlink\" title=\"题目描述\"></a>题目描述</h5><p>知识点：最短路，最短路的优化</p>\n<p>贝克兰德有n个城镇，这些城镇之间有m条道路连接，每条道路有一个长度l。</p>\n<p>zf在其中k个城镇设置了治安点。当一个城镇发生事件时，任意一个治安点都可以派人前往。但是为了节省资源，往往会选择距离最近的治安点。</p>\n<p>那么请问，对于每一个城镇，最近的治安点距离为多少。</p>\n<h5 id=\"思路\"><a href=\"#思路\" class=\"headerlink\" title=\"思路\"></a>思路</h5><p>这个题要求算部分点到其他点的最短距离，因此看起来是一个多源最短路，但是你如果执行多次 dijkstra 你就超时了，所以我们要多设立一个虚拟点 s，把所有的治安点往这个虚拟点上拉一条距离为 0的边（无向），以这个点为起点计算到其他点的最短路即满足要求</p>\n<h5 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h5><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* </span></span><br><span class=\"line\"><span class=\"comment\"> Author: 王振</span></span><br><span class=\"line\"><span class=\"comment\"> Result: AC\tSubmission_id: 1833390</span></span><br><span class=\"line\"><span class=\"comment\"> Created at: Fri Sep 13 2019 21:01:55 GMT+0800 (CST)</span></span><br><span class=\"line\"><span class=\"comment\"> Problem_id: 2378\tTime: 540\tMemory: 5508</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\">#include &lt;queue&gt;</span><br><span class=\"line\">#include &lt;vector&gt;</span><br><span class=\"line\">#include &lt;algorithm&gt;</span><br><span class=\"line\">using namespace std;</span><br><span class=\"line\">int n,m,s;</span><br><span class=\"line\">int dist[<span class=\"number\">1005</span>];</span><br><span class=\"line\">struct line&#123;</span><br><span class=\"line\">    int w;</span><br><span class=\"line\">    int v;</span><br><span class=\"line\">    bool operator &lt;(<span class=\"keyword\">const</span> line&amp;b) <span class=\"keyword\">const</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">return</span> w&gt;b.w;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;list;</span><br><span class=\"line\"></span><br><span class=\"line\">vector &lt;line&gt; vec[<span class=\"number\">1005</span>];</span><br><span class=\"line\">priority_queue &lt;line&gt; q;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> dijkstra(int p)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\tlist.v=p;</span><br><span class=\"line\">\tlist.w=<span class=\"number\">0</span>;</span><br><span class=\"line\">\tq.push(list);</span><br><span class=\"line\">\t<span class=\"keyword\">while</span>(!q.empty())</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tstruct line k=q.top();</span><br><span class=\"line\">\t\tq.pop();</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span>(k.w&gt;dist[k.v])</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">continue</span>;</span><br><span class=\"line\">\t\t&#125;<span class=\"keyword\">else</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;vec[k.v].size();i++)</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\tstruct line j=vec[k.v][i];</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">if</span>(dist[j.v]&gt;dist[k.v]+j.w)</span><br><span class=\"line\">\t\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\t\tdist[j.v]=dist[k.v]+j.w;</span><br><span class=\"line\">\t\t\t\t\tlist.v=j.v;</span><br><span class=\"line\">\t\t\t\t\tlist.w=dist[j.v];</span><br><span class=\"line\">\t\t\t\t\tq.push(list);</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\tint t;</span><br><span class=\"line\">\tcin&gt;&gt;t;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span>(t--)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tint u,v,w;</span><br><span class=\"line\">\t\tscanf(<span class=\"string\">\"%d%d%d\"</span>,&amp;n,&amp;m,&amp;s);</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=n+<span class=\"number\">1</span>;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">while</span>(!vec[i].empty())</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\tvec[i].pop_back();</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=n+<span class=\"number\">1</span>;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tdist[i]=<span class=\"number\">10000000</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=s;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tscanf(<span class=\"string\">\"%d\"</span>,&amp;u);</span><br><span class=\"line\">\t\t\tlist.w=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\t\tlist.v=u;</span><br><span class=\"line\">\t\t\tvec[n+<span class=\"number\">1</span>].push_back(list);</span><br><span class=\"line\">\t\t\tlist.v=n+<span class=\"number\">1</span>;</span><br><span class=\"line\">\t\t\tvec[u].push_back(list);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=m;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tscanf(<span class=\"string\">\"%d%d%d\"</span>,&amp;u,&amp;v,&amp;w);</span><br><span class=\"line\">\t\t\tlist.v=v;</span><br><span class=\"line\">\t\t\tlist.w=w;</span><br><span class=\"line\">\t\t\tvec[u].push_back(list);</span><br><span class=\"line\">\t\t\tlist.v=u;</span><br><span class=\"line\">\t\t\tvec[v].push_back(list);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tdist[n+<span class=\"number\">1</span>]=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\tdijkstra(n+<span class=\"number\">1</span>);</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=n;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tprintf(<span class=\"string\">\"%d \"</span>,dist[i]);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tprintf(<span class=\"string\">\"\\n\"</span>);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<h3 id=\"单源最短路-—-spfa-算法-可以判断负环！\"><a href=\"#单源最短路-—-spfa-算法-可以判断负环！\" class=\"headerlink\" title=\"单源最短路 — spfa 算法  可以判断负环！\"></a>单源最短路 — spfa 算法  可以判断负环！</h3><h4 id=\"算法描述-1\"><a href=\"#算法描述-1\" class=\"headerlink\" title=\"算法描述\"></a>算法描述</h4><p>将某个点的序号 x 作为 spfa 函数的输入，则从这个点开始进行单源最短路，如果点 v 通过当前点 u 到输入点 x 的距离变小，那么更新距离值，并且如果 v 不在队列中，就将 v 加入到队列里，对于每个点记录它们加入队列的次数，如果大于总点数 n ,就判定为当前图中存在负环。</p>\n<h4 id=\"题目描述-1\"><a href=\"#题目描述-1\" class=\"headerlink\" title=\"题目描述\"></a>题目描述</h4><p>知识点：最短路</p>\n<p>克莱恩在一场冒险中得到了得到了一个破损的魔法阵，这个魔法阵是一个有n个点m条边的有向有环图，任意两点之间最多只有一条边，每条边有一个能量值a（可能是负数，别问问就是magical），不存在负环。</p>\n<p>克莱恩试图去修补这个魔法阵。已知，这个魔法阵缺少了3条边，且已经知道这3条边的起点和终点（有向）。对于每条边，克莱恩要赋予其一个能量值c，为了避免邪神出现，修补过程以及结束后也不能出现负环。</p>\n<p>请问每次的最小花费是多少(保证有解，可以是负数)。</p>\n<h4 id=\"题目思路\"><a href=\"#题目思路\" class=\"headerlink\" title=\"题目思路\"></a>题目思路</h4><p>修补过程及结束后不能出现负环，则枚举边权来找到最大的可以使图中出现负环的权值，那么给这个权值加一图中就没有负环（其实可以二分权值直接找到答案）</p>\n<h4 id=\"代码示例\"><a href=\"#代码示例\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/* </span></span><br><span class=\"line\"><span class=\"comment\"> Author: 王振</span></span><br><span class=\"line\"><span class=\"comment\"> Result: AC\tSubmission_id: 1833275</span></span><br><span class=\"line\"><span class=\"comment\"> Created at: Fri Sep 13 2019 16:22:27 GMT+0800 (CST)</span></span><br><span class=\"line\"><span class=\"comment\"> Problem_id: 2376\tTime: 790\tMemory: 3228</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"></span><br><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\">#include &lt;queue&gt;</span><br><span class=\"line\">#include &lt;algorithm&gt;</span><br><span class=\"line\">#include &lt;vector&gt;</span><br><span class=\"line\">#include &lt;cmath&gt;</span><br><span class=\"line\">using namespace std;</span><br><span class=\"line\"></span><br><span class=\"line\">struct edge&#123;</span><br><span class=\"line\">\tint v,w;</span><br><span class=\"line\">&#125;e;</span><br><span class=\"line\"></span><br><span class=\"line\">vector &lt;edge&gt; v[<span class=\"number\">305</span>];</span><br><span class=\"line\">queue &lt;int&gt; q;</span><br><span class=\"line\">int n,m;</span><br><span class=\"line\">int flag=<span class=\"number\">0</span>;                <span class=\"comment\">// 有无负环的标志，有负环 flag=1 </span></span><br><span class=\"line\">int num[<span class=\"number\">305</span>];              <span class=\"comment\">// 存储每个点加入队列的次数 </span></span><br><span class=\"line\">int visit[<span class=\"number\">305</span>];\t\t\t   <span class=\"comment\">// 如果某个点在队列中，那么visit[i]=1，反之为0 </span></span><br><span class=\"line\">int dist[<span class=\"number\">305</span>];\t\t\t   <span class=\"comment\">// 存储距离 </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> spfa(int x)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;n;i++)          <span class=\"comment\">// 初始化 </span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tnum[i]=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\tvisit[i]=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span>(i!=x) dist[i]=<span class=\"number\">10000000</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span>(!q.empty())</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tint a=q.front();</span><br><span class=\"line\">\t\tvisit[a]=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\tq.pop();</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;v[a].size();i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tint c=v[a][i].v;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span>(dist[c]&gt;dist[a]+v[a][i].w)    <span class=\"comment\">// 距离小于当前距离，更新，如果这个点不在队列中则加入队列，且这个点的访问次数+1 </span></span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\tdist[c]=dist[a]+v[a][i].w;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">if</span>(visit[c]==<span class=\"number\">0</span>)</span><br><span class=\"line\">\t\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\t\tnum[c]++; </span><br><span class=\"line\">\t\t\t\t\tq.push(c);</span><br><span class=\"line\">\t\t\t\t\tvisit[c]=<span class=\"number\">1</span>;</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;n;i++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span>(num[i]&gt;n)            <span class=\"comment\">// 如果对一个点访问次数 &gt;n 则判定为存在负环 </span></span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\tflag=<span class=\"number\">1</span>;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">return</span>;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\tcin&gt;&gt;n&gt;&gt;m;</span><br><span class=\"line\">\tint x,y,z;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;m;i++)         <span class=\"comment\">// 输入边 </span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tcin&gt;&gt;x&gt;&gt;y&gt;&gt;z;</span><br><span class=\"line\">\t\te.v=y;</span><br><span class=\"line\">\t\te.w=z;</span><br><span class=\"line\">\t\tv[x].push_back(e);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">0</span>;i&lt;<span class=\"number\">3</span>;i++)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tflag=<span class=\"number\">0</span>;</span><br><span class=\"line\">\t\tcin&gt;&gt;x&gt;&gt;y;</span><br><span class=\"line\">\t\te.v=y;</span><br><span class=\"line\">\t\te.w=<span class=\"number\">1000</span>;</span><br><span class=\"line\">\t\tv[x].push_back(e);</span><br><span class=\"line\">\t\t<span class=\"keyword\">while</span>(flag==<span class=\"number\">0</span>)        <span class=\"comment\">// 若没有负环则边权减小直到有负环为止</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tq.push(x);</span><br><span class=\"line\">\t\t\te.w--;</span><br><span class=\"line\">\t\t\tv[x].pop_back();</span><br><span class=\"line\">\t\t\tv[x].push_back(e);</span><br><span class=\"line\">\t\t\tspfa(x);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tv[x].pop_back();      <span class=\"comment\">//此时的边权为最大的有负环的权值，加一则没有负环</span></span><br><span class=\"line\">\t\te.w++;</span><br><span class=\"line\">\t\tv[x].push_back(e);</span><br><span class=\"line\">\t\tcout&lt;&lt;e.w&lt;&lt;endl;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"多源最短路-—-floyd-算法\"><a href=\"#多源最短路-—-floyd-算法\" class=\"headerlink\" title=\"多源最短路 — floyd 算法\"></a>多源最短路 — floyd 算法</h3><h4 id=\"算法描述-2\"><a href=\"#算法描述-2\" class=\"headerlink\" title=\"算法描述\"></a>算法描述</h4><p>floyd 算法很简单，先在邻接矩阵中将直接相连的边的权值更新，然后对于任意两个点，以任意一个点为中介，更新两个点之间的权值，注意将当成中介的点放在最外面的循环，如若不然，可以将这三个循环执行三遍，则不用管i,j,k的顺序</p>\n<h4 id=\"代码示例-1\"><a href=\"#代码示例-1\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span>(int k=<span class=\"number\">1</span>;k&lt;=n;k++)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=n;i++)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int j=<span class=\"number\">1</span>;j&lt;=n;j++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span>(dist[i][j]&gt;dist[i][k]+dist[k][j])</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\tdist[i][j]=dist[i][k]+dist[k][j];</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>"},{"title":"关于此博客","date":"2019-09-20T08:50:01.000Z","_content":"欢迎大家来到我的博客，在下在写博客这方面是一个新人小白，如果有人来看的话，希望不要笑话我O(∩_∩)O\n\n## 我在博客中会写的东西\n\n### 编程学习过程的笔记\n\n\n因为我的编程技术很菜，而且脑子又不好，学了啥都记不住，所以想在我的博客中记录下我学习的东西，以便我在以后的时候通过看我的博客能够快速回顾，如果有人能看到我的博客，也希望能从我的笔记中有一些收获，如果我的笔记能对更多人有帮助的话，我会感到十分荣幸\n\n<!--more-->\n### 其他一些很nice的东西\n\n我们在网络上浏览的时候经常能遇到一些好的网站或是一些其他东西，所以我希望能把它们记录下来\n\n\n目前我的博客中可能只会添加这些东西，如果我有其他想要添加的东西的话，就会更新这篇文章，希望通过此方式我和其他人都能有更大的进步","source":"_posts/关于此博客.md","raw":"---\ntitle: 关于此博客\ndate: 2019-09-20 16:50:01\n---\n欢迎大家来到我的博客，在下在写博客这方面是一个新人小白，如果有人来看的话，希望不要笑话我O(∩_∩)O\n\n## 我在博客中会写的东西\n\n### 编程学习过程的笔记\n\n\n因为我的编程技术很菜，而且脑子又不好，学了啥都记不住，所以想在我的博客中记录下我学习的东西，以便我在以后的时候通过看我的博客能够快速回顾，如果有人能看到我的博客，也希望能从我的笔记中有一些收获，如果我的笔记能对更多人有帮助的话，我会感到十分荣幸\n\n<!--more-->\n### 其他一些很nice的东西\n\n我们在网络上浏览的时候经常能遇到一些好的网站或是一些其他东西，所以我希望能把它们记录下来\n\n\n目前我的博客中可能只会添加这些东西，如果我有其他想要添加的东西的话，就会更新这篇文章，希望通过此方式我和其他人都能有更大的进步","slug":"关于此博客","published":1,"updated":"2019-09-29T10:05:00.369Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh701y000ea0uzp7cwxght","content":"<p>欢迎大家来到我的博客，在下在写博客这方面是一个新人小白，如果有人来看的话，希望不要笑话我O(∩_∩)O</p>\n<h2 id=\"我在博客中会写的东西\"><a href=\"#我在博客中会写的东西\" class=\"headerlink\" title=\"我在博客中会写的东西\"></a>我在博客中会写的东西</h2><h3 id=\"编程学习过程的笔记\"><a href=\"#编程学习过程的笔记\" class=\"headerlink\" title=\"编程学习过程的笔记\"></a>编程学习过程的笔记</h3><p>因为我的编程技术很菜，而且脑子又不好，学了啥都记不住，所以想在我的博客中记录下我学习的东西，以便我在以后的时候通过看我的博客能够快速回顾，如果有人能看到我的博客，也希望能从我的笔记中有一些收获，如果我的笔记能对更多人有帮助的话，我会感到十分荣幸</p>\n<a id=\"more\"></a>\n<h3 id=\"其他一些很nice的东西\"><a href=\"#其他一些很nice的东西\" class=\"headerlink\" title=\"其他一些很nice的东西\"></a>其他一些很nice的东西</h3><p>我们在网络上浏览的时候经常能遇到一些好的网站或是一些其他东西，所以我希望能把它们记录下来</p>\n<p>目前我的博客中可能只会添加这些东西，如果我有其他想要添加的东西的话，就会更新这篇文章，希望通过此方式我和其他人都能有更大的进步</p>\n","site":{"data":{}},"excerpt":"<p>欢迎大家来到我的博客，在下在写博客这方面是一个新人小白，如果有人来看的话，希望不要笑话我O(∩_∩)O</p>\n<h2 id=\"我在博客中会写的东西\"><a href=\"#我在博客中会写的东西\" class=\"headerlink\" title=\"我在博客中会写的东西\"></a>我在博客中会写的东西</h2><h3 id=\"编程学习过程的笔记\"><a href=\"#编程学习过程的笔记\" class=\"headerlink\" title=\"编程学习过程的笔记\"></a>编程学习过程的笔记</h3><p>因为我的编程技术很菜，而且脑子又不好，学了啥都记不住，所以想在我的博客中记录下我学习的东西，以便我在以后的时候通过看我的博客能够快速回顾，如果有人能看到我的博客，也希望能从我的笔记中有一些收获，如果我的笔记能对更多人有帮助的话，我会感到十分荣幸</p>","more":"<h3 id=\"其他一些很nice的东西\"><a href=\"#其他一些很nice的东西\" class=\"headerlink\" title=\"其他一些很nice的东西\"></a>其他一些很nice的东西</h3><p>我们在网络上浏览的时候经常能遇到一些好的网站或是一些其他东西，所以我希望能把它们记录下来</p>\n<p>目前我的博客中可能只会添加这些东西，如果我有其他想要添加的东西的话，就会更新这篇文章，希望通过此方式我和其他人都能有更大的进步</p>"},{"title":"最小生成树","date":"2019-09-24T05:54:47.000Z","_content":"\n## 最小生成树的两种算法 -- Prim & Kruscal\n\n### 什么是最小生成树\n\n最小生成树是一副连通加权无向图中一棵权值最小的生成树。\n\n在一给定的无向图 G = (V, E) 中，(u, v) 代表连接顶点 u 与顶点 v 的边（即 {\\displaystyle (u,v)\\in E}(u,v)\\in E），而 w(u, v) 代表此边的权重，若存在 T 为 E 的子集且 (V, T) 为树，使得 w(T) 最小，则此 T 为 G 的最小生成树。\n<!--more-->\n### 最小生成树 -- Prim 算法\n\n#### 算法描述\n\n0. 准备：定义一个二维数组 dist 来存储每两个点之间的距离，定义一个一维数组 minc 来存储每个点到已经在最小生成树中的点的最小距离\n1. 初始化邻接矩阵，然后通过输入的数据来改变邻接矩阵\n2. 选择一个顶点 s 作为最小生成树中的点，初始化 minc 数组，其中 minc[s] 为 0 ，若其他点到 s 有边，则初始化为边的权重，否则初始化为 MAX 值\n3. 选择 minc 数组中不为 0 且最小的一个值对应的点，加入最小生成树，将该值变为 0，更新其他点到最小生成树中的点的最小距离\n4. 重复第三步操作直到所有的点都加入到最小生成树中\n\n#### 代码示例\n\n{% codeblock lang:JavaScript %}\n#include <stdio.h>\n#define M 5001\n#define INF 99999999\nint n,e1,e;\nint dist[M][M];\nint minc[M];\n\nvoid solve(int s)\n{\n    int i,j,count=0,min,k;\n    for(i=1;i<=n;i++)\n    {\n    \tminc[i]=dist[s][i];\n\t}\n    minc[s]=0;\n    for(i=1;i<n;i++)\n\t{\n        min=INF;\n        for(j=1;j<=n;j++)\n\t\t{\n            if(minc[j] && minc[j]<min)\n\t\t\t{\n                min=minc[j];\n                k=j;\n            }\n        }\n        minc[k]=0;\n        count+=min;\n        for(j=1;j<=n;j++)\n\t\t{\n            if(dist[k][j]<minc[j])\n            {\n            \tminc[j]=dist[k][j];\n\t\t\t}\n        }\n    }\n    printf(\"%d\",count);\n}\n\nint main()\n{\n    int t1,t2,t3,i,j;\n    for(i=0;i<M;i++)\n    {\n    \tfor(j=0;j<M;j++)\n    \t{\n    \t\tdist[i][j]=INF;\n\t\t}\n\t}\n    scanf(\"%d%d\",&n,&e);\n    for(i=1;i<=e;i++)\n\t{\n        scanf(\"%d%d%d\",&t1,&t2,&t3);\n        if(t3<dist[t1][t2])\n        {\n        \tdist[t2][t1]=dist[t1][t2]=t3;\n\t\t}\n    }\n    solve(1);\n    return 0;\n}\n{% endcodeblock %}\n\n### 最小生成树 -- kruscal 算法\n\n#### 算法描述\n\n0. 准备：并查集的知识\n1. 用邻接链表存储每一条边，再用一个结构数组存储所有的边，将结构数组按照边的权值大小从小到大排序\n2. 遍历结构数组，如果一条边的两个端点的祖宗不同，则将起点的祖宗的祖宗设为终点的祖宗（有点绕嘴），否则直接跳到下一条边\n3. 重复 2 操作，直到所有的点都加入到了最小生成树中\n\n#### 代码示例\n\n{% codeblock lang:JavaScript %}\n#include <stdio.h>\n#include <stdlib.h>\nint n,m,i,j,u,v,total;\nstruct edge{\n\tint start,to;\n\tlong long val;\n}bian[200005];\nint f[100000];\nlong long ans;\n\nint find(int x)\n    if(f[x]==x)\n    {\n    \treturn x;\n\t}else \n    {\n        f[x]=find(f[x]);\n        return f[x];\n    }   \n}\n\nvoid kruskal()\n{\n\n    for(i=1;i<=m;i++)\n    {\n        u=find(bian[i].start);\n        v=find(bian[i].to);\n        if(u==v) continue;\n            ans+=bian[i].val;\n            f[u]=v;\n            total++;\n            if(total==n-1) break;\n    }\n} \n\nint cmp(const void *ap,const void *bp)\n{\n\tconst struct edge *a=(struct edge *)ap;\n\tconst struct edge *b=(struct edge *)bp;\n\treturn a->val-b->val;\n}\n\nint main()\n{\n    scanf(\"%d%d\",&n,&m);\n    for(i=1;i<=n;i++) \n    {\n    \tf[i]=i;\n\t}\n    for(i=1;i<=m;i++)\n    {\n        scanf(\"%d%d%d\",&bian[i].start,&bian[i].to,&bian[i].val);\n    }\n    qsort(bian+1,m,sizeof(struct edge),cmp);\n    kruskal();\n    printf(\"%d\",ans);\n    return 0;\n}\n{% endcodeblock %}\n\n### 注意事项\n\nPrim 算法多用于稠密图，Kruscal 算法多用于稀疏图","source":"_posts/最小生成树.md","raw":"---\ntitle: 最小生成树\ndate: 2019-09-24 13:54:47\ntags:\n    - 数据结构\n---\n\n## 最小生成树的两种算法 -- Prim & Kruscal\n\n### 什么是最小生成树\n\n最小生成树是一副连通加权无向图中一棵权值最小的生成树。\n\n在一给定的无向图 G = (V, E) 中，(u, v) 代表连接顶点 u 与顶点 v 的边（即 {\\displaystyle (u,v)\\in E}(u,v)\\in E），而 w(u, v) 代表此边的权重，若存在 T 为 E 的子集且 (V, T) 为树，使得 w(T) 最小，则此 T 为 G 的最小生成树。\n<!--more-->\n### 最小生成树 -- Prim 算法\n\n#### 算法描述\n\n0. 准备：定义一个二维数组 dist 来存储每两个点之间的距离，定义一个一维数组 minc 来存储每个点到已经在最小生成树中的点的最小距离\n1. 初始化邻接矩阵，然后通过输入的数据来改变邻接矩阵\n2. 选择一个顶点 s 作为最小生成树中的点，初始化 minc 数组，其中 minc[s] 为 0 ，若其他点到 s 有边，则初始化为边的权重，否则初始化为 MAX 值\n3. 选择 minc 数组中不为 0 且最小的一个值对应的点，加入最小生成树，将该值变为 0，更新其他点到最小生成树中的点的最小距离\n4. 重复第三步操作直到所有的点都加入到最小生成树中\n\n#### 代码示例\n\n{% codeblock lang:JavaScript %}\n#include <stdio.h>\n#define M 5001\n#define INF 99999999\nint n,e1,e;\nint dist[M][M];\nint minc[M];\n\nvoid solve(int s)\n{\n    int i,j,count=0,min,k;\n    for(i=1;i<=n;i++)\n    {\n    \tminc[i]=dist[s][i];\n\t}\n    minc[s]=0;\n    for(i=1;i<n;i++)\n\t{\n        min=INF;\n        for(j=1;j<=n;j++)\n\t\t{\n            if(minc[j] && minc[j]<min)\n\t\t\t{\n                min=minc[j];\n                k=j;\n            }\n        }\n        minc[k]=0;\n        count+=min;\n        for(j=1;j<=n;j++)\n\t\t{\n            if(dist[k][j]<minc[j])\n            {\n            \tminc[j]=dist[k][j];\n\t\t\t}\n        }\n    }\n    printf(\"%d\",count);\n}\n\nint main()\n{\n    int t1,t2,t3,i,j;\n    for(i=0;i<M;i++)\n    {\n    \tfor(j=0;j<M;j++)\n    \t{\n    \t\tdist[i][j]=INF;\n\t\t}\n\t}\n    scanf(\"%d%d\",&n,&e);\n    for(i=1;i<=e;i++)\n\t{\n        scanf(\"%d%d%d\",&t1,&t2,&t3);\n        if(t3<dist[t1][t2])\n        {\n        \tdist[t2][t1]=dist[t1][t2]=t3;\n\t\t}\n    }\n    solve(1);\n    return 0;\n}\n{% endcodeblock %}\n\n### 最小生成树 -- kruscal 算法\n\n#### 算法描述\n\n0. 准备：并查集的知识\n1. 用邻接链表存储每一条边，再用一个结构数组存储所有的边，将结构数组按照边的权值大小从小到大排序\n2. 遍历结构数组，如果一条边的两个端点的祖宗不同，则将起点的祖宗的祖宗设为终点的祖宗（有点绕嘴），否则直接跳到下一条边\n3. 重复 2 操作，直到所有的点都加入到了最小生成树中\n\n#### 代码示例\n\n{% codeblock lang:JavaScript %}\n#include <stdio.h>\n#include <stdlib.h>\nint n,m,i,j,u,v,total;\nstruct edge{\n\tint start,to;\n\tlong long val;\n}bian[200005];\nint f[100000];\nlong long ans;\n\nint find(int x)\n    if(f[x]==x)\n    {\n    \treturn x;\n\t}else \n    {\n        f[x]=find(f[x]);\n        return f[x];\n    }   \n}\n\nvoid kruskal()\n{\n\n    for(i=1;i<=m;i++)\n    {\n        u=find(bian[i].start);\n        v=find(bian[i].to);\n        if(u==v) continue;\n            ans+=bian[i].val;\n            f[u]=v;\n            total++;\n            if(total==n-1) break;\n    }\n} \n\nint cmp(const void *ap,const void *bp)\n{\n\tconst struct edge *a=(struct edge *)ap;\n\tconst struct edge *b=(struct edge *)bp;\n\treturn a->val-b->val;\n}\n\nint main()\n{\n    scanf(\"%d%d\",&n,&m);\n    for(i=1;i<=n;i++) \n    {\n    \tf[i]=i;\n\t}\n    for(i=1;i<=m;i++)\n    {\n        scanf(\"%d%d%d\",&bian[i].start,&bian[i].to,&bian[i].val);\n    }\n    qsort(bian+1,m,sizeof(struct edge),cmp);\n    kruskal();\n    printf(\"%d\",ans);\n    return 0;\n}\n{% endcodeblock %}\n\n### 注意事项\n\nPrim 算法多用于稠密图，Kruscal 算法多用于稀疏图","slug":"最小生成树","published":1,"updated":"2019-11-25T13:17:07.382Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh7028000ga0uzxllhuef6","content":"<h2 id=\"最小生成树的两种算法-—-Prim-amp-Kruscal\"><a href=\"#最小生成树的两种算法-—-Prim-amp-Kruscal\" class=\"headerlink\" title=\"最小生成树的两种算法 — Prim &amp; Kruscal\"></a>最小生成树的两种算法 — Prim &amp; Kruscal</h2><h3 id=\"什么是最小生成树\"><a href=\"#什么是最小生成树\" class=\"headerlink\" title=\"什么是最小生成树\"></a>什么是最小生成树</h3><p>最小生成树是一副连通加权无向图中一棵权值最小的生成树。</p>\n<p>在一给定的无向图 G = (V, E) 中，(u, v) 代表连接顶点 u 与顶点 v 的边（即 {\\displaystyle (u,v)\\in E}(u,v)\\in E），而 w(u, v) 代表此边的权重，若存在 T 为 E 的子集且 (V, T) 为树，使得 w(T) 最小，则此 T 为 G 的最小生成树。<br><a id=\"more\"></a></p>\n<h3 id=\"最小生成树-—-Prim-算法\"><a href=\"#最小生成树-—-Prim-算法\" class=\"headerlink\" title=\"最小生成树 — Prim 算法\"></a>最小生成树 — Prim 算法</h3><h4 id=\"算法描述\"><a href=\"#算法描述\" class=\"headerlink\" title=\"算法描述\"></a>算法描述</h4><ol>\n<li>准备：定义一个二维数组 dist 来存储每两个点之间的距离，定义一个一维数组 minc 来存储每个点到已经在最小生成树中的点的最小距离</li>\n<li>初始化邻接矩阵，然后通过输入的数据来改变邻接矩阵</li>\n<li>选择一个顶点 s 作为最小生成树中的点，初始化 minc 数组，其中 minc[s] 为 0 ，若其他点到 s 有边，则初始化为边的权重，否则初始化为 MAX 值</li>\n<li>选择 minc 数组中不为 0 且最小的一个值对应的点，加入最小生成树，将该值变为 0，更新其他点到最小生成树中的点的最小距离</li>\n<li>重复第三步操作直到所有的点都加入到最小生成树中</li>\n</ol>\n<h4 id=\"代码示例\"><a href=\"#代码示例\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#define M 5001</span><br><span class=\"line\">#define INF 99999999</span><br><span class=\"line\">int n,e1,e;</span><br><span class=\"line\">int dist[M][M];</span><br><span class=\"line\">int minc[M];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> solve(int s)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int i,j,count=<span class=\"number\">0</span>,min,k;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=n;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    \tminc[i]=dist[s][i];</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    minc[s]=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;n;i++)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">        min=INF;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(j=<span class=\"number\">1</span>;j&lt;=n;j++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(minc[j] &amp;&amp; minc[j]&lt;min)</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">                min=minc[j];</span><br><span class=\"line\">                k=j;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        minc[k]=<span class=\"number\">0</span>;</span><br><span class=\"line\">        count+=min;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(j=<span class=\"number\">1</span>;j&lt;=n;j++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(dist[k][j]&lt;minc[j])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">            \tminc[j]=dist[k][j];</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    printf(<span class=\"string\">\"%d\"</span>,count);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int t1,t2,t3,i,j;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>;i&lt;M;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">for</span>(j=<span class=\"number\">0</span>;j&lt;M;j++)</span><br><span class=\"line\">    \t&#123;</span><br><span class=\"line\">    \t\tdist[i][j]=INF;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    scanf(<span class=\"string\">\"%d%d\"</span>,&amp;n,&amp;e);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=e;i++)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">        scanf(<span class=\"string\">\"%d%d%d\"</span>,&amp;t1,&amp;t2,&amp;t3);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(t3&lt;dist[t1][t2])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">        \tdist[t2][t1]=dist[t1][t2]=t3;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    solve(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"最小生成树-—-kruscal-算法\"><a href=\"#最小生成树-—-kruscal-算法\" class=\"headerlink\" title=\"最小生成树 — kruscal 算法\"></a>最小生成树 — kruscal 算法</h3><h4 id=\"算法描述-1\"><a href=\"#算法描述-1\" class=\"headerlink\" title=\"算法描述\"></a>算法描述</h4><ol>\n<li>准备：并查集的知识</li>\n<li>用邻接链表存储每一条边，再用一个结构数组存储所有的边，将结构数组按照边的权值大小从小到大排序</li>\n<li>遍历结构数组，如果一条边的两个端点的祖宗不同，则将起点的祖宗的祖宗设为终点的祖宗（有点绕嘴），否则直接跳到下一条边</li>\n<li>重复 2 操作，直到所有的点都加入到了最小生成树中</li>\n</ol>\n<h4 id=\"代码示例-1\"><a href=\"#代码示例-1\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">int n,m,i,j,u,v,total;</span><br><span class=\"line\">struct edge&#123;</span><br><span class=\"line\">\tint start,to;</span><br><span class=\"line\">\tlong long val;</span><br><span class=\"line\">&#125;bian[<span class=\"number\">200005</span>];</span><br><span class=\"line\">int f[<span class=\"number\">100000</span>];</span><br><span class=\"line\">long long ans;</span><br><span class=\"line\"></span><br><span class=\"line\">int find(int x)</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(f[x]==x)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">return</span> x;</span><br><span class=\"line\">\t&#125;<span class=\"keyword\">else</span> </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        f[x]=find(f[x]);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> f[x];</span><br><span class=\"line\">    &#125;   </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> kruskal()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=m;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        u=find(bian[i].start);</span><br><span class=\"line\">        v=find(bian[i].to);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(u==v) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">            ans+=bian[i].val;</span><br><span class=\"line\">            f[u]=v;</span><br><span class=\"line\">            total++;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(total==n<span class=\"number\">-1</span>) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125; </span><br><span class=\"line\"></span><br><span class=\"line\">int cmp(<span class=\"keyword\">const</span> <span class=\"keyword\">void</span> *ap,<span class=\"keyword\">const</span> <span class=\"keyword\">void</span> *bp)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">const</span> struct edge *a=(struct edge *)ap;</span><br><span class=\"line\">\t<span class=\"keyword\">const</span> struct edge *b=(struct edge *)bp;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> a-&gt;val-b-&gt;val;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    scanf(<span class=\"string\">\"%d%d\"</span>,&amp;n,&amp;m);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=n;i++) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    \tf[i]=i;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=m;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        scanf(<span class=\"string\">\"%d%d%d\"</span>,&amp;bian[i].start,&amp;bian[i].to,&amp;bian[i].val);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    qsort(bian+<span class=\"number\">1</span>,m,sizeof(struct edge),cmp);</span><br><span class=\"line\">    kruskal();</span><br><span class=\"line\">    printf(<span class=\"string\">\"%d\"</span>,ans);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"注意事项\"><a href=\"#注意事项\" class=\"headerlink\" title=\"注意事项\"></a>注意事项</h3><p>Prim 算法多用于稠密图，Kruscal 算法多用于稀疏图</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"最小生成树的两种算法-—-Prim-amp-Kruscal\"><a href=\"#最小生成树的两种算法-—-Prim-amp-Kruscal\" class=\"headerlink\" title=\"最小生成树的两种算法 — Prim &amp; Kruscal\"></a>最小生成树的两种算法 — Prim &amp; Kruscal</h2><h3 id=\"什么是最小生成树\"><a href=\"#什么是最小生成树\" class=\"headerlink\" title=\"什么是最小生成树\"></a>什么是最小生成树</h3><p>最小生成树是一副连通加权无向图中一棵权值最小的生成树。</p>\n<p>在一给定的无向图 G = (V, E) 中，(u, v) 代表连接顶点 u 与顶点 v 的边（即 {\\displaystyle (u,v)\\in E}(u,v)\\in E），而 w(u, v) 代表此边的权重，若存在 T 为 E 的子集且 (V, T) 为树，使得 w(T) 最小，则此 T 为 G 的最小生成树。<br></p>","more":"<p></p>\n<h3 id=\"最小生成树-—-Prim-算法\"><a href=\"#最小生成树-—-Prim-算法\" class=\"headerlink\" title=\"最小生成树 — Prim 算法\"></a>最小生成树 — Prim 算法</h3><h4 id=\"算法描述\"><a href=\"#算法描述\" class=\"headerlink\" title=\"算法描述\"></a>算法描述</h4><ol>\n<li>准备：定义一个二维数组 dist 来存储每两个点之间的距离，定义一个一维数组 minc 来存储每个点到已经在最小生成树中的点的最小距离</li>\n<li>初始化邻接矩阵，然后通过输入的数据来改变邻接矩阵</li>\n<li>选择一个顶点 s 作为最小生成树中的点，初始化 minc 数组，其中 minc[s] 为 0 ，若其他点到 s 有边，则初始化为边的权重，否则初始化为 MAX 值</li>\n<li>选择 minc 数组中不为 0 且最小的一个值对应的点，加入最小生成树，将该值变为 0，更新其他点到最小生成树中的点的最小距离</li>\n<li>重复第三步操作直到所有的点都加入到最小生成树中</li>\n</ol>\n<h4 id=\"代码示例\"><a href=\"#代码示例\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#define M 5001</span><br><span class=\"line\">#define INF 99999999</span><br><span class=\"line\">int n,e1,e;</span><br><span class=\"line\">int dist[M][M];</span><br><span class=\"line\">int minc[M];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> solve(int s)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int i,j,count=<span class=\"number\">0</span>,min,k;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=n;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    \tminc[i]=dist[s][i];</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    minc[s]=<span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;n;i++)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">        min=INF;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(j=<span class=\"number\">1</span>;j&lt;=n;j++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(minc[j] &amp;&amp; minc[j]&lt;min)</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">                min=minc[j];</span><br><span class=\"line\">                k=j;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        minc[k]=<span class=\"number\">0</span>;</span><br><span class=\"line\">        count+=min;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(j=<span class=\"number\">1</span>;j&lt;=n;j++)</span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(dist[k][j]&lt;minc[j])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">            \tminc[j]=dist[k][j];</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    printf(<span class=\"string\">\"%d\"</span>,count);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int t1,t2,t3,i,j;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>;i&lt;M;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">for</span>(j=<span class=\"number\">0</span>;j&lt;M;j++)</span><br><span class=\"line\">    \t&#123;</span><br><span class=\"line\">    \t\tdist[i][j]=INF;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    scanf(<span class=\"string\">\"%d%d\"</span>,&amp;n,&amp;e);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=e;i++)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">        scanf(<span class=\"string\">\"%d%d%d\"</span>,&amp;t1,&amp;t2,&amp;t3);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(t3&lt;dist[t1][t2])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">        \tdist[t2][t1]=dist[t1][t2]=t3;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    solve(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"最小生成树-—-kruscal-算法\"><a href=\"#最小生成树-—-kruscal-算法\" class=\"headerlink\" title=\"最小生成树 — kruscal 算法\"></a>最小生成树 — kruscal 算法</h3><h4 id=\"算法描述-1\"><a href=\"#算法描述-1\" class=\"headerlink\" title=\"算法描述\"></a>算法描述</h4><ol>\n<li>准备：并查集的知识</li>\n<li>用邻接链表存储每一条边，再用一个结构数组存储所有的边，将结构数组按照边的权值大小从小到大排序</li>\n<li>遍历结构数组，如果一条边的两个端点的祖宗不同，则将起点的祖宗的祖宗设为终点的祖宗（有点绕嘴），否则直接跳到下一条边</li>\n<li>重复 2 操作，直到所有的点都加入到了最小生成树中</li>\n</ol>\n<h4 id=\"代码示例-1\"><a href=\"#代码示例-1\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">int n,m,i,j,u,v,total;</span><br><span class=\"line\">struct edge&#123;</span><br><span class=\"line\">\tint start,to;</span><br><span class=\"line\">\tlong long val;</span><br><span class=\"line\">&#125;bian[<span class=\"number\">200005</span>];</span><br><span class=\"line\">int f[<span class=\"number\">100000</span>];</span><br><span class=\"line\">long long ans;</span><br><span class=\"line\"></span><br><span class=\"line\">int find(int x)</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(f[x]==x)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">return</span> x;</span><br><span class=\"line\">\t&#125;<span class=\"keyword\">else</span> </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        f[x]=find(f[x]);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> f[x];</span><br><span class=\"line\">    &#125;   </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> kruskal()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=m;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        u=find(bian[i].start);</span><br><span class=\"line\">        v=find(bian[i].to);</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(u==v) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">            ans+=bian[i].val;</span><br><span class=\"line\">            f[u]=v;</span><br><span class=\"line\">            total++;</span><br><span class=\"line\">            <span class=\"keyword\">if</span>(total==n<span class=\"number\">-1</span>) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125; </span><br><span class=\"line\"></span><br><span class=\"line\">int cmp(<span class=\"keyword\">const</span> <span class=\"keyword\">void</span> *ap,<span class=\"keyword\">const</span> <span class=\"keyword\">void</span> *bp)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">const</span> struct edge *a=(struct edge *)ap;</span><br><span class=\"line\">\t<span class=\"keyword\">const</span> struct edge *b=(struct edge *)bp;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> a-&gt;val-b-&gt;val;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    scanf(<span class=\"string\">\"%d%d\"</span>,&amp;n,&amp;m);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=n;i++) </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">    \tf[i]=i;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=m;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        scanf(<span class=\"string\">\"%d%d%d\"</span>,&amp;bian[i].start,&amp;bian[i].to,&amp;bian[i].val);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    qsort(bian+<span class=\"number\">1</span>,m,sizeof(struct edge),cmp);</span><br><span class=\"line\">    kruskal();</span><br><span class=\"line\">    printf(<span class=\"string\">\"%d\"</span>,ans);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"注意事项\"><a href=\"#注意事项\" class=\"headerlink\" title=\"注意事项\"></a>注意事项</h3><p>Prim 算法多用于稠密图，Kruscal 算法多用于稀疏图</p>"},{"title":"状压dp","date":"2019-09-22T14:33:50.000Z","_content":"\n## 题目：互不侵犯\n\n### 题目描述\n\n在 N*N 的棋盘里面放 K 个国王，使他们互不攻击，共有多少种摆放方案。国王能攻击到它上下左右，以及左上左下右上右下八个方向上附近的各一个格子，共 8 个格子。\n<!--more-->\n### 输入\n\n只有一行，包含两个数 N, K。\n\n### 输出\n\n所得的方案数。\n\n### 输入样例\n\n{% codeblock  %}\n3 2\n{% endcodeblock %}\n\n### 输出样例\n\n{% codeblock  %}\n16\n{% endcodeblock %}\n\n## 思路\n\n### 关于 状压dp\n\n状压dp是动态规划的一种，通过将状态压缩为整数来达到优化转移的目的。\n具体来说，我们可以用一个二进制数的每一个二进制位来表示一个位置的状态，在这个题中，我们就可以用 0 来表示该位置不放置国王，用 1 来表示该位置放置国王\n因为棋盘是一个 N*N 大小的矩阵，我们就可以每一行用一个二进制数来表示该行国王的放置情况\n\n### 具体操作\n\n见代码注释\n\n### 代码\n\n这里是本蒟蒻的代码~\n\n{% codeblock lang:JavaScript %}\n#include <iostream>\n#include <algorithm>\nusing namespace std;\n\nint n,k,cnt;    // n为棋盘的大小，k为国王的个数，cnt为只考虑一行的情况下（即一个国王的左右不能放置国王）放置国王的所有可能情况（国王为任意数量）\nlong long sta[2005],sit[2005];      // sta数组存储各个情况放置的国王的数目 sit数组存储各个情况下国王的放置位置（用一个二进制数来表示）\nint f[15][2005][105];               // f数组的第一维是当前的行数，第二维是放置国王的所有情况中的第几个，第三维是到该行总共放置国王的个数\n\nvoid dfs(int x,int num,int cur)    // 预处理出单行情况放置国王的所有情况 x:国王的放置位置(一个二进制数) num:放置国王的个数 cur:当前搜到的位置\n{\n\tif(cur>=n)         // cur>=n 表示一行搜完\n\t{\n\t\tsit[++cnt]=x;  \n\t\tsta[cnt]=num;\n\t\treturn;\n\t}\n\tdfs(x,num,cur+1);     //该位置不放国王\n\tdfs(x+(1<<cur),num+1,cur+2);      //该位置放国王\n}\n\nint main()\n{\n\twhile(cin>>n>>k)\n\t{\n\t\tdfs(0,0,0);        //预处理出所有情况\n\t\tfor(int i=1;i<=cnt;i++)       //将结果赋给第一行\n\t\t{\n\t\t\tf[1][i][sta[i]]=1;\n\t\t}\n\t\tfor(int i=2;i<=n;i++)         //从第 2 行到第 n 行，对于前一行的所有可能状态，当前行用所有的可能状态进行比较\n\t\t{\n\t\t\tfor(int j=1;j<=cnt;j++)\n\t\t\t{\n\t\t\t\tfor(int l=1;l<=cnt;l++)\n\t\t\t\t{\n\t\t\t\t\tif(sit[j]&sit[l]) continue;\n\t\t\t\t\tif((sit[j]<<1)&sit[l]) continue;\n\t\t\t\t\tif(sit[j]&(sit[l]<<1)) continue;\n                    //上面这三行用来排除不合法的转移     即当前行有国王的上方或左上或右上存在国王\n\n\t\t\t\t\tfor(int p=sta[j];p<=k;p++)     // 如果两行没有冲突  则当前行放置 sta[j] 个国王\n\t\t\t\t\t{\n\t\t\t\t\t\tf[i][j][p]+=f[i-1][l][p-sta[j]];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tlong long ans=0;       // ans为答案\n\t\tfor(int i=1;i<=cnt;i++)      // ans加上第n行的每一种情况下放置k个国王的总数\n\t\t{\n\t\t\tans+=f[n][i][k];\n\t\t}\n\t\tcout<<ans<<endl;\n\t}\n\treturn 0;\n}\n{% endcodeblock %}\n\n感谢观看~","source":"_posts/状压dp.md","raw":"---\ntitle: 状压dp\ndate: 2019-09-22 22:33:50\ntags: [算法,动态规划]\n---\n\n## 题目：互不侵犯\n\n### 题目描述\n\n在 N*N 的棋盘里面放 K 个国王，使他们互不攻击，共有多少种摆放方案。国王能攻击到它上下左右，以及左上左下右上右下八个方向上附近的各一个格子，共 8 个格子。\n<!--more-->\n### 输入\n\n只有一行，包含两个数 N, K。\n\n### 输出\n\n所得的方案数。\n\n### 输入样例\n\n{% codeblock  %}\n3 2\n{% endcodeblock %}\n\n### 输出样例\n\n{% codeblock  %}\n16\n{% endcodeblock %}\n\n## 思路\n\n### 关于 状压dp\n\n状压dp是动态规划的一种，通过将状态压缩为整数来达到优化转移的目的。\n具体来说，我们可以用一个二进制数的每一个二进制位来表示一个位置的状态，在这个题中，我们就可以用 0 来表示该位置不放置国王，用 1 来表示该位置放置国王\n因为棋盘是一个 N*N 大小的矩阵，我们就可以每一行用一个二进制数来表示该行国王的放置情况\n\n### 具体操作\n\n见代码注释\n\n### 代码\n\n这里是本蒟蒻的代码~\n\n{% codeblock lang:JavaScript %}\n#include <iostream>\n#include <algorithm>\nusing namespace std;\n\nint n,k,cnt;    // n为棋盘的大小，k为国王的个数，cnt为只考虑一行的情况下（即一个国王的左右不能放置国王）放置国王的所有可能情况（国王为任意数量）\nlong long sta[2005],sit[2005];      // sta数组存储各个情况放置的国王的数目 sit数组存储各个情况下国王的放置位置（用一个二进制数来表示）\nint f[15][2005][105];               // f数组的第一维是当前的行数，第二维是放置国王的所有情况中的第几个，第三维是到该行总共放置国王的个数\n\nvoid dfs(int x,int num,int cur)    // 预处理出单行情况放置国王的所有情况 x:国王的放置位置(一个二进制数) num:放置国王的个数 cur:当前搜到的位置\n{\n\tif(cur>=n)         // cur>=n 表示一行搜完\n\t{\n\t\tsit[++cnt]=x;  \n\t\tsta[cnt]=num;\n\t\treturn;\n\t}\n\tdfs(x,num,cur+1);     //该位置不放国王\n\tdfs(x+(1<<cur),num+1,cur+2);      //该位置放国王\n}\n\nint main()\n{\n\twhile(cin>>n>>k)\n\t{\n\t\tdfs(0,0,0);        //预处理出所有情况\n\t\tfor(int i=1;i<=cnt;i++)       //将结果赋给第一行\n\t\t{\n\t\t\tf[1][i][sta[i]]=1;\n\t\t}\n\t\tfor(int i=2;i<=n;i++)         //从第 2 行到第 n 行，对于前一行的所有可能状态，当前行用所有的可能状态进行比较\n\t\t{\n\t\t\tfor(int j=1;j<=cnt;j++)\n\t\t\t{\n\t\t\t\tfor(int l=1;l<=cnt;l++)\n\t\t\t\t{\n\t\t\t\t\tif(sit[j]&sit[l]) continue;\n\t\t\t\t\tif((sit[j]<<1)&sit[l]) continue;\n\t\t\t\t\tif(sit[j]&(sit[l]<<1)) continue;\n                    //上面这三行用来排除不合法的转移     即当前行有国王的上方或左上或右上存在国王\n\n\t\t\t\t\tfor(int p=sta[j];p<=k;p++)     // 如果两行没有冲突  则当前行放置 sta[j] 个国王\n\t\t\t\t\t{\n\t\t\t\t\t\tf[i][j][p]+=f[i-1][l][p-sta[j]];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tlong long ans=0;       // ans为答案\n\t\tfor(int i=1;i<=cnt;i++)      // ans加上第n行的每一种情况下放置k个国王的总数\n\t\t{\n\t\t\tans+=f[n][i][k];\n\t\t}\n\t\tcout<<ans<<endl;\n\t}\n\treturn 0;\n}\n{% endcodeblock %}\n\n感谢观看~","slug":"状压dp","published":1,"updated":"2019-09-29T10:05:14.417Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh702g000ia0uzix55gl43","content":"<h2 id=\"题目：互不侵犯\"><a href=\"#题目：互不侵犯\" class=\"headerlink\" title=\"题目：互不侵犯\"></a>题目：互不侵犯</h2><h3 id=\"题目描述\"><a href=\"#题目描述\" class=\"headerlink\" title=\"题目描述\"></a>题目描述</h3><p>在 N*N 的棋盘里面放 K 个国王，使他们互不攻击，共有多少种摆放方案。国王能攻击到它上下左右，以及左上左下右上右下八个方向上附近的各一个格子，共 8 个格子。<br><a id=\"more\"></a></p>\n<h3 id=\"输入\"><a href=\"#输入\" class=\"headerlink\" title=\"输入\"></a>输入</h3><p>只有一行，包含两个数 N, K。</p>\n<h3 id=\"输出\"><a href=\"#输出\" class=\"headerlink\" title=\"输出\"></a>输出</h3><p>所得的方案数。</p>\n<h3 id=\"输入样例\"><a href=\"#输入样例\" class=\"headerlink\" title=\"输入样例\"></a>输入样例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3 2</span><br></pre></td></tr></table></figure>\n<h3 id=\"输出样例\"><a href=\"#输出样例\" class=\"headerlink\" title=\"输出样例\"></a>输出样例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">16</span><br></pre></td></tr></table></figure>\n<h2 id=\"思路\"><a href=\"#思路\" class=\"headerlink\" title=\"思路\"></a>思路</h2><h3 id=\"关于-状压dp\"><a href=\"#关于-状压dp\" class=\"headerlink\" title=\"关于 状压dp\"></a>关于 状压dp</h3><p>状压dp是动态规划的一种，通过将状态压缩为整数来达到优化转移的目的。<br>具体来说，我们可以用一个二进制数的每一个二进制位来表示一个位置的状态，在这个题中，我们就可以用 0 来表示该位置不放置国王，用 1 来表示该位置放置国王<br>因为棋盘是一个 N*N 大小的矩阵，我们就可以每一行用一个二进制数来表示该行国王的放置情况</p>\n<h3 id=\"具体操作\"><a href=\"#具体操作\" class=\"headerlink\" title=\"具体操作\"></a>具体操作</h3><p>见代码注释</p>\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><p>这里是本蒟蒻的代码~</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\">#include &lt;algorithm&gt;</span><br><span class=\"line\">using namespace std;</span><br><span class=\"line\"></span><br><span class=\"line\">int n,k,cnt;    <span class=\"comment\">// n为棋盘的大小，k为国王的个数，cnt为只考虑一行的情况下（即一个国王的左右不能放置国王）放置国王的所有可能情况（国王为任意数量）</span></span><br><span class=\"line\">long long sta[<span class=\"number\">2005</span>],sit[<span class=\"number\">2005</span>];      <span class=\"comment\">// sta数组存储各个情况放置的国王的数目 sit数组存储各个情况下国王的放置位置（用一个二进制数来表示）</span></span><br><span class=\"line\">int f[<span class=\"number\">15</span>][<span class=\"number\">2005</span>][<span class=\"number\">105</span>];               <span class=\"comment\">// f数组的第一维是当前的行数，第二维是放置国王的所有情况中的第几个，第三维是到该行总共放置国王的个数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> dfs(int x,int num,int cur)    <span class=\"comment\">// 预处理出单行情况放置国王的所有情况 x:国王的放置位置(一个二进制数) num:放置国王的个数 cur:当前搜到的位置</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span>(cur&gt;=n)         <span class=\"comment\">// cur&gt;=n 表示一行搜完</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tsit[++cnt]=x;  </span><br><span class=\"line\">\t\tsta[cnt]=num;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdfs(x,num,cur+<span class=\"number\">1</span>);     <span class=\"comment\">//该位置不放国王</span></span><br><span class=\"line\">\tdfs(x+(<span class=\"number\">1</span>&lt;&lt;cur),num+<span class=\"number\">1</span>,cur+<span class=\"number\">2</span>);      <span class=\"comment\">//该位置放国王</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span>(cin&gt;&gt;n&gt;&gt;k)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tdfs(<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>);        <span class=\"comment\">//预处理出所有情况</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=cnt;i++)       <span class=\"comment\">//将结果赋给第一行</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tf[<span class=\"number\">1</span>][i][sta[i]]=<span class=\"number\">1</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">2</span>;i&lt;=n;i++)         <span class=\"comment\">//从第 2 行到第 n 行，对于前一行的所有可能状态，当前行用所有的可能状态进行比较</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">for</span>(int j=<span class=\"number\">1</span>;j&lt;=cnt;j++)</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">for</span>(int l=<span class=\"number\">1</span>;l&lt;=cnt;l++)</span><br><span class=\"line\">\t\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\t\t<span class=\"keyword\">if</span>(sit[j]&amp;sit[l]) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">\t\t\t\t\t<span class=\"keyword\">if</span>((sit[j]&lt;&lt;<span class=\"number\">1</span>)&amp;sit[l]) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">\t\t\t\t\t<span class=\"keyword\">if</span>(sit[j]&amp;(sit[l]&lt;&lt;<span class=\"number\">1</span>)) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">                    <span class=\"comment\">//上面这三行用来排除不合法的转移     即当前行有国王的上方或左上或右上存在国王</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t\t\t<span class=\"keyword\">for</span>(int p=sta[j];p&lt;=k;p++)     <span class=\"comment\">// 如果两行没有冲突  则当前行放置 sta[j] 个国王</span></span><br><span class=\"line\">\t\t\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\t\t\tf[i][j][p]+=f[i<span class=\"number\">-1</span>][l][p-sta[j]];</span><br><span class=\"line\">\t\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tlong long ans=<span class=\"number\">0</span>;       <span class=\"comment\">// ans为答案</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=cnt;i++)      <span class=\"comment\">// ans加上第n行的每一种情况下放置k个国王的总数</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tans+=f[n][i][k];</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tcout&lt;&lt;ans&lt;&lt;endl;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>感谢观看~</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"题目：互不侵犯\"><a href=\"#题目：互不侵犯\" class=\"headerlink\" title=\"题目：互不侵犯\"></a>题目：互不侵犯</h2><h3 id=\"题目描述\"><a href=\"#题目描述\" class=\"headerlink\" title=\"题目描述\"></a>题目描述</h3><p>在 N*N 的棋盘里面放 K 个国王，使他们互不攻击，共有多少种摆放方案。国王能攻击到它上下左右，以及左上左下右上右下八个方向上附近的各一个格子，共 8 个格子。<br></p>","more":"<p></p>\n<h3 id=\"输入\"><a href=\"#输入\" class=\"headerlink\" title=\"输入\"></a>输入</h3><p>只有一行，包含两个数 N, K。</p>\n<h3 id=\"输出\"><a href=\"#输出\" class=\"headerlink\" title=\"输出\"></a>输出</h3><p>所得的方案数。</p>\n<h3 id=\"输入样例\"><a href=\"#输入样例\" class=\"headerlink\" title=\"输入样例\"></a>输入样例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3 2</span><br></pre></td></tr></table></figure>\n<h3 id=\"输出样例\"><a href=\"#输出样例\" class=\"headerlink\" title=\"输出样例\"></a>输出样例</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">16</span><br></pre></td></tr></table></figure>\n<h2 id=\"思路\"><a href=\"#思路\" class=\"headerlink\" title=\"思路\"></a>思路</h2><h3 id=\"关于-状压dp\"><a href=\"#关于-状压dp\" class=\"headerlink\" title=\"关于 状压dp\"></a>关于 状压dp</h3><p>状压dp是动态规划的一种，通过将状态压缩为整数来达到优化转移的目的。<br>具体来说，我们可以用一个二进制数的每一个二进制位来表示一个位置的状态，在这个题中，我们就可以用 0 来表示该位置不放置国王，用 1 来表示该位置放置国王<br>因为棋盘是一个 N*N 大小的矩阵，我们就可以每一行用一个二进制数来表示该行国王的放置情况</p>\n<h3 id=\"具体操作\"><a href=\"#具体操作\" class=\"headerlink\" title=\"具体操作\"></a>具体操作</h3><p>见代码注释</p>\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><p>这里是本蒟蒻的代码~</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\">#include &lt;algorithm&gt;</span><br><span class=\"line\">using namespace std;</span><br><span class=\"line\"></span><br><span class=\"line\">int n,k,cnt;    <span class=\"comment\">// n为棋盘的大小，k为国王的个数，cnt为只考虑一行的情况下（即一个国王的左右不能放置国王）放置国王的所有可能情况（国王为任意数量）</span></span><br><span class=\"line\">long long sta[<span class=\"number\">2005</span>],sit[<span class=\"number\">2005</span>];      <span class=\"comment\">// sta数组存储各个情况放置的国王的数目 sit数组存储各个情况下国王的放置位置（用一个二进制数来表示）</span></span><br><span class=\"line\">int f[<span class=\"number\">15</span>][<span class=\"number\">2005</span>][<span class=\"number\">105</span>];               <span class=\"comment\">// f数组的第一维是当前的行数，第二维是放置国王的所有情况中的第几个，第三维是到该行总共放置国王的个数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> dfs(int x,int num,int cur)    <span class=\"comment\">// 预处理出单行情况放置国王的所有情况 x:国王的放置位置(一个二进制数) num:放置国王的个数 cur:当前搜到的位置</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span>(cur&gt;=n)         <span class=\"comment\">// cur&gt;=n 表示一行搜完</span></span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tsit[++cnt]=x;  </span><br><span class=\"line\">\t\tsta[cnt]=num;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span>;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdfs(x,num,cur+<span class=\"number\">1</span>);     <span class=\"comment\">//该位置不放国王</span></span><br><span class=\"line\">\tdfs(x+(<span class=\"number\">1</span>&lt;&lt;cur),num+<span class=\"number\">1</span>,cur+<span class=\"number\">2</span>);      <span class=\"comment\">//该位置放国王</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">while</span>(cin&gt;&gt;n&gt;&gt;k)</span><br><span class=\"line\">\t&#123;</span><br><span class=\"line\">\t\tdfs(<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>);        <span class=\"comment\">//预处理出所有情况</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=cnt;i++)       <span class=\"comment\">//将结果赋给第一行</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tf[<span class=\"number\">1</span>][i][sta[i]]=<span class=\"number\">1</span>;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">2</span>;i&lt;=n;i++)         <span class=\"comment\">//从第 2 行到第 n 行，对于前一行的所有可能状态，当前行用所有的可能状态进行比较</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">for</span>(int j=<span class=\"number\">1</span>;j&lt;=cnt;j++)</span><br><span class=\"line\">\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">for</span>(int l=<span class=\"number\">1</span>;l&lt;=cnt;l++)</span><br><span class=\"line\">\t\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\t\t<span class=\"keyword\">if</span>(sit[j]&amp;sit[l]) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">\t\t\t\t\t<span class=\"keyword\">if</span>((sit[j]&lt;&lt;<span class=\"number\">1</span>)&amp;sit[l]) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">\t\t\t\t\t<span class=\"keyword\">if</span>(sit[j]&amp;(sit[l]&lt;&lt;<span class=\"number\">1</span>)) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">                    <span class=\"comment\">//上面这三行用来排除不合法的转移     即当前行有国王的上方或左上或右上存在国王</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t\t\t<span class=\"keyword\">for</span>(int p=sta[j];p&lt;=k;p++)     <span class=\"comment\">// 如果两行没有冲突  则当前行放置 sta[j] 个国王</span></span><br><span class=\"line\">\t\t\t\t\t&#123;</span><br><span class=\"line\">\t\t\t\t\t\tf[i][j][p]+=f[i<span class=\"number\">-1</span>][l][p-sta[j]];</span><br><span class=\"line\">\t\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tlong long ans=<span class=\"number\">0</span>;       <span class=\"comment\">// ans为答案</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span>(int i=<span class=\"number\">1</span>;i&lt;=cnt;i++)      <span class=\"comment\">// ans加上第n行的每一种情况下放置k个国王的总数</span></span><br><span class=\"line\">\t\t&#123;</span><br><span class=\"line\">\t\t\tans+=f[n][i][k];</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tcout&lt;&lt;ans&lt;&lt;endl;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>感谢观看~</p>"},{"title":"第一次上机E题题解","date":"2019-10-11T04:01:24.000Z","_content":"\n## 题目：点灯\n\n### 题目描述\n***\n有n个灯，编号0∼n−1，一开始都是关闭状态。\n\n每次操作会拨动一个区间[L,R]灯的开关，也就是说，对于灯i，L≤i≤R，如果i是关闭状态，则操作会使灯亮，反之会使灯灭。\n\n请问k次操作后有多少灯亮着。\n\n<!--more-->\n### 输入\n***\n多组输入数据\n\n每组数据第一行两个数n,k（1≤n≤109,1≤k≤105）\n\n接下来k行，每行两个数l,r（0≤l≤r≤n−1）\n\n### 输出\n***\n每组数据一行一个数，表示最后灯亮的个数\n\n### 输入样例\n***\n{% codeblock lang:JavaScript %}\n10 1\n2 6\n{% endcodeblock %}\n\n### 输出样例\n***\n{% codeblock lang:JavaScript %}\n5\n{% endcodeblock %}\n\n### 思路\n***\n\n对于每一个灯，如果它位于一个 [L,R] 区间内，说明开关被按动一次，设这个灯位于 k 个 [L,R] 的区间之内，那么 k 是奇数代表开关被按了奇数次，此时灯是亮的，若 k 是偶数，则灯是灭的。那么问题的关键就是如何求出每个灯的 k 。\n\n因此，读入了 k 个 L 和 k 个 R 之后，我们将这 2*k 个数（ k 个 L 和 k 个 R+1 ）放在一起，并标记每个数是 L 还是 R+1（二维数组和结构数组均可，我使用的是二维数组），由小到大排序，然后定义一个变量 turn = 0（turn 就相当于之前的 k) ，之后对排序后的数组从前向后循环，如果遇到 L ，则 turn += 1 ,说明进入到了一个开关范围内，如果遇到 R+1 ，则 turn -= 1 ，说明离开了一个开关的范围，turn 每次改变后进行判断，若改变后 turn 为奇数，则改变前为偶数，说明从现在这个 L 或 R+1 的位置到上一个 L 或 R+1 的位置中的所有灯的 turn 都是偶数，即灯是灭的，若改变后 turn 为偶数 ，说明从现在的位置到上一个位置的灯都是亮的，那么 ans += 两个位置的差，循环结束即可得到正确结果。\n\n### 代码\n\n{% codeblock lang:JavaScript %}\n/*\n Author: 王振\n Result: AC\tSubmission_id: 1860544\n Created at: Thu Oct 10 2019 17:08:32 GMT+0800 (CST)\n Problem_id: 2489\tTime: 824\tMemory: 7180\n*/\n \n#include <algorithm>\n#include <cmath>\n#include <cstdlib>\n#include <cstring>\n#include <iostream>\n#include <queue>\n#include <vector>\nusing namespace std;\nint l[100005];\nint r[100005];\nint t[200005][2];\nint turn;\nint cmp(const void *a, const void *b) { return *(int *)a - *(int *)b; }\nint main()\n{\n    int n, k;\n    while (cin >> n >> k)\n    {\n        int i;\n        int p = 0;\n        for (i = 1; i <= k; i++)\n        {\n            scanf(\"%d%d\", &l[i], &r[i]);\n            t[++p][0] = l[i];\n            t[p][1] = 1;\n            t[++p][0] = r[i] + 1;\n            t[p][1] = 2;\n        }\n        qsort(t + 1, k * 2, 8, cmp);\n        int ans = 0;\n        for (i = 1; i <= k * 2; i++)\n        {\n            if (t[i][1] == 1)\n            {\n                turn++;\n            }\n            else\n            {\n                turn--;\n            }\n            if (turn % 2 == 0)\n            {\n                ans += t[i][0] - t[i - 1][0];\n            }\n        }\n        cout << ans << endl;\n    }\n    return 0;\n}\n{% endcodeblock %}","source":"_posts/第一次上机E题题解.md","raw":"---\ntitle: 第一次上机E题题解\ndate: 2019-10-11 12:01:24\ntags:\n    - 题解\n---\n\n## 题目：点灯\n\n### 题目描述\n***\n有n个灯，编号0∼n−1，一开始都是关闭状态。\n\n每次操作会拨动一个区间[L,R]灯的开关，也就是说，对于灯i，L≤i≤R，如果i是关闭状态，则操作会使灯亮，反之会使灯灭。\n\n请问k次操作后有多少灯亮着。\n\n<!--more-->\n### 输入\n***\n多组输入数据\n\n每组数据第一行两个数n,k（1≤n≤109,1≤k≤105）\n\n接下来k行，每行两个数l,r（0≤l≤r≤n−1）\n\n### 输出\n***\n每组数据一行一个数，表示最后灯亮的个数\n\n### 输入样例\n***\n{% codeblock lang:JavaScript %}\n10 1\n2 6\n{% endcodeblock %}\n\n### 输出样例\n***\n{% codeblock lang:JavaScript %}\n5\n{% endcodeblock %}\n\n### 思路\n***\n\n对于每一个灯，如果它位于一个 [L,R] 区间内，说明开关被按动一次，设这个灯位于 k 个 [L,R] 的区间之内，那么 k 是奇数代表开关被按了奇数次，此时灯是亮的，若 k 是偶数，则灯是灭的。那么问题的关键就是如何求出每个灯的 k 。\n\n因此，读入了 k 个 L 和 k 个 R 之后，我们将这 2*k 个数（ k 个 L 和 k 个 R+1 ）放在一起，并标记每个数是 L 还是 R+1（二维数组和结构数组均可，我使用的是二维数组），由小到大排序，然后定义一个变量 turn = 0（turn 就相当于之前的 k) ，之后对排序后的数组从前向后循环，如果遇到 L ，则 turn += 1 ,说明进入到了一个开关范围内，如果遇到 R+1 ，则 turn -= 1 ，说明离开了一个开关的范围，turn 每次改变后进行判断，若改变后 turn 为奇数，则改变前为偶数，说明从现在这个 L 或 R+1 的位置到上一个 L 或 R+1 的位置中的所有灯的 turn 都是偶数，即灯是灭的，若改变后 turn 为偶数 ，说明从现在的位置到上一个位置的灯都是亮的，那么 ans += 两个位置的差，循环结束即可得到正确结果。\n\n### 代码\n\n{% codeblock lang:JavaScript %}\n/*\n Author: 王振\n Result: AC\tSubmission_id: 1860544\n Created at: Thu Oct 10 2019 17:08:32 GMT+0800 (CST)\n Problem_id: 2489\tTime: 824\tMemory: 7180\n*/\n \n#include <algorithm>\n#include <cmath>\n#include <cstdlib>\n#include <cstring>\n#include <iostream>\n#include <queue>\n#include <vector>\nusing namespace std;\nint l[100005];\nint r[100005];\nint t[200005][2];\nint turn;\nint cmp(const void *a, const void *b) { return *(int *)a - *(int *)b; }\nint main()\n{\n    int n, k;\n    while (cin >> n >> k)\n    {\n        int i;\n        int p = 0;\n        for (i = 1; i <= k; i++)\n        {\n            scanf(\"%d%d\", &l[i], &r[i]);\n            t[++p][0] = l[i];\n            t[p][1] = 1;\n            t[++p][0] = r[i] + 1;\n            t[p][1] = 2;\n        }\n        qsort(t + 1, k * 2, 8, cmp);\n        int ans = 0;\n        for (i = 1; i <= k * 2; i++)\n        {\n            if (t[i][1] == 1)\n            {\n                turn++;\n            }\n            else\n            {\n                turn--;\n            }\n            if (turn % 2 == 0)\n            {\n                ans += t[i][0] - t[i - 1][0];\n            }\n        }\n        cout << ans << endl;\n    }\n    return 0;\n}\n{% endcodeblock %}","slug":"第一次上机E题题解","published":1,"updated":"2019-10-11T04:37:53.894Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh702r000la0uz1bx5bevr","content":"<h2 id=\"题目：点灯\"><a href=\"#题目：点灯\" class=\"headerlink\" title=\"题目：点灯\"></a>题目：点灯</h2><h3 id=\"题目描述\"><a href=\"#题目描述\" class=\"headerlink\" title=\"题目描述\"></a>题目描述</h3><hr>\n<p>有n个灯，编号0∼n−1，一开始都是关闭状态。</p>\n<p>每次操作会拨动一个区间[L,R]灯的开关，也就是说，对于灯i，L≤i≤R，如果i是关闭状态，则操作会使灯亮，反之会使灯灭。</p>\n<p>请问k次操作后有多少灯亮着。</p>\n<a id=\"more\"></a>\n<h3 id=\"输入\"><a href=\"#输入\" class=\"headerlink\" title=\"输入\"></a>输入</h3><hr>\n<p>多组输入数据</p>\n<p>每组数据第一行两个数n,k（1≤n≤109,1≤k≤105）</p>\n<p>接下来k行，每行两个数l,r（0≤l≤r≤n−1）</p>\n<h3 id=\"输出\"><a href=\"#输出\" class=\"headerlink\" title=\"输出\"></a>输出</h3><hr>\n<p>每组数据一行一个数，表示最后灯亮的个数</p>\n<h3 id=\"输入样例\"><a href=\"#输入样例\" class=\"headerlink\" title=\"输入样例\"></a>输入样例</h3><hr>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">10</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">2</span> <span class=\"number\">6</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"输出样例\"><a href=\"#输出样例\" class=\"headerlink\" title=\"输出样例\"></a>输出样例</h3><hr>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">5</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"思路\"><a href=\"#思路\" class=\"headerlink\" title=\"思路\"></a>思路</h3><hr>\n<p>对于每一个灯，如果它位于一个 [L,R] 区间内，说明开关被按动一次，设这个灯位于 k 个 [L,R] 的区间之内，那么 k 是奇数代表开关被按了奇数次，此时灯是亮的，若 k 是偶数，则灯是灭的。那么问题的关键就是如何求出每个灯的 k 。</p>\n<p>因此，读入了 k 个 L 和 k 个 R 之后，我们将这 2*k 个数（ k 个 L 和 k 个 R+1 ）放在一起，并标记每个数是 L 还是 R+1（二维数组和结构数组均可，我使用的是二维数组），由小到大排序，然后定义一个变量 turn = 0（turn 就相当于之前的 k) ，之后对排序后的数组从前向后循环，如果遇到 L ，则 turn += 1 ,说明进入到了一个开关范围内，如果遇到 R+1 ，则 turn -= 1 ，说明离开了一个开关的范围，turn 每次改变后进行判断，若改变后 turn 为奇数，则改变前为偶数，说明从现在这个 L 或 R+1 的位置到上一个 L 或 R+1 的位置中的所有灯的 turn 都是偶数，即灯是灭的，若改变后 turn 为偶数 ，说明从现在的位置到上一个位置的灯都是亮的，那么 ans += 两个位置的差，循环结束即可得到正确结果。</p>\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\"> Author: 王振</span></span><br><span class=\"line\"><span class=\"comment\"> Result: AC\tSubmission_id: 1860544</span></span><br><span class=\"line\"><span class=\"comment\"> Created at: Thu Oct 10 2019 17:08:32 GMT+0800 (CST)</span></span><br><span class=\"line\"><span class=\"comment\"> Problem_id: 2489\tTime: 824\tMemory: 7180</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"> </span><br><span class=\"line\">#include &lt;algorithm&gt;</span><br><span class=\"line\">#include &lt;cmath&gt;</span><br><span class=\"line\">#include &lt;cstdlib&gt;</span><br><span class=\"line\">#include &lt;cstring&gt;</span><br><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\">#include &lt;queue&gt;</span><br><span class=\"line\">#include &lt;vector&gt;</span><br><span class=\"line\">using namespace std;</span><br><span class=\"line\">int l[<span class=\"number\">100005</span>];</span><br><span class=\"line\">int r[<span class=\"number\">100005</span>];</span><br><span class=\"line\">int t[<span class=\"number\">200005</span>][<span class=\"number\">2</span>];</span><br><span class=\"line\">int turn;</span><br><span class=\"line\">int cmp(<span class=\"keyword\">const</span> <span class=\"keyword\">void</span> *a, <span class=\"keyword\">const</span> <span class=\"keyword\">void</span> *b) &#123; <span class=\"keyword\">return</span> *(int *)a - *(int *)b; &#125;</span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int n, k;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (cin &gt;&gt; n &gt;&gt; k)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        int i;</span><br><span class=\"line\">        int p = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (i = <span class=\"number\">1</span>; i &lt;= k; i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            scanf(<span class=\"string\">\"%d%d\"</span>, &amp;l[i], &amp;r[i]);</span><br><span class=\"line\">            t[++p][<span class=\"number\">0</span>] = l[i];</span><br><span class=\"line\">            t[p][<span class=\"number\">1</span>] = <span class=\"number\">1</span>;</span><br><span class=\"line\">            t[++p][<span class=\"number\">0</span>] = r[i] + <span class=\"number\">1</span>;</span><br><span class=\"line\">            t[p][<span class=\"number\">1</span>] = <span class=\"number\">2</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        qsort(t + <span class=\"number\">1</span>, k * <span class=\"number\">2</span>, <span class=\"number\">8</span>, cmp);</span><br><span class=\"line\">        int ans = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (i = <span class=\"number\">1</span>; i &lt;= k * <span class=\"number\">2</span>; i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (t[i][<span class=\"number\">1</span>] == <span class=\"number\">1</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                turn++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                turn--;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (turn % <span class=\"number\">2</span> == <span class=\"number\">0</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                ans += t[i][<span class=\"number\">0</span>] - t[i - <span class=\"number\">1</span>][<span class=\"number\">0</span>];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        cout &lt;&lt; ans &lt;&lt; endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<h2 id=\"题目：点灯\"><a href=\"#题目：点灯\" class=\"headerlink\" title=\"题目：点灯\"></a>题目：点灯</h2><h3 id=\"题目描述\"><a href=\"#题目描述\" class=\"headerlink\" title=\"题目描述\"></a>题目描述</h3><hr>\n<p>有n个灯，编号0∼n−1，一开始都是关闭状态。</p>\n<p>每次操作会拨动一个区间[L,R]灯的开关，也就是说，对于灯i，L≤i≤R，如果i是关闭状态，则操作会使灯亮，反之会使灯灭。</p>\n<p>请问k次操作后有多少灯亮着。</p>","more":"<h3 id=\"输入\"><a href=\"#输入\" class=\"headerlink\" title=\"输入\"></a>输入</h3><hr>\n<p>多组输入数据</p>\n<p>每组数据第一行两个数n,k（1≤n≤109,1≤k≤105）</p>\n<p>接下来k行，每行两个数l,r（0≤l≤r≤n−1）</p>\n<h3 id=\"输出\"><a href=\"#输出\" class=\"headerlink\" title=\"输出\"></a>输出</h3><hr>\n<p>每组数据一行一个数，表示最后灯亮的个数</p>\n<h3 id=\"输入样例\"><a href=\"#输入样例\" class=\"headerlink\" title=\"输入样例\"></a>输入样例</h3><hr>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">10</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">2</span> <span class=\"number\">6</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"输出样例\"><a href=\"#输出样例\" class=\"headerlink\" title=\"输出样例\"></a>输出样例</h3><hr>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">5</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"思路\"><a href=\"#思路\" class=\"headerlink\" title=\"思路\"></a>思路</h3><hr>\n<p>对于每一个灯，如果它位于一个 [L,R] 区间内，说明开关被按动一次，设这个灯位于 k 个 [L,R] 的区间之内，那么 k 是奇数代表开关被按了奇数次，此时灯是亮的，若 k 是偶数，则灯是灭的。那么问题的关键就是如何求出每个灯的 k 。</p>\n<p>因此，读入了 k 个 L 和 k 个 R 之后，我们将这 2*k 个数（ k 个 L 和 k 个 R+1 ）放在一起，并标记每个数是 L 还是 R+1（二维数组和结构数组均可，我使用的是二维数组），由小到大排序，然后定义一个变量 turn = 0（turn 就相当于之前的 k) ，之后对排序后的数组从前向后循环，如果遇到 L ，则 turn += 1 ,说明进入到了一个开关范围内，如果遇到 R+1 ，则 turn -= 1 ，说明离开了一个开关的范围，turn 每次改变后进行判断，若改变后 turn 为奇数，则改变前为偶数，说明从现在这个 L 或 R+1 的位置到上一个 L 或 R+1 的位置中的所有灯的 turn 都是偶数，即灯是灭的，若改变后 turn 为偶数 ，说明从现在的位置到上一个位置的灯都是亮的，那么 ans += 两个位置的差，循环结束即可得到正确结果。</p>\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\"> Author: 王振</span></span><br><span class=\"line\"><span class=\"comment\"> Result: AC\tSubmission_id: 1860544</span></span><br><span class=\"line\"><span class=\"comment\"> Created at: Thu Oct 10 2019 17:08:32 GMT+0800 (CST)</span></span><br><span class=\"line\"><span class=\"comment\"> Problem_id: 2489\tTime: 824\tMemory: 7180</span></span><br><span class=\"line\"><span class=\"comment\">*/</span></span><br><span class=\"line\"> </span><br><span class=\"line\">#include &lt;algorithm&gt;</span><br><span class=\"line\">#include &lt;cmath&gt;</span><br><span class=\"line\">#include &lt;cstdlib&gt;</span><br><span class=\"line\">#include &lt;cstring&gt;</span><br><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\">#include &lt;queue&gt;</span><br><span class=\"line\">#include &lt;vector&gt;</span><br><span class=\"line\">using namespace std;</span><br><span class=\"line\">int l[<span class=\"number\">100005</span>];</span><br><span class=\"line\">int r[<span class=\"number\">100005</span>];</span><br><span class=\"line\">int t[<span class=\"number\">200005</span>][<span class=\"number\">2</span>];</span><br><span class=\"line\">int turn;</span><br><span class=\"line\">int cmp(<span class=\"keyword\">const</span> <span class=\"keyword\">void</span> *a, <span class=\"keyword\">const</span> <span class=\"keyword\">void</span> *b) &#123; <span class=\"keyword\">return</span> *(int *)a - *(int *)b; &#125;</span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int n, k;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (cin &gt;&gt; n &gt;&gt; k)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        int i;</span><br><span class=\"line\">        int p = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (i = <span class=\"number\">1</span>; i &lt;= k; i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            scanf(<span class=\"string\">\"%d%d\"</span>, &amp;l[i], &amp;r[i]);</span><br><span class=\"line\">            t[++p][<span class=\"number\">0</span>] = l[i];</span><br><span class=\"line\">            t[p][<span class=\"number\">1</span>] = <span class=\"number\">1</span>;</span><br><span class=\"line\">            t[++p][<span class=\"number\">0</span>] = r[i] + <span class=\"number\">1</span>;</span><br><span class=\"line\">            t[p][<span class=\"number\">1</span>] = <span class=\"number\">2</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        qsort(t + <span class=\"number\">1</span>, k * <span class=\"number\">2</span>, <span class=\"number\">8</span>, cmp);</span><br><span class=\"line\">        int ans = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (i = <span class=\"number\">1</span>; i &lt;= k * <span class=\"number\">2</span>; i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (t[i][<span class=\"number\">1</span>] == <span class=\"number\">1</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                turn++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span></span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                turn--;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (turn % <span class=\"number\">2</span> == <span class=\"number\">0</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                ans += t[i][<span class=\"number\">0</span>] - t[i - <span class=\"number\">1</span>][<span class=\"number\">0</span>];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        cout &lt;&lt; ans &lt;&lt; endl;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"数字电路复习笔记","date":"2020-09-07T08:15:48.000Z","_content":"\n# 数字电路复习笔记\n\n关于数字电路自己总结的复习笔记，仅供参考，不怎么全\n\n<!--more-->\n## 第一章 数制和码制\n\n### 进制转换（整数和小数）\n\n### 原码，反码，补码\n\n> 正数的原码等于反码等于补码\n>\n> 负数的反码等于原码0变1，1变0，补码等于反码+1\n>\n> 二进制数运算：补码运算\n\n### 常用编码\n\n#### 十进制\n\n![image-20201207095115200](数字电路/image-20201207095115200.png)\n\n余3码的数值比对应十进制数多3\n\n注意下面的权值，代表各个位置为1时的大小\n\n#### 格雷码\n\n![image-20201207095702879](数字电路/image-20201207095702879.png)\n\n## 第二章 逻辑代数基础\n\n![image-20201207100058038](数字电路/image-20201207100058038.png)\n\n![image-20201207100101916](数字电路/image-20201207100101916.png)\n\n![image-20201207100105985](数字电路/image-20201207100105985.png)\n\n![image-20201207100108953](数字电路/image-20201207100108953.png)\n\n![image-20201207100257128](数字电路/image-20201207100257128.png)\n\n### 基本公式\n\n![image-20201207100339923](数字电路/image-20201207100339923.png)\n\n### 常用公式\n\n![image-20201207100458411](数字电路/image-20201207100458411.png)\n\n\n\n### 逻辑函数的表示方法\n\n逻辑真值表，逻辑函数式，逻辑图（将逻辑关系用图形符号表示出来），波形图\n\n最小项和最大项\n\n转化为或非可以先转化为与或非的形式（利用最小项以及Y=(Y ‘) ’），再转换为或非的形式\n\n逻辑函数化简\n\n### 卡诺图\n\n![image-20201207103734768](数字电路/image-20201207103734768.png)\n\n卡诺图合并，可以重复使用一个最小项\n\n### 具有无关项的逻辑函数及其化简\n\n## 第三章 门电路\n\n![image-20201207141227512](数字电路/image-20201207141227512.png)\n\n![image-20201207141230974](数字电路/image-20201207141230974.png)\n\n### CMOS门电路\n\n![image-20201207141338902](数字电路/image-20201207141338902.png)\n\n#### CMOS反相器\n\n![image-20201207143351015](数字电路/image-20201207143351015.png)\n\n#### CMOS与非门 或非门\n\n![image-20201207143605620](数字电路/image-20201207143605620.png)\n\n#### CMOS传输门\n\n![image-20201207150409345](数字电路/image-20201207150409345.png)\n\n当C=1,C'=0时导通，C=0,C'=1时截止\n\n#### 三态输出的CMOS门电路\n\nb图若EN'连线尾部有圈则为低电平有效，当EN'=0时正常与非门，当EN'=1时高阻\n\n![image-20201207151538922](数字电路/image-20201207151538922.png)\n\n理解3.3.40图   难\n\n### TTL门电路\n\n![image-20201207155711758](数字电路/image-20201207155711758.png)\n\n![image-20201207155851664](数字电路/image-20201207155851664.png)\n\n#### 三极管反相器\n\n![image-20201207155940917](数字电路/image-20201207155940917.png)\n\n#### TTL反相器\n\n![image-20201207160054355](数字电路/image-20201207160054355.png)\n\n#### TTL门电路——与非门，或非门，与或非门，异或门\n\n多发射极三极管可以看作两个发射级独立而基极和集电极分别并联在一起的三极管\n\n![image-20201207163239045](数字电路/image-20201207163239045.png)\n\n只要有一个导通，则输出为低电平，只有两个都不导通的时候，则输出端c才是高电平\n\n![image-20201207163011726](数字电路/image-20201207163011726.png)\n\n![image-20201207163100622](数字电路/image-20201207163100622.png)\n\n#### 集电极开路输出的门电路（OC门）\n\n#### 三态输出门电路（TS门）\n\n高电平有效：\n\n![image-20201207164852673](数字电路/image-20201207164852673.png)\n\n低电平有效：\n\n![image-20201207164837016](数字电路/image-20201207164837016.png)\n\n## 第四章 组合逻辑电路\n\n### 组合逻辑电路的分析方法和设计方法\n\n#### 分析方法\n\n将电路图转换为函数式或者真值表\n\n#### 设计方法\n\n1. 进行逻辑抽象，根据事件的因果关系确定输入变量和输出变量，定义逻辑状态的含义，根据给定的因果关系列出逻辑真值表\n2. 写出逻辑函数式\n3. 选定器件的类型\n4. 将逻辑函数化简或变换成适当的形式\n5. 根据逻辑函数式画出逻辑电路图\n\n### 常用的组合逻辑电路\n\n#### 编码器\n\n##### 普通编码器\n\n任何时刻只允许输入一个编码信号\n\n![image-20201207180435959](数字电路/image-20201207180435959.png)\n\n![image-20201207180624804](数字电路/image-20201207180624804.png)\n\n##### 优先编码器\n\n![image-20201207202208723](数字电路/image-20201207202208723.png)\n\nS‘ 为选通输入端，只有S' = 0 时，编码器才能正常工作，而在S' = 1时，所有的输出端均被封锁在高电平\n\n![image-20201207202442317](数字电路/image-20201207202442317.png)\n\n![image-20201207202738889](数字电路/image-20201207202738889.png)\n\n![image-20201207202617679](数字电路/image-20201207202617679.png)\n\n> 当芯片接口带圈时，输入信号表示为 X’\n\n##### 二--十进制优先编码器\n\n#### 译码器\n\n##### 普通译码器\n\n\n\n![image-20201207204428555](数字电路/image-20201207204428555.png)\n\n![image-20201207204622034](数字电路/image-20201207204622034.png)\n\n![image-20201207204956445](数字电路/image-20201207204956445.png)\n\n##### 二--十进制译码器\n\n##### 显示译码器\n\n###### 七段字符显示器\n\n###### BCD - 七段显示译码器\n\n##### 用译码器设计组合逻辑电路\n\n![image-20201207205904689](数字电路/image-20201207205904689.png)\n\n![image-20201207210045223](数字电路/image-20201207210045223.png)\n\n#### 数据选择器\n\n##### 四选一数据选择器\n\n`A0, A1` 决定选择的数据，S‘ 控制电路工作状态，S' = 0 时数据选择器工作，反之不工作\n\n##### 八选一数据选择器\n\n![image-20201207211753609](数字电路/image-20201207211753609.png)\n\n##### 用数据选择器设计组合逻辑电路\n\n![image-20201207225752379](数字电路/image-20201207225752379.png)\n\n#### 加法器\n\n##### 一位加法器\n\n半加器（不考虑进位）\n\n全加器（考虑进位）\n\n##### 多位加法器\n\n串行进位加法器\n\n超前进位加法器\n\n#### 利用加法器设计电路\n\n![image-20201207230758027](数字电路/image-20201207230758027.png)\n\n#### 数值比较器\n\n##### 1位数值比较器\n\n![image-20201207231257765](数字电路/image-20201207231257765.png)\n\n##### 多位数值比较器\n\n![image-20201207231703395](数字电路/image-20201207231703395.png)\n\nI 是来自低位的比较信息\n\n## 第五章 触发器\n\n能够储存 1 位二值信号的基本单元电路统称为触发器\n\n### SR锁存器\n\n![image-20201207234319334](数字电路/image-20201207234319334.png)\n\n![image-20201207234431264](数字电路/image-20201207234431264.png)\n\n### 电平触发的触发器\n\n触发信号输入端               触发信号 `CLK`\n\n![image-20201208093951521](数字电路/image-20201208093951521.png)\n\n当 `CLK=0`时，S, R的信号无法影响到输出，当 `CLK=1`时，S, R的信号才能起作用\n\n![image-20201208094730885](数字电路/image-20201208094730885.png)\n\n### 电平触发的D触发器\n\n![image-20201208095118685](数字电路/image-20201208095118685.png)\n\n当`CLK=1`时，Q的值和D相同，当`CLK=0`时，Q的值保持不变\n\n### 脉冲触发的触发器（主从SR触发器）\n\n![image-20201208100213115](数字电路/image-20201208100213115.png)\n\n![image-20201208100252440](数字电路/image-20201208100252440.png)\n\n![image-20201208100311393](数字电路/image-20201208100311393.png)\n\n### 主从 JK 触发器\n\n![image-20201208100710777](数字电路/image-20201208100710777.png)\n\n当下降沿到达时，\n\n若 J=1, K=0，则Q置1，若 J=0, K=1，则Q置0，若 J=0, K=0，则Q不变，若 J=1, K=1，则Q状态翻转（0变1，1变0）\n\n\n\n主从触发器的状态由全部在CLK=1时的动作决定\n\n### 边沿触发的触发器\n\n![image-20201208102916928](数字电路/image-20201208102916928.png)\n\n![image-20201208103050351](数字电路/image-20201208103050351.png)\n\n### T触发器\n\n![image-20201208103416148](数字电路/image-20201208103416148.png)\n\n### 触发器分类\n\n![image-20201208103304650](数字电路/image-20201208103304650.png)\n\n## 第六章 时序逻辑电路\n\n### 特性方程\n\n ![image-20201208120335673](数字电路/image-20201208120335673.png)\n\nD 触发器的特性方程 Q* = D\n\nT 触发器的特性方程 Q* = TQ' + T'Q\n\n### 分析同步时序逻辑电路\n\n![image-20201208120149198](数字电路/image-20201208120149198.png)\n\n### 异步时序逻辑电路\n\n### 常用时序逻辑电路\n\n#### 寄存器\n\n#### 移位寄存器\n\n![image-20201208133000921](数字电路/image-20201208133000921.png)\n\n![image-20201208133500161](数字电路/image-20201208133500161.png)\n\n#### 计数器\n\n##### 同步计数器\n\n![image-20201208162623051](数字电路/image-20201208162623051.png)\n\n![image-20201208162700995](数字电路/image-20201208162700995.png)\n\n![image-20201208163034352](数字电路/image-20201208163034352.png)\n\n![image-20201208163053439](数字电路/image-20201208163053439.png)\n\n##### 同步置零和异步置零\n\n![image-20201208163510773](数字电路/image-20201208163510773.png)\n\n##### 异步计数器\n\n##### 任意进制计数器的构成方法\n\n假设已有的是N进制计数器，而需要得到的是M进制计数器，此时分为两种情况：\n\n1. M<N\n\n置零法（复位法），置数法（置位法）\n\n同步置零法：从S0状态出发到达S(M-1)状态时译出同步置零信号，在下一次CLK到达后变为S0状态\n\n![image-20201208192312875](数字电路/image-20201208192312875.png)\n\n异步置零法：从S0状态出发到达S(M)状态时译出异步置零信号，变为S0状态\n\n同步置数法：到达 Si 状态时令 LD'=0 ，在下一个 CLK 到来时，将要置入的数据置入计数器中，状态变为 Sj\n\n![image-20201208192326383](数字电路/image-20201208192326383.png)\n\n异步置数法：到达 S(i+1) 状态时令 LD'=0 ，状态直接变为 Sj\n\n2. M>N\n\n![image-20201208211819333](数字电路/image-20201208211819333.png)\n\n![image-20201208211825145](数字电路/image-20201208211825145.png)\n\n![image-20201208212439760](数字电路/image-20201208212439760.png)\n\n![image-20201208212442919](数字电路/image-20201208212442919.png)\n\n##### 移位寄存器型计数器\n\n环形计数器\n\n扭环形计数器\n\n### 同步时序逻辑电路的设计方法\n\n![image-20201208214549378](数字电路/image-20201208214549378.png)\n\n1. 逻辑抽象，得出电路的状态转换图或状态转换表\n2. 状态化简\n\n![image-20201208214717350](数字电路/image-20201208214717350.png)\n\n3. 状态分配\n\n![image-20201208214956731](数字电路/image-20201208214956731.png)\n\n4. 选定触发器的类型，求出电路的状态方程、驱动方程和输出方程\n\n![image-20201208215446146](数字电路/image-20201208215446146.png)\n\n![image-20201208215327269](数字电路/image-20201208215327269.png)\n\n![image-20201208215405366](数字电路/image-20201208215405366.png)\n\n![image-20201208215602590](数字电路/image-20201208215602590.png)\n\n5. 根据得到的方程式画出逻辑图\n\n![image-20201208215639819](数字电路/image-20201208215639819.png)\n\n6. 检查设计的电路能否自启动\n\n![image-20201208215654220](数字电路/image-20201208215654220.png)\n\n### 异步时序逻辑电路的设计方法\n\n![image-20201208215859239](数字电路/image-20201208215859239.png)\n\n## 第七章 半导体存储器\n\n### 分类\n\n#### 只读存储器\n\n掩模 ROM\n\n可编程 PROM\n\n可擦除的可编程 EPROM\n\n#### 随机读写存储器\n\n动态 DRAM\n\n静态 SRAM\n\n![image-20201209091933646](数字电路/image-20201209091933646.png)\n\n![image-20201209092949508](数字电路/image-20201209092949508.png)\n\n\n","source":"_posts/数字电路.md","raw":"---\ntitle: 数字电路复习笔记\ndate: 2020-09-07 16:15:48\ntags:\n---\n\n# 数字电路复习笔记\n\n关于数字电路自己总结的复习笔记，仅供参考，不怎么全\n\n<!--more-->\n## 第一章 数制和码制\n\n### 进制转换（整数和小数）\n\n### 原码，反码，补码\n\n> 正数的原码等于反码等于补码\n>\n> 负数的反码等于原码0变1，1变0，补码等于反码+1\n>\n> 二进制数运算：补码运算\n\n### 常用编码\n\n#### 十进制\n\n![image-20201207095115200](数字电路/image-20201207095115200.png)\n\n余3码的数值比对应十进制数多3\n\n注意下面的权值，代表各个位置为1时的大小\n\n#### 格雷码\n\n![image-20201207095702879](数字电路/image-20201207095702879.png)\n\n## 第二章 逻辑代数基础\n\n![image-20201207100058038](数字电路/image-20201207100058038.png)\n\n![image-20201207100101916](数字电路/image-20201207100101916.png)\n\n![image-20201207100105985](数字电路/image-20201207100105985.png)\n\n![image-20201207100108953](数字电路/image-20201207100108953.png)\n\n![image-20201207100257128](数字电路/image-20201207100257128.png)\n\n### 基本公式\n\n![image-20201207100339923](数字电路/image-20201207100339923.png)\n\n### 常用公式\n\n![image-20201207100458411](数字电路/image-20201207100458411.png)\n\n\n\n### 逻辑函数的表示方法\n\n逻辑真值表，逻辑函数式，逻辑图（将逻辑关系用图形符号表示出来），波形图\n\n最小项和最大项\n\n转化为或非可以先转化为与或非的形式（利用最小项以及Y=(Y ‘) ’），再转换为或非的形式\n\n逻辑函数化简\n\n### 卡诺图\n\n![image-20201207103734768](数字电路/image-20201207103734768.png)\n\n卡诺图合并，可以重复使用一个最小项\n\n### 具有无关项的逻辑函数及其化简\n\n## 第三章 门电路\n\n![image-20201207141227512](数字电路/image-20201207141227512.png)\n\n![image-20201207141230974](数字电路/image-20201207141230974.png)\n\n### CMOS门电路\n\n![image-20201207141338902](数字电路/image-20201207141338902.png)\n\n#### CMOS反相器\n\n![image-20201207143351015](数字电路/image-20201207143351015.png)\n\n#### CMOS与非门 或非门\n\n![image-20201207143605620](数字电路/image-20201207143605620.png)\n\n#### CMOS传输门\n\n![image-20201207150409345](数字电路/image-20201207150409345.png)\n\n当C=1,C'=0时导通，C=0,C'=1时截止\n\n#### 三态输出的CMOS门电路\n\nb图若EN'连线尾部有圈则为低电平有效，当EN'=0时正常与非门，当EN'=1时高阻\n\n![image-20201207151538922](数字电路/image-20201207151538922.png)\n\n理解3.3.40图   难\n\n### TTL门电路\n\n![image-20201207155711758](数字电路/image-20201207155711758.png)\n\n![image-20201207155851664](数字电路/image-20201207155851664.png)\n\n#### 三极管反相器\n\n![image-20201207155940917](数字电路/image-20201207155940917.png)\n\n#### TTL反相器\n\n![image-20201207160054355](数字电路/image-20201207160054355.png)\n\n#### TTL门电路——与非门，或非门，与或非门，异或门\n\n多发射极三极管可以看作两个发射级独立而基极和集电极分别并联在一起的三极管\n\n![image-20201207163239045](数字电路/image-20201207163239045.png)\n\n只要有一个导通，则输出为低电平，只有两个都不导通的时候，则输出端c才是高电平\n\n![image-20201207163011726](数字电路/image-20201207163011726.png)\n\n![image-20201207163100622](数字电路/image-20201207163100622.png)\n\n#### 集电极开路输出的门电路（OC门）\n\n#### 三态输出门电路（TS门）\n\n高电平有效：\n\n![image-20201207164852673](数字电路/image-20201207164852673.png)\n\n低电平有效：\n\n![image-20201207164837016](数字电路/image-20201207164837016.png)\n\n## 第四章 组合逻辑电路\n\n### 组合逻辑电路的分析方法和设计方法\n\n#### 分析方法\n\n将电路图转换为函数式或者真值表\n\n#### 设计方法\n\n1. 进行逻辑抽象，根据事件的因果关系确定输入变量和输出变量，定义逻辑状态的含义，根据给定的因果关系列出逻辑真值表\n2. 写出逻辑函数式\n3. 选定器件的类型\n4. 将逻辑函数化简或变换成适当的形式\n5. 根据逻辑函数式画出逻辑电路图\n\n### 常用的组合逻辑电路\n\n#### 编码器\n\n##### 普通编码器\n\n任何时刻只允许输入一个编码信号\n\n![image-20201207180435959](数字电路/image-20201207180435959.png)\n\n![image-20201207180624804](数字电路/image-20201207180624804.png)\n\n##### 优先编码器\n\n![image-20201207202208723](数字电路/image-20201207202208723.png)\n\nS‘ 为选通输入端，只有S' = 0 时，编码器才能正常工作，而在S' = 1时，所有的输出端均被封锁在高电平\n\n![image-20201207202442317](数字电路/image-20201207202442317.png)\n\n![image-20201207202738889](数字电路/image-20201207202738889.png)\n\n![image-20201207202617679](数字电路/image-20201207202617679.png)\n\n> 当芯片接口带圈时，输入信号表示为 X’\n\n##### 二--十进制优先编码器\n\n#### 译码器\n\n##### 普通译码器\n\n\n\n![image-20201207204428555](数字电路/image-20201207204428555.png)\n\n![image-20201207204622034](数字电路/image-20201207204622034.png)\n\n![image-20201207204956445](数字电路/image-20201207204956445.png)\n\n##### 二--十进制译码器\n\n##### 显示译码器\n\n###### 七段字符显示器\n\n###### BCD - 七段显示译码器\n\n##### 用译码器设计组合逻辑电路\n\n![image-20201207205904689](数字电路/image-20201207205904689.png)\n\n![image-20201207210045223](数字电路/image-20201207210045223.png)\n\n#### 数据选择器\n\n##### 四选一数据选择器\n\n`A0, A1` 决定选择的数据，S‘ 控制电路工作状态，S' = 0 时数据选择器工作，反之不工作\n\n##### 八选一数据选择器\n\n![image-20201207211753609](数字电路/image-20201207211753609.png)\n\n##### 用数据选择器设计组合逻辑电路\n\n![image-20201207225752379](数字电路/image-20201207225752379.png)\n\n#### 加法器\n\n##### 一位加法器\n\n半加器（不考虑进位）\n\n全加器（考虑进位）\n\n##### 多位加法器\n\n串行进位加法器\n\n超前进位加法器\n\n#### 利用加法器设计电路\n\n![image-20201207230758027](数字电路/image-20201207230758027.png)\n\n#### 数值比较器\n\n##### 1位数值比较器\n\n![image-20201207231257765](数字电路/image-20201207231257765.png)\n\n##### 多位数值比较器\n\n![image-20201207231703395](数字电路/image-20201207231703395.png)\n\nI 是来自低位的比较信息\n\n## 第五章 触发器\n\n能够储存 1 位二值信号的基本单元电路统称为触发器\n\n### SR锁存器\n\n![image-20201207234319334](数字电路/image-20201207234319334.png)\n\n![image-20201207234431264](数字电路/image-20201207234431264.png)\n\n### 电平触发的触发器\n\n触发信号输入端               触发信号 `CLK`\n\n![image-20201208093951521](数字电路/image-20201208093951521.png)\n\n当 `CLK=0`时，S, R的信号无法影响到输出，当 `CLK=1`时，S, R的信号才能起作用\n\n![image-20201208094730885](数字电路/image-20201208094730885.png)\n\n### 电平触发的D触发器\n\n![image-20201208095118685](数字电路/image-20201208095118685.png)\n\n当`CLK=1`时，Q的值和D相同，当`CLK=0`时，Q的值保持不变\n\n### 脉冲触发的触发器（主从SR触发器）\n\n![image-20201208100213115](数字电路/image-20201208100213115.png)\n\n![image-20201208100252440](数字电路/image-20201208100252440.png)\n\n![image-20201208100311393](数字电路/image-20201208100311393.png)\n\n### 主从 JK 触发器\n\n![image-20201208100710777](数字电路/image-20201208100710777.png)\n\n当下降沿到达时，\n\n若 J=1, K=0，则Q置1，若 J=0, K=1，则Q置0，若 J=0, K=0，则Q不变，若 J=1, K=1，则Q状态翻转（0变1，1变0）\n\n\n\n主从触发器的状态由全部在CLK=1时的动作决定\n\n### 边沿触发的触发器\n\n![image-20201208102916928](数字电路/image-20201208102916928.png)\n\n![image-20201208103050351](数字电路/image-20201208103050351.png)\n\n### T触发器\n\n![image-20201208103416148](数字电路/image-20201208103416148.png)\n\n### 触发器分类\n\n![image-20201208103304650](数字电路/image-20201208103304650.png)\n\n## 第六章 时序逻辑电路\n\n### 特性方程\n\n ![image-20201208120335673](数字电路/image-20201208120335673.png)\n\nD 触发器的特性方程 Q* = D\n\nT 触发器的特性方程 Q* = TQ' + T'Q\n\n### 分析同步时序逻辑电路\n\n![image-20201208120149198](数字电路/image-20201208120149198.png)\n\n### 异步时序逻辑电路\n\n### 常用时序逻辑电路\n\n#### 寄存器\n\n#### 移位寄存器\n\n![image-20201208133000921](数字电路/image-20201208133000921.png)\n\n![image-20201208133500161](数字电路/image-20201208133500161.png)\n\n#### 计数器\n\n##### 同步计数器\n\n![image-20201208162623051](数字电路/image-20201208162623051.png)\n\n![image-20201208162700995](数字电路/image-20201208162700995.png)\n\n![image-20201208163034352](数字电路/image-20201208163034352.png)\n\n![image-20201208163053439](数字电路/image-20201208163053439.png)\n\n##### 同步置零和异步置零\n\n![image-20201208163510773](数字电路/image-20201208163510773.png)\n\n##### 异步计数器\n\n##### 任意进制计数器的构成方法\n\n假设已有的是N进制计数器，而需要得到的是M进制计数器，此时分为两种情况：\n\n1. M<N\n\n置零法（复位法），置数法（置位法）\n\n同步置零法：从S0状态出发到达S(M-1)状态时译出同步置零信号，在下一次CLK到达后变为S0状态\n\n![image-20201208192312875](数字电路/image-20201208192312875.png)\n\n异步置零法：从S0状态出发到达S(M)状态时译出异步置零信号，变为S0状态\n\n同步置数法：到达 Si 状态时令 LD'=0 ，在下一个 CLK 到来时，将要置入的数据置入计数器中，状态变为 Sj\n\n![image-20201208192326383](数字电路/image-20201208192326383.png)\n\n异步置数法：到达 S(i+1) 状态时令 LD'=0 ，状态直接变为 Sj\n\n2. M>N\n\n![image-20201208211819333](数字电路/image-20201208211819333.png)\n\n![image-20201208211825145](数字电路/image-20201208211825145.png)\n\n![image-20201208212439760](数字电路/image-20201208212439760.png)\n\n![image-20201208212442919](数字电路/image-20201208212442919.png)\n\n##### 移位寄存器型计数器\n\n环形计数器\n\n扭环形计数器\n\n### 同步时序逻辑电路的设计方法\n\n![image-20201208214549378](数字电路/image-20201208214549378.png)\n\n1. 逻辑抽象，得出电路的状态转换图或状态转换表\n2. 状态化简\n\n![image-20201208214717350](数字电路/image-20201208214717350.png)\n\n3. 状态分配\n\n![image-20201208214956731](数字电路/image-20201208214956731.png)\n\n4. 选定触发器的类型，求出电路的状态方程、驱动方程和输出方程\n\n![image-20201208215446146](数字电路/image-20201208215446146.png)\n\n![image-20201208215327269](数字电路/image-20201208215327269.png)\n\n![image-20201208215405366](数字电路/image-20201208215405366.png)\n\n![image-20201208215602590](数字电路/image-20201208215602590.png)\n\n5. 根据得到的方程式画出逻辑图\n\n![image-20201208215639819](数字电路/image-20201208215639819.png)\n\n6. 检查设计的电路能否自启动\n\n![image-20201208215654220](数字电路/image-20201208215654220.png)\n\n### 异步时序逻辑电路的设计方法\n\n![image-20201208215859239](数字电路/image-20201208215859239.png)\n\n## 第七章 半导体存储器\n\n### 分类\n\n#### 只读存储器\n\n掩模 ROM\n\n可编程 PROM\n\n可擦除的可编程 EPROM\n\n#### 随机读写存储器\n\n动态 DRAM\n\n静态 SRAM\n\n![image-20201209091933646](数字电路/image-20201209091933646.png)\n\n![image-20201209092949508](数字电路/image-20201209092949508.png)\n\n\n","slug":"数字电路","published":1,"updated":"2020-12-21T09:58:31.620Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckiyh709a0013a0uz9vnhwcoc","content":"<h1 id=\"数字电路复习笔记\"><a href=\"#数字电路复习笔记\" class=\"headerlink\" title=\"数字电路复习笔记\"></a>数字电路复习笔记</h1><p>关于数字电路自己总结的复习笔记，仅供参考，不怎么全</p>\n<a id=\"more\"></a>\n<h2 id=\"第一章-数制和码制\"><a href=\"#第一章-数制和码制\" class=\"headerlink\" title=\"第一章 数制和码制\"></a>第一章 数制和码制</h2><h3 id=\"进制转换（整数和小数）\"><a href=\"#进制转换（整数和小数）\" class=\"headerlink\" title=\"进制转换（整数和小数）\"></a>进制转换（整数和小数）</h3><h3 id=\"原码，反码，补码\"><a href=\"#原码，反码，补码\" class=\"headerlink\" title=\"原码，反码，补码\"></a>原码，反码，补码</h3><blockquote>\n<p>正数的原码等于反码等于补码</p>\n<p>负数的反码等于原码0变1，1变0，补码等于反码+1</p>\n<p>二进制数运算：补码运算</p>\n</blockquote>\n<h3 id=\"常用编码\"><a href=\"#常用编码\" class=\"headerlink\" title=\"常用编码\"></a>常用编码</h3><h4 id=\"十进制\"><a href=\"#十进制\" class=\"headerlink\" title=\"十进制\"></a>十进制</h4><p><img src=\"/2020/09/07/数字电路/image-20201207095115200.png\" alt=\"image-20201207095115200\"></p>\n<p>余3码的数值比对应十进制数多3</p>\n<p>注意下面的权值，代表各个位置为1时的大小</p>\n<h4 id=\"格雷码\"><a href=\"#格雷码\" class=\"headerlink\" title=\"格雷码\"></a>格雷码</h4><p><img src=\"/2020/09/07/数字电路/image-20201207095702879.png\" alt=\"image-20201207095702879\"></p>\n<h2 id=\"第二章-逻辑代数基础\"><a href=\"#第二章-逻辑代数基础\" class=\"headerlink\" title=\"第二章 逻辑代数基础\"></a>第二章 逻辑代数基础</h2><p><img src=\"/2020/09/07/数字电路/image-20201207100058038.png\" alt=\"image-20201207100058038\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207100101916.png\" alt=\"image-20201207100101916\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207100105985.png\" alt=\"image-20201207100105985\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207100108953.png\" alt=\"image-20201207100108953\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207100257128.png\" alt=\"image-20201207100257128\"></p>\n<h3 id=\"基本公式\"><a href=\"#基本公式\" class=\"headerlink\" title=\"基本公式\"></a>基本公式</h3><p><img src=\"/2020/09/07/数字电路/image-20201207100339923.png\" alt=\"image-20201207100339923\"></p>\n<h3 id=\"常用公式\"><a href=\"#常用公式\" class=\"headerlink\" title=\"常用公式\"></a>常用公式</h3><p><img src=\"/2020/09/07/数字电路/image-20201207100458411.png\" alt=\"image-20201207100458411\"></p>\n<h3 id=\"逻辑函数的表示方法\"><a href=\"#逻辑函数的表示方法\" class=\"headerlink\" title=\"逻辑函数的表示方法\"></a>逻辑函数的表示方法</h3><p>逻辑真值表，逻辑函数式，逻辑图（将逻辑关系用图形符号表示出来），波形图</p>\n<p>最小项和最大项</p>\n<p>转化为或非可以先转化为与或非的形式（利用最小项以及Y=(Y ‘) ’），再转换为或非的形式</p>\n<p>逻辑函数化简</p>\n<h3 id=\"卡诺图\"><a href=\"#卡诺图\" class=\"headerlink\" title=\"卡诺图\"></a>卡诺图</h3><p><img src=\"/2020/09/07/数字电路/image-20201207103734768.png\" alt=\"image-20201207103734768\"></p>\n<p>卡诺图合并，可以重复使用一个最小项</p>\n<h3 id=\"具有无关项的逻辑函数及其化简\"><a href=\"#具有无关项的逻辑函数及其化简\" class=\"headerlink\" title=\"具有无关项的逻辑函数及其化简\"></a>具有无关项的逻辑函数及其化简</h3><h2 id=\"第三章-门电路\"><a href=\"#第三章-门电路\" class=\"headerlink\" title=\"第三章 门电路\"></a>第三章 门电路</h2><p><img src=\"/2020/09/07/数字电路/image-20201207141227512.png\" alt=\"image-20201207141227512\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207141230974.png\" alt=\"image-20201207141230974\"></p>\n<h3 id=\"CMOS门电路\"><a href=\"#CMOS门电路\" class=\"headerlink\" title=\"CMOS门电路\"></a>CMOS门电路</h3><p><img src=\"/2020/09/07/数字电路/image-20201207141338902.png\" alt=\"image-20201207141338902\"></p>\n<h4 id=\"CMOS反相器\"><a href=\"#CMOS反相器\" class=\"headerlink\" title=\"CMOS反相器\"></a>CMOS反相器</h4><p><img src=\"/2020/09/07/数字电路/image-20201207143351015.png\" alt=\"image-20201207143351015\"></p>\n<h4 id=\"CMOS与非门-或非门\"><a href=\"#CMOS与非门-或非门\" class=\"headerlink\" title=\"CMOS与非门 或非门\"></a>CMOS与非门 或非门</h4><p><img src=\"/2020/09/07/数字电路/image-20201207143605620.png\" alt=\"image-20201207143605620\"></p>\n<h4 id=\"CMOS传输门\"><a href=\"#CMOS传输门\" class=\"headerlink\" title=\"CMOS传输门\"></a>CMOS传输门</h4><p><img src=\"/2020/09/07/数字电路/image-20201207150409345.png\" alt=\"image-20201207150409345\"></p>\n<p>当C=1,C’=0时导通，C=0,C’=1时截止</p>\n<h4 id=\"三态输出的CMOS门电路\"><a href=\"#三态输出的CMOS门电路\" class=\"headerlink\" title=\"三态输出的CMOS门电路\"></a>三态输出的CMOS门电路</h4><p>b图若EN’连线尾部有圈则为低电平有效，当EN’=0时正常与非门，当EN’=1时高阻</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207151538922.png\" alt=\"image-20201207151538922\"></p>\n<p>理解3.3.40图   难</p>\n<h3 id=\"TTL门电路\"><a href=\"#TTL门电路\" class=\"headerlink\" title=\"TTL门电路\"></a>TTL门电路</h3><p><img src=\"/2020/09/07/数字电路/image-20201207155711758.png\" alt=\"image-20201207155711758\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207155851664.png\" alt=\"image-20201207155851664\"></p>\n<h4 id=\"三极管反相器\"><a href=\"#三极管反相器\" class=\"headerlink\" title=\"三极管反相器\"></a>三极管反相器</h4><p><img src=\"/2020/09/07/数字电路/image-20201207155940917.png\" alt=\"image-20201207155940917\"></p>\n<h4 id=\"TTL反相器\"><a href=\"#TTL反相器\" class=\"headerlink\" title=\"TTL反相器\"></a>TTL反相器</h4><p><img src=\"/2020/09/07/数字电路/image-20201207160054355.png\" alt=\"image-20201207160054355\"></p>\n<h4 id=\"TTL门电路——与非门，或非门，与或非门，异或门\"><a href=\"#TTL门电路——与非门，或非门，与或非门，异或门\" class=\"headerlink\" title=\"TTL门电路——与非门，或非门，与或非门，异或门\"></a>TTL门电路——与非门，或非门，与或非门，异或门</h4><p>多发射极三极管可以看作两个发射级独立而基极和集电极分别并联在一起的三极管</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207163239045.png\" alt=\"image-20201207163239045\"></p>\n<p>只要有一个导通，则输出为低电平，只有两个都不导通的时候，则输出端c才是高电平</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207163011726.png\" alt=\"image-20201207163011726\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207163100622.png\" alt=\"image-20201207163100622\"></p>\n<h4 id=\"集电极开路输出的门电路（OC门）\"><a href=\"#集电极开路输出的门电路（OC门）\" class=\"headerlink\" title=\"集电极开路输出的门电路（OC门）\"></a>集电极开路输出的门电路（OC门）</h4><h4 id=\"三态输出门电路（TS门）\"><a href=\"#三态输出门电路（TS门）\" class=\"headerlink\" title=\"三态输出门电路（TS门）\"></a>三态输出门电路（TS门）</h4><p>高电平有效：</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207164852673.png\" alt=\"image-20201207164852673\"></p>\n<p>低电平有效：</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207164837016.png\" alt=\"image-20201207164837016\"></p>\n<h2 id=\"第四章-组合逻辑电路\"><a href=\"#第四章-组合逻辑电路\" class=\"headerlink\" title=\"第四章 组合逻辑电路\"></a>第四章 组合逻辑电路</h2><h3 id=\"组合逻辑电路的分析方法和设计方法\"><a href=\"#组合逻辑电路的分析方法和设计方法\" class=\"headerlink\" title=\"组合逻辑电路的分析方法和设计方法\"></a>组合逻辑电路的分析方法和设计方法</h3><h4 id=\"分析方法\"><a href=\"#分析方法\" class=\"headerlink\" title=\"分析方法\"></a>分析方法</h4><p>将电路图转换为函数式或者真值表</p>\n<h4 id=\"设计方法\"><a href=\"#设计方法\" class=\"headerlink\" title=\"设计方法\"></a>设计方法</h4><ol>\n<li>进行逻辑抽象，根据事件的因果关系确定输入变量和输出变量，定义逻辑状态的含义，根据给定的因果关系列出逻辑真值表</li>\n<li>写出逻辑函数式</li>\n<li>选定器件的类型</li>\n<li>将逻辑函数化简或变换成适当的形式</li>\n<li>根据逻辑函数式画出逻辑电路图</li>\n</ol>\n<h3 id=\"常用的组合逻辑电路\"><a href=\"#常用的组合逻辑电路\" class=\"headerlink\" title=\"常用的组合逻辑电路\"></a>常用的组合逻辑电路</h3><h4 id=\"编码器\"><a href=\"#编码器\" class=\"headerlink\" title=\"编码器\"></a>编码器</h4><h5 id=\"普通编码器\"><a href=\"#普通编码器\" class=\"headerlink\" title=\"普通编码器\"></a>普通编码器</h5><p>任何时刻只允许输入一个编码信号</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207180435959.png\" alt=\"image-20201207180435959\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207180624804.png\" alt=\"image-20201207180624804\"></p>\n<h5 id=\"优先编码器\"><a href=\"#优先编码器\" class=\"headerlink\" title=\"优先编码器\"></a>优先编码器</h5><p><img src=\"/2020/09/07/数字电路/image-20201207202208723.png\" alt=\"image-20201207202208723\"></p>\n<p>S‘ 为选通输入端，只有S’ = 0 时，编码器才能正常工作，而在S’ = 1时，所有的输出端均被封锁在高电平</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207202442317.png\" alt=\"image-20201207202442317\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207202738889.png\" alt=\"image-20201207202738889\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207202617679.png\" alt=\"image-20201207202617679\"></p>\n<blockquote>\n<p>当芯片接口带圈时，输入信号表示为 X’</p>\n</blockquote>\n<h5 id=\"二—十进制优先编码器\"><a href=\"#二—十进制优先编码器\" class=\"headerlink\" title=\"二—十进制优先编码器\"></a>二—十进制优先编码器</h5><h4 id=\"译码器\"><a href=\"#译码器\" class=\"headerlink\" title=\"译码器\"></a>译码器</h4><h5 id=\"普通译码器\"><a href=\"#普通译码器\" class=\"headerlink\" title=\"普通译码器\"></a>普通译码器</h5><p><img src=\"/2020/09/07/数字电路/image-20201207204428555.png\" alt=\"image-20201207204428555\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207204622034.png\" alt=\"image-20201207204622034\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207204956445.png\" alt=\"image-20201207204956445\"></p>\n<h5 id=\"二—十进制译码器\"><a href=\"#二—十进制译码器\" class=\"headerlink\" title=\"二—十进制译码器\"></a>二—十进制译码器</h5><h5 id=\"显示译码器\"><a href=\"#显示译码器\" class=\"headerlink\" title=\"显示译码器\"></a>显示译码器</h5><h6 id=\"七段字符显示器\"><a href=\"#七段字符显示器\" class=\"headerlink\" title=\"七段字符显示器\"></a>七段字符显示器</h6><h6 id=\"BCD-七段显示译码器\"><a href=\"#BCD-七段显示译码器\" class=\"headerlink\" title=\"BCD - 七段显示译码器\"></a>BCD - 七段显示译码器</h6><h5 id=\"用译码器设计组合逻辑电路\"><a href=\"#用译码器设计组合逻辑电路\" class=\"headerlink\" title=\"用译码器设计组合逻辑电路\"></a>用译码器设计组合逻辑电路</h5><p><img src=\"/2020/09/07/数字电路/image-20201207205904689.png\" alt=\"image-20201207205904689\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207210045223.png\" alt=\"image-20201207210045223\"></p>\n<h4 id=\"数据选择器\"><a href=\"#数据选择器\" class=\"headerlink\" title=\"数据选择器\"></a>数据选择器</h4><h5 id=\"四选一数据选择器\"><a href=\"#四选一数据选择器\" class=\"headerlink\" title=\"四选一数据选择器\"></a>四选一数据选择器</h5><p><code>A0, A1</code> 决定选择的数据，S‘ 控制电路工作状态，S’ = 0 时数据选择器工作，反之不工作</p>\n<h5 id=\"八选一数据选择器\"><a href=\"#八选一数据选择器\" class=\"headerlink\" title=\"八选一数据选择器\"></a>八选一数据选择器</h5><p><img src=\"/2020/09/07/数字电路/image-20201207211753609.png\" alt=\"image-20201207211753609\"></p>\n<h5 id=\"用数据选择器设计组合逻辑电路\"><a href=\"#用数据选择器设计组合逻辑电路\" class=\"headerlink\" title=\"用数据选择器设计组合逻辑电路\"></a>用数据选择器设计组合逻辑电路</h5><p><img src=\"/2020/09/07/数字电路/image-20201207225752379.png\" alt=\"image-20201207225752379\"></p>\n<h4 id=\"加法器\"><a href=\"#加法器\" class=\"headerlink\" title=\"加法器\"></a>加法器</h4><h5 id=\"一位加法器\"><a href=\"#一位加法器\" class=\"headerlink\" title=\"一位加法器\"></a>一位加法器</h5><p>半加器（不考虑进位）</p>\n<p>全加器（考虑进位）</p>\n<h5 id=\"多位加法器\"><a href=\"#多位加法器\" class=\"headerlink\" title=\"多位加法器\"></a>多位加法器</h5><p>串行进位加法器</p>\n<p>超前进位加法器</p>\n<h4 id=\"利用加法器设计电路\"><a href=\"#利用加法器设计电路\" class=\"headerlink\" title=\"利用加法器设计电路\"></a>利用加法器设计电路</h4><p><img src=\"/2020/09/07/数字电路/image-20201207230758027.png\" alt=\"image-20201207230758027\"></p>\n<h4 id=\"数值比较器\"><a href=\"#数值比较器\" class=\"headerlink\" title=\"数值比较器\"></a>数值比较器</h4><h5 id=\"1位数值比较器\"><a href=\"#1位数值比较器\" class=\"headerlink\" title=\"1位数值比较器\"></a>1位数值比较器</h5><p><img src=\"/2020/09/07/数字电路/image-20201207231257765.png\" alt=\"image-20201207231257765\"></p>\n<h5 id=\"多位数值比较器\"><a href=\"#多位数值比较器\" class=\"headerlink\" title=\"多位数值比较器\"></a>多位数值比较器</h5><p><img src=\"/2020/09/07/数字电路/image-20201207231703395.png\" alt=\"image-20201207231703395\"></p>\n<p>I 是来自低位的比较信息</p>\n<h2 id=\"第五章-触发器\"><a href=\"#第五章-触发器\" class=\"headerlink\" title=\"第五章 触发器\"></a>第五章 触发器</h2><p>能够储存 1 位二值信号的基本单元电路统称为触发器</p>\n<h3 id=\"SR锁存器\"><a href=\"#SR锁存器\" class=\"headerlink\" title=\"SR锁存器\"></a>SR锁存器</h3><p><img src=\"/2020/09/07/数字电路/image-20201207234319334.png\" alt=\"image-20201207234319334\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207234431264.png\" alt=\"image-20201207234431264\"></p>\n<h3 id=\"电平触发的触发器\"><a href=\"#电平触发的触发器\" class=\"headerlink\" title=\"电平触发的触发器\"></a>电平触发的触发器</h3><p>触发信号输入端               触发信号 <code>CLK</code></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208093951521.png\" alt=\"image-20201208093951521\"></p>\n<p>当 <code>CLK=0</code>时，S, R的信号无法影响到输出，当 <code>CLK=1</code>时，S, R的信号才能起作用</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208094730885.png\" alt=\"image-20201208094730885\"></p>\n<h3 id=\"电平触发的D触发器\"><a href=\"#电平触发的D触发器\" class=\"headerlink\" title=\"电平触发的D触发器\"></a>电平触发的D触发器</h3><p><img src=\"/2020/09/07/数字电路/image-20201208095118685.png\" alt=\"image-20201208095118685\"></p>\n<p>当<code>CLK=1</code>时，Q的值和D相同，当<code>CLK=0</code>时，Q的值保持不变</p>\n<h3 id=\"脉冲触发的触发器（主从SR触发器）\"><a href=\"#脉冲触发的触发器（主从SR触发器）\" class=\"headerlink\" title=\"脉冲触发的触发器（主从SR触发器）\"></a>脉冲触发的触发器（主从SR触发器）</h3><p><img src=\"/2020/09/07/数字电路/image-20201208100213115.png\" alt=\"image-20201208100213115\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208100252440.png\" alt=\"image-20201208100252440\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208100311393.png\" alt=\"image-20201208100311393\"></p>\n<h3 id=\"主从-JK-触发器\"><a href=\"#主从-JK-触发器\" class=\"headerlink\" title=\"主从 JK 触发器\"></a>主从 JK 触发器</h3><p><img src=\"/2020/09/07/数字电路/image-20201208100710777.png\" alt=\"image-20201208100710777\"></p>\n<p>当下降沿到达时，</p>\n<p>若 J=1, K=0，则Q置1，若 J=0, K=1，则Q置0，若 J=0, K=0，则Q不变，若 J=1, K=1，则Q状态翻转（0变1，1变0）</p>\n<p>主从触发器的状态由全部在CLK=1时的动作决定</p>\n<h3 id=\"边沿触发的触发器\"><a href=\"#边沿触发的触发器\" class=\"headerlink\" title=\"边沿触发的触发器\"></a>边沿触发的触发器</h3><p><img src=\"/2020/09/07/数字电路/image-20201208102916928.png\" alt=\"image-20201208102916928\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208103050351.png\" alt=\"image-20201208103050351\"></p>\n<h3 id=\"T触发器\"><a href=\"#T触发器\" class=\"headerlink\" title=\"T触发器\"></a>T触发器</h3><p><img src=\"/2020/09/07/数字电路/image-20201208103416148.png\" alt=\"image-20201208103416148\"></p>\n<h3 id=\"触发器分类\"><a href=\"#触发器分类\" class=\"headerlink\" title=\"触发器分类\"></a>触发器分类</h3><p><img src=\"/2020/09/07/数字电路/image-20201208103304650.png\" alt=\"image-20201208103304650\"></p>\n<h2 id=\"第六章-时序逻辑电路\"><a href=\"#第六章-时序逻辑电路\" class=\"headerlink\" title=\"第六章 时序逻辑电路\"></a>第六章 时序逻辑电路</h2><h3 id=\"特性方程\"><a href=\"#特性方程\" class=\"headerlink\" title=\"特性方程\"></a>特性方程</h3><p> <img src=\"/2020/09/07/数字电路/image-20201208120335673.png\" alt=\"image-20201208120335673\"></p>\n<p>D 触发器的特性方程 Q* = D</p>\n<p>T 触发器的特性方程 Q* = TQ’ + T’Q</p>\n<h3 id=\"分析同步时序逻辑电路\"><a href=\"#分析同步时序逻辑电路\" class=\"headerlink\" title=\"分析同步时序逻辑电路\"></a>分析同步时序逻辑电路</h3><p><img src=\"/2020/09/07/数字电路/image-20201208120149198.png\" alt=\"image-20201208120149198\"></p>\n<h3 id=\"异步时序逻辑电路\"><a href=\"#异步时序逻辑电路\" class=\"headerlink\" title=\"异步时序逻辑电路\"></a>异步时序逻辑电路</h3><h3 id=\"常用时序逻辑电路\"><a href=\"#常用时序逻辑电路\" class=\"headerlink\" title=\"常用时序逻辑电路\"></a>常用时序逻辑电路</h3><h4 id=\"寄存器\"><a href=\"#寄存器\" class=\"headerlink\" title=\"寄存器\"></a>寄存器</h4><h4 id=\"移位寄存器\"><a href=\"#移位寄存器\" class=\"headerlink\" title=\"移位寄存器\"></a>移位寄存器</h4><p><img src=\"/2020/09/07/数字电路/image-20201208133000921.png\" alt=\"image-20201208133000921\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208133500161.png\" alt=\"image-20201208133500161\"></p>\n<h4 id=\"计数器\"><a href=\"#计数器\" class=\"headerlink\" title=\"计数器\"></a>计数器</h4><h5 id=\"同步计数器\"><a href=\"#同步计数器\" class=\"headerlink\" title=\"同步计数器\"></a>同步计数器</h5><p><img src=\"/2020/09/07/数字电路/image-20201208162623051.png\" alt=\"image-20201208162623051\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208162700995.png\" alt=\"image-20201208162700995\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208163034352.png\" alt=\"image-20201208163034352\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208163053439.png\" alt=\"image-20201208163053439\"></p>\n<h5 id=\"同步置零和异步置零\"><a href=\"#同步置零和异步置零\" class=\"headerlink\" title=\"同步置零和异步置零\"></a>同步置零和异步置零</h5><p><img src=\"/2020/09/07/数字电路/image-20201208163510773.png\" alt=\"image-20201208163510773\"></p>\n<h5 id=\"异步计数器\"><a href=\"#异步计数器\" class=\"headerlink\" title=\"异步计数器\"></a>异步计数器</h5><h5 id=\"任意进制计数器的构成方法\"><a href=\"#任意进制计数器的构成方法\" class=\"headerlink\" title=\"任意进制计数器的构成方法\"></a>任意进制计数器的构成方法</h5><p>假设已有的是N进制计数器，而需要得到的是M进制计数器，此时分为两种情况：</p>\n<ol>\n<li>M&lt;N</li>\n</ol>\n<p>置零法（复位法），置数法（置位法）</p>\n<p>同步置零法：从S0状态出发到达S(M-1)状态时译出同步置零信号，在下一次CLK到达后变为S0状态</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208192312875.png\" alt=\"image-20201208192312875\"></p>\n<p>异步置零法：从S0状态出发到达S(M)状态时译出异步置零信号，变为S0状态</p>\n<p>同步置数法：到达 Si 状态时令 LD’=0 ，在下一个 CLK 到来时，将要置入的数据置入计数器中，状态变为 Sj</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208192326383.png\" alt=\"image-20201208192326383\"></p>\n<p>异步置数法：到达 S(i+1) 状态时令 LD’=0 ，状态直接变为 Sj</p>\n<ol>\n<li>M&gt;N</li>\n</ol>\n<p><img src=\"/2020/09/07/数字电路/image-20201208211819333.png\" alt=\"image-20201208211819333\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208211825145.png\" alt=\"image-20201208211825145\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208212439760.png\" alt=\"image-20201208212439760\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208212442919.png\" alt=\"image-20201208212442919\"></p>\n<h5 id=\"移位寄存器型计数器\"><a href=\"#移位寄存器型计数器\" class=\"headerlink\" title=\"移位寄存器型计数器\"></a>移位寄存器型计数器</h5><p>环形计数器</p>\n<p>扭环形计数器</p>\n<h3 id=\"同步时序逻辑电路的设计方法\"><a href=\"#同步时序逻辑电路的设计方法\" class=\"headerlink\" title=\"同步时序逻辑电路的设计方法\"></a>同步时序逻辑电路的设计方法</h3><p><img src=\"/2020/09/07/数字电路/image-20201208214549378.png\" alt=\"image-20201208214549378\"></p>\n<ol>\n<li>逻辑抽象，得出电路的状态转换图或状态转换表</li>\n<li>状态化简</li>\n</ol>\n<p><img src=\"/2020/09/07/数字电路/image-20201208214717350.png\" alt=\"image-20201208214717350\"></p>\n<ol>\n<li>状态分配</li>\n</ol>\n<p><img src=\"/2020/09/07/数字电路/image-20201208214956731.png\" alt=\"image-20201208214956731\"></p>\n<ol>\n<li>选定触发器的类型，求出电路的状态方程、驱动方程和输出方程</li>\n</ol>\n<p><img src=\"/2020/09/07/数字电路/image-20201208215446146.png\" alt=\"image-20201208215446146\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208215327269.png\" alt=\"image-20201208215327269\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208215405366.png\" alt=\"image-20201208215405366\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208215602590.png\" alt=\"image-20201208215602590\"></p>\n<ol>\n<li>根据得到的方程式画出逻辑图</li>\n</ol>\n<p><img src=\"/2020/09/07/数字电路/image-20201208215639819.png\" alt=\"image-20201208215639819\"></p>\n<ol>\n<li>检查设计的电路能否自启动</li>\n</ol>\n<p><img src=\"/2020/09/07/数字电路/image-20201208215654220.png\" alt=\"image-20201208215654220\"></p>\n<h3 id=\"异步时序逻辑电路的设计方法\"><a href=\"#异步时序逻辑电路的设计方法\" class=\"headerlink\" title=\"异步时序逻辑电路的设计方法\"></a>异步时序逻辑电路的设计方法</h3><p><img src=\"/2020/09/07/数字电路/image-20201208215859239.png\" alt=\"image-20201208215859239\"></p>\n<h2 id=\"第七章-半导体存储器\"><a href=\"#第七章-半导体存储器\" class=\"headerlink\" title=\"第七章 半导体存储器\"></a>第七章 半导体存储器</h2><h3 id=\"分类\"><a href=\"#分类\" class=\"headerlink\" title=\"分类\"></a>分类</h3><h4 id=\"只读存储器\"><a href=\"#只读存储器\" class=\"headerlink\" title=\"只读存储器\"></a>只读存储器</h4><p>掩模 ROM</p>\n<p>可编程 PROM</p>\n<p>可擦除的可编程 EPROM</p>\n<h4 id=\"随机读写存储器\"><a href=\"#随机读写存储器\" class=\"headerlink\" title=\"随机读写存储器\"></a>随机读写存储器</h4><p>动态 DRAM</p>\n<p>静态 SRAM</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201209091933646.png\" alt=\"image-20201209091933646\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201209092949508.png\" alt=\"image-20201209092949508\"></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"数字电路复习笔记\"><a href=\"#数字电路复习笔记\" class=\"headerlink\" title=\"数字电路复习笔记\"></a>数字电路复习笔记</h1><p>关于数字电路自己总结的复习笔记，仅供参考，不怎么全</p>","more":"<h2 id=\"第一章-数制和码制\"><a href=\"#第一章-数制和码制\" class=\"headerlink\" title=\"第一章 数制和码制\"></a>第一章 数制和码制</h2><h3 id=\"进制转换（整数和小数）\"><a href=\"#进制转换（整数和小数）\" class=\"headerlink\" title=\"进制转换（整数和小数）\"></a>进制转换（整数和小数）</h3><h3 id=\"原码，反码，补码\"><a href=\"#原码，反码，补码\" class=\"headerlink\" title=\"原码，反码，补码\"></a>原码，反码，补码</h3><blockquote>\n<p>正数的原码等于反码等于补码</p>\n<p>负数的反码等于原码0变1，1变0，补码等于反码+1</p>\n<p>二进制数运算：补码运算</p>\n</blockquote>\n<h3 id=\"常用编码\"><a href=\"#常用编码\" class=\"headerlink\" title=\"常用编码\"></a>常用编码</h3><h4 id=\"十进制\"><a href=\"#十进制\" class=\"headerlink\" title=\"十进制\"></a>十进制</h4><p><img src=\"/2020/09/07/数字电路/image-20201207095115200.png\" alt=\"image-20201207095115200\"></p>\n<p>余3码的数值比对应十进制数多3</p>\n<p>注意下面的权值，代表各个位置为1时的大小</p>\n<h4 id=\"格雷码\"><a href=\"#格雷码\" class=\"headerlink\" title=\"格雷码\"></a>格雷码</h4><p><img src=\"/2020/09/07/数字电路/image-20201207095702879.png\" alt=\"image-20201207095702879\"></p>\n<h2 id=\"第二章-逻辑代数基础\"><a href=\"#第二章-逻辑代数基础\" class=\"headerlink\" title=\"第二章 逻辑代数基础\"></a>第二章 逻辑代数基础</h2><p><img src=\"/2020/09/07/数字电路/image-20201207100058038.png\" alt=\"image-20201207100058038\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207100101916.png\" alt=\"image-20201207100101916\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207100105985.png\" alt=\"image-20201207100105985\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207100108953.png\" alt=\"image-20201207100108953\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207100257128.png\" alt=\"image-20201207100257128\"></p>\n<h3 id=\"基本公式\"><a href=\"#基本公式\" class=\"headerlink\" title=\"基本公式\"></a>基本公式</h3><p><img src=\"/2020/09/07/数字电路/image-20201207100339923.png\" alt=\"image-20201207100339923\"></p>\n<h3 id=\"常用公式\"><a href=\"#常用公式\" class=\"headerlink\" title=\"常用公式\"></a>常用公式</h3><p><img src=\"/2020/09/07/数字电路/image-20201207100458411.png\" alt=\"image-20201207100458411\"></p>\n<h3 id=\"逻辑函数的表示方法\"><a href=\"#逻辑函数的表示方法\" class=\"headerlink\" title=\"逻辑函数的表示方法\"></a>逻辑函数的表示方法</h3><p>逻辑真值表，逻辑函数式，逻辑图（将逻辑关系用图形符号表示出来），波形图</p>\n<p>最小项和最大项</p>\n<p>转化为或非可以先转化为与或非的形式（利用最小项以及Y=(Y ‘) ’），再转换为或非的形式</p>\n<p>逻辑函数化简</p>\n<h3 id=\"卡诺图\"><a href=\"#卡诺图\" class=\"headerlink\" title=\"卡诺图\"></a>卡诺图</h3><p><img src=\"/2020/09/07/数字电路/image-20201207103734768.png\" alt=\"image-20201207103734768\"></p>\n<p>卡诺图合并，可以重复使用一个最小项</p>\n<h3 id=\"具有无关项的逻辑函数及其化简\"><a href=\"#具有无关项的逻辑函数及其化简\" class=\"headerlink\" title=\"具有无关项的逻辑函数及其化简\"></a>具有无关项的逻辑函数及其化简</h3><h2 id=\"第三章-门电路\"><a href=\"#第三章-门电路\" class=\"headerlink\" title=\"第三章 门电路\"></a>第三章 门电路</h2><p><img src=\"/2020/09/07/数字电路/image-20201207141227512.png\" alt=\"image-20201207141227512\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207141230974.png\" alt=\"image-20201207141230974\"></p>\n<h3 id=\"CMOS门电路\"><a href=\"#CMOS门电路\" class=\"headerlink\" title=\"CMOS门电路\"></a>CMOS门电路</h3><p><img src=\"/2020/09/07/数字电路/image-20201207141338902.png\" alt=\"image-20201207141338902\"></p>\n<h4 id=\"CMOS反相器\"><a href=\"#CMOS反相器\" class=\"headerlink\" title=\"CMOS反相器\"></a>CMOS反相器</h4><p><img src=\"/2020/09/07/数字电路/image-20201207143351015.png\" alt=\"image-20201207143351015\"></p>\n<h4 id=\"CMOS与非门-或非门\"><a href=\"#CMOS与非门-或非门\" class=\"headerlink\" title=\"CMOS与非门 或非门\"></a>CMOS与非门 或非门</h4><p><img src=\"/2020/09/07/数字电路/image-20201207143605620.png\" alt=\"image-20201207143605620\"></p>\n<h4 id=\"CMOS传输门\"><a href=\"#CMOS传输门\" class=\"headerlink\" title=\"CMOS传输门\"></a>CMOS传输门</h4><p><img src=\"/2020/09/07/数字电路/image-20201207150409345.png\" alt=\"image-20201207150409345\"></p>\n<p>当C=1,C’=0时导通，C=0,C’=1时截止</p>\n<h4 id=\"三态输出的CMOS门电路\"><a href=\"#三态输出的CMOS门电路\" class=\"headerlink\" title=\"三态输出的CMOS门电路\"></a>三态输出的CMOS门电路</h4><p>b图若EN’连线尾部有圈则为低电平有效，当EN’=0时正常与非门，当EN’=1时高阻</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207151538922.png\" alt=\"image-20201207151538922\"></p>\n<p>理解3.3.40图   难</p>\n<h3 id=\"TTL门电路\"><a href=\"#TTL门电路\" class=\"headerlink\" title=\"TTL门电路\"></a>TTL门电路</h3><p><img src=\"/2020/09/07/数字电路/image-20201207155711758.png\" alt=\"image-20201207155711758\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207155851664.png\" alt=\"image-20201207155851664\"></p>\n<h4 id=\"三极管反相器\"><a href=\"#三极管反相器\" class=\"headerlink\" title=\"三极管反相器\"></a>三极管反相器</h4><p><img src=\"/2020/09/07/数字电路/image-20201207155940917.png\" alt=\"image-20201207155940917\"></p>\n<h4 id=\"TTL反相器\"><a href=\"#TTL反相器\" class=\"headerlink\" title=\"TTL反相器\"></a>TTL反相器</h4><p><img src=\"/2020/09/07/数字电路/image-20201207160054355.png\" alt=\"image-20201207160054355\"></p>\n<h4 id=\"TTL门电路——与非门，或非门，与或非门，异或门\"><a href=\"#TTL门电路——与非门，或非门，与或非门，异或门\" class=\"headerlink\" title=\"TTL门电路——与非门，或非门，与或非门，异或门\"></a>TTL门电路——与非门，或非门，与或非门，异或门</h4><p>多发射极三极管可以看作两个发射级独立而基极和集电极分别并联在一起的三极管</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207163239045.png\" alt=\"image-20201207163239045\"></p>\n<p>只要有一个导通，则输出为低电平，只有两个都不导通的时候，则输出端c才是高电平</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207163011726.png\" alt=\"image-20201207163011726\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207163100622.png\" alt=\"image-20201207163100622\"></p>\n<h4 id=\"集电极开路输出的门电路（OC门）\"><a href=\"#集电极开路输出的门电路（OC门）\" class=\"headerlink\" title=\"集电极开路输出的门电路（OC门）\"></a>集电极开路输出的门电路（OC门）</h4><h4 id=\"三态输出门电路（TS门）\"><a href=\"#三态输出门电路（TS门）\" class=\"headerlink\" title=\"三态输出门电路（TS门）\"></a>三态输出门电路（TS门）</h4><p>高电平有效：</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207164852673.png\" alt=\"image-20201207164852673\"></p>\n<p>低电平有效：</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207164837016.png\" alt=\"image-20201207164837016\"></p>\n<h2 id=\"第四章-组合逻辑电路\"><a href=\"#第四章-组合逻辑电路\" class=\"headerlink\" title=\"第四章 组合逻辑电路\"></a>第四章 组合逻辑电路</h2><h3 id=\"组合逻辑电路的分析方法和设计方法\"><a href=\"#组合逻辑电路的分析方法和设计方法\" class=\"headerlink\" title=\"组合逻辑电路的分析方法和设计方法\"></a>组合逻辑电路的分析方法和设计方法</h3><h4 id=\"分析方法\"><a href=\"#分析方法\" class=\"headerlink\" title=\"分析方法\"></a>分析方法</h4><p>将电路图转换为函数式或者真值表</p>\n<h4 id=\"设计方法\"><a href=\"#设计方法\" class=\"headerlink\" title=\"设计方法\"></a>设计方法</h4><ol>\n<li>进行逻辑抽象，根据事件的因果关系确定输入变量和输出变量，定义逻辑状态的含义，根据给定的因果关系列出逻辑真值表</li>\n<li>写出逻辑函数式</li>\n<li>选定器件的类型</li>\n<li>将逻辑函数化简或变换成适当的形式</li>\n<li>根据逻辑函数式画出逻辑电路图</li>\n</ol>\n<h3 id=\"常用的组合逻辑电路\"><a href=\"#常用的组合逻辑电路\" class=\"headerlink\" title=\"常用的组合逻辑电路\"></a>常用的组合逻辑电路</h3><h4 id=\"编码器\"><a href=\"#编码器\" class=\"headerlink\" title=\"编码器\"></a>编码器</h4><h5 id=\"普通编码器\"><a href=\"#普通编码器\" class=\"headerlink\" title=\"普通编码器\"></a>普通编码器</h5><p>任何时刻只允许输入一个编码信号</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207180435959.png\" alt=\"image-20201207180435959\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207180624804.png\" alt=\"image-20201207180624804\"></p>\n<h5 id=\"优先编码器\"><a href=\"#优先编码器\" class=\"headerlink\" title=\"优先编码器\"></a>优先编码器</h5><p><img src=\"/2020/09/07/数字电路/image-20201207202208723.png\" alt=\"image-20201207202208723\"></p>\n<p>S‘ 为选通输入端，只有S’ = 0 时，编码器才能正常工作，而在S’ = 1时，所有的输出端均被封锁在高电平</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207202442317.png\" alt=\"image-20201207202442317\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207202738889.png\" alt=\"image-20201207202738889\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207202617679.png\" alt=\"image-20201207202617679\"></p>\n<blockquote>\n<p>当芯片接口带圈时，输入信号表示为 X’</p>\n</blockquote>\n<h5 id=\"二—十进制优先编码器\"><a href=\"#二—十进制优先编码器\" class=\"headerlink\" title=\"二—十进制优先编码器\"></a>二—十进制优先编码器</h5><h4 id=\"译码器\"><a href=\"#译码器\" class=\"headerlink\" title=\"译码器\"></a>译码器</h4><h5 id=\"普通译码器\"><a href=\"#普通译码器\" class=\"headerlink\" title=\"普通译码器\"></a>普通译码器</h5><p><img src=\"/2020/09/07/数字电路/image-20201207204428555.png\" alt=\"image-20201207204428555\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207204622034.png\" alt=\"image-20201207204622034\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207204956445.png\" alt=\"image-20201207204956445\"></p>\n<h5 id=\"二—十进制译码器\"><a href=\"#二—十进制译码器\" class=\"headerlink\" title=\"二—十进制译码器\"></a>二—十进制译码器</h5><h5 id=\"显示译码器\"><a href=\"#显示译码器\" class=\"headerlink\" title=\"显示译码器\"></a>显示译码器</h5><h6 id=\"七段字符显示器\"><a href=\"#七段字符显示器\" class=\"headerlink\" title=\"七段字符显示器\"></a>七段字符显示器</h6><h6 id=\"BCD-七段显示译码器\"><a href=\"#BCD-七段显示译码器\" class=\"headerlink\" title=\"BCD - 七段显示译码器\"></a>BCD - 七段显示译码器</h6><h5 id=\"用译码器设计组合逻辑电路\"><a href=\"#用译码器设计组合逻辑电路\" class=\"headerlink\" title=\"用译码器设计组合逻辑电路\"></a>用译码器设计组合逻辑电路</h5><p><img src=\"/2020/09/07/数字电路/image-20201207205904689.png\" alt=\"image-20201207205904689\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207210045223.png\" alt=\"image-20201207210045223\"></p>\n<h4 id=\"数据选择器\"><a href=\"#数据选择器\" class=\"headerlink\" title=\"数据选择器\"></a>数据选择器</h4><h5 id=\"四选一数据选择器\"><a href=\"#四选一数据选择器\" class=\"headerlink\" title=\"四选一数据选择器\"></a>四选一数据选择器</h5><p><code>A0, A1</code> 决定选择的数据，S‘ 控制电路工作状态，S’ = 0 时数据选择器工作，反之不工作</p>\n<h5 id=\"八选一数据选择器\"><a href=\"#八选一数据选择器\" class=\"headerlink\" title=\"八选一数据选择器\"></a>八选一数据选择器</h5><p><img src=\"/2020/09/07/数字电路/image-20201207211753609.png\" alt=\"image-20201207211753609\"></p>\n<h5 id=\"用数据选择器设计组合逻辑电路\"><a href=\"#用数据选择器设计组合逻辑电路\" class=\"headerlink\" title=\"用数据选择器设计组合逻辑电路\"></a>用数据选择器设计组合逻辑电路</h5><p><img src=\"/2020/09/07/数字电路/image-20201207225752379.png\" alt=\"image-20201207225752379\"></p>\n<h4 id=\"加法器\"><a href=\"#加法器\" class=\"headerlink\" title=\"加法器\"></a>加法器</h4><h5 id=\"一位加法器\"><a href=\"#一位加法器\" class=\"headerlink\" title=\"一位加法器\"></a>一位加法器</h5><p>半加器（不考虑进位）</p>\n<p>全加器（考虑进位）</p>\n<h5 id=\"多位加法器\"><a href=\"#多位加法器\" class=\"headerlink\" title=\"多位加法器\"></a>多位加法器</h5><p>串行进位加法器</p>\n<p>超前进位加法器</p>\n<h4 id=\"利用加法器设计电路\"><a href=\"#利用加法器设计电路\" class=\"headerlink\" title=\"利用加法器设计电路\"></a>利用加法器设计电路</h4><p><img src=\"/2020/09/07/数字电路/image-20201207230758027.png\" alt=\"image-20201207230758027\"></p>\n<h4 id=\"数值比较器\"><a href=\"#数值比较器\" class=\"headerlink\" title=\"数值比较器\"></a>数值比较器</h4><h5 id=\"1位数值比较器\"><a href=\"#1位数值比较器\" class=\"headerlink\" title=\"1位数值比较器\"></a>1位数值比较器</h5><p><img src=\"/2020/09/07/数字电路/image-20201207231257765.png\" alt=\"image-20201207231257765\"></p>\n<h5 id=\"多位数值比较器\"><a href=\"#多位数值比较器\" class=\"headerlink\" title=\"多位数值比较器\"></a>多位数值比较器</h5><p><img src=\"/2020/09/07/数字电路/image-20201207231703395.png\" alt=\"image-20201207231703395\"></p>\n<p>I 是来自低位的比较信息</p>\n<h2 id=\"第五章-触发器\"><a href=\"#第五章-触发器\" class=\"headerlink\" title=\"第五章 触发器\"></a>第五章 触发器</h2><p>能够储存 1 位二值信号的基本单元电路统称为触发器</p>\n<h3 id=\"SR锁存器\"><a href=\"#SR锁存器\" class=\"headerlink\" title=\"SR锁存器\"></a>SR锁存器</h3><p><img src=\"/2020/09/07/数字电路/image-20201207234319334.png\" alt=\"image-20201207234319334\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201207234431264.png\" alt=\"image-20201207234431264\"></p>\n<h3 id=\"电平触发的触发器\"><a href=\"#电平触发的触发器\" class=\"headerlink\" title=\"电平触发的触发器\"></a>电平触发的触发器</h3><p>触发信号输入端               触发信号 <code>CLK</code></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208093951521.png\" alt=\"image-20201208093951521\"></p>\n<p>当 <code>CLK=0</code>时，S, R的信号无法影响到输出，当 <code>CLK=1</code>时，S, R的信号才能起作用</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208094730885.png\" alt=\"image-20201208094730885\"></p>\n<h3 id=\"电平触发的D触发器\"><a href=\"#电平触发的D触发器\" class=\"headerlink\" title=\"电平触发的D触发器\"></a>电平触发的D触发器</h3><p><img src=\"/2020/09/07/数字电路/image-20201208095118685.png\" alt=\"image-20201208095118685\"></p>\n<p>当<code>CLK=1</code>时，Q的值和D相同，当<code>CLK=0</code>时，Q的值保持不变</p>\n<h3 id=\"脉冲触发的触发器（主从SR触发器）\"><a href=\"#脉冲触发的触发器（主从SR触发器）\" class=\"headerlink\" title=\"脉冲触发的触发器（主从SR触发器）\"></a>脉冲触发的触发器（主从SR触发器）</h3><p><img src=\"/2020/09/07/数字电路/image-20201208100213115.png\" alt=\"image-20201208100213115\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208100252440.png\" alt=\"image-20201208100252440\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208100311393.png\" alt=\"image-20201208100311393\"></p>\n<h3 id=\"主从-JK-触发器\"><a href=\"#主从-JK-触发器\" class=\"headerlink\" title=\"主从 JK 触发器\"></a>主从 JK 触发器</h3><p><img src=\"/2020/09/07/数字电路/image-20201208100710777.png\" alt=\"image-20201208100710777\"></p>\n<p>当下降沿到达时，</p>\n<p>若 J=1, K=0，则Q置1，若 J=0, K=1，则Q置0，若 J=0, K=0，则Q不变，若 J=1, K=1，则Q状态翻转（0变1，1变0）</p>\n<p>主从触发器的状态由全部在CLK=1时的动作决定</p>\n<h3 id=\"边沿触发的触发器\"><a href=\"#边沿触发的触发器\" class=\"headerlink\" title=\"边沿触发的触发器\"></a>边沿触发的触发器</h3><p><img src=\"/2020/09/07/数字电路/image-20201208102916928.png\" alt=\"image-20201208102916928\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208103050351.png\" alt=\"image-20201208103050351\"></p>\n<h3 id=\"T触发器\"><a href=\"#T触发器\" class=\"headerlink\" title=\"T触发器\"></a>T触发器</h3><p><img src=\"/2020/09/07/数字电路/image-20201208103416148.png\" alt=\"image-20201208103416148\"></p>\n<h3 id=\"触发器分类\"><a href=\"#触发器分类\" class=\"headerlink\" title=\"触发器分类\"></a>触发器分类</h3><p><img src=\"/2020/09/07/数字电路/image-20201208103304650.png\" alt=\"image-20201208103304650\"></p>\n<h2 id=\"第六章-时序逻辑电路\"><a href=\"#第六章-时序逻辑电路\" class=\"headerlink\" title=\"第六章 时序逻辑电路\"></a>第六章 时序逻辑电路</h2><h3 id=\"特性方程\"><a href=\"#特性方程\" class=\"headerlink\" title=\"特性方程\"></a>特性方程</h3><p> <img src=\"/2020/09/07/数字电路/image-20201208120335673.png\" alt=\"image-20201208120335673\"></p>\n<p>D 触发器的特性方程 Q* = D</p>\n<p>T 触发器的特性方程 Q* = TQ’ + T’Q</p>\n<h3 id=\"分析同步时序逻辑电路\"><a href=\"#分析同步时序逻辑电路\" class=\"headerlink\" title=\"分析同步时序逻辑电路\"></a>分析同步时序逻辑电路</h3><p><img src=\"/2020/09/07/数字电路/image-20201208120149198.png\" alt=\"image-20201208120149198\"></p>\n<h3 id=\"异步时序逻辑电路\"><a href=\"#异步时序逻辑电路\" class=\"headerlink\" title=\"异步时序逻辑电路\"></a>异步时序逻辑电路</h3><h3 id=\"常用时序逻辑电路\"><a href=\"#常用时序逻辑电路\" class=\"headerlink\" title=\"常用时序逻辑电路\"></a>常用时序逻辑电路</h3><h4 id=\"寄存器\"><a href=\"#寄存器\" class=\"headerlink\" title=\"寄存器\"></a>寄存器</h4><h4 id=\"移位寄存器\"><a href=\"#移位寄存器\" class=\"headerlink\" title=\"移位寄存器\"></a>移位寄存器</h4><p><img src=\"/2020/09/07/数字电路/image-20201208133000921.png\" alt=\"image-20201208133000921\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208133500161.png\" alt=\"image-20201208133500161\"></p>\n<h4 id=\"计数器\"><a href=\"#计数器\" class=\"headerlink\" title=\"计数器\"></a>计数器</h4><h5 id=\"同步计数器\"><a href=\"#同步计数器\" class=\"headerlink\" title=\"同步计数器\"></a>同步计数器</h5><p><img src=\"/2020/09/07/数字电路/image-20201208162623051.png\" alt=\"image-20201208162623051\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208162700995.png\" alt=\"image-20201208162700995\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208163034352.png\" alt=\"image-20201208163034352\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208163053439.png\" alt=\"image-20201208163053439\"></p>\n<h5 id=\"同步置零和异步置零\"><a href=\"#同步置零和异步置零\" class=\"headerlink\" title=\"同步置零和异步置零\"></a>同步置零和异步置零</h5><p><img src=\"/2020/09/07/数字电路/image-20201208163510773.png\" alt=\"image-20201208163510773\"></p>\n<h5 id=\"异步计数器\"><a href=\"#异步计数器\" class=\"headerlink\" title=\"异步计数器\"></a>异步计数器</h5><h5 id=\"任意进制计数器的构成方法\"><a href=\"#任意进制计数器的构成方法\" class=\"headerlink\" title=\"任意进制计数器的构成方法\"></a>任意进制计数器的构成方法</h5><p>假设已有的是N进制计数器，而需要得到的是M进制计数器，此时分为两种情况：</p>\n<ol>\n<li>M&lt;N</li>\n</ol>\n<p>置零法（复位法），置数法（置位法）</p>\n<p>同步置零法：从S0状态出发到达S(M-1)状态时译出同步置零信号，在下一次CLK到达后变为S0状态</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208192312875.png\" alt=\"image-20201208192312875\"></p>\n<p>异步置零法：从S0状态出发到达S(M)状态时译出异步置零信号，变为S0状态</p>\n<p>同步置数法：到达 Si 状态时令 LD’=0 ，在下一个 CLK 到来时，将要置入的数据置入计数器中，状态变为 Sj</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208192326383.png\" alt=\"image-20201208192326383\"></p>\n<p>异步置数法：到达 S(i+1) 状态时令 LD’=0 ，状态直接变为 Sj</p>\n<ol>\n<li>M&gt;N</li>\n</ol>\n<p><img src=\"/2020/09/07/数字电路/image-20201208211819333.png\" alt=\"image-20201208211819333\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208211825145.png\" alt=\"image-20201208211825145\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208212439760.png\" alt=\"image-20201208212439760\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208212442919.png\" alt=\"image-20201208212442919\"></p>\n<h5 id=\"移位寄存器型计数器\"><a href=\"#移位寄存器型计数器\" class=\"headerlink\" title=\"移位寄存器型计数器\"></a>移位寄存器型计数器</h5><p>环形计数器</p>\n<p>扭环形计数器</p>\n<h3 id=\"同步时序逻辑电路的设计方法\"><a href=\"#同步时序逻辑电路的设计方法\" class=\"headerlink\" title=\"同步时序逻辑电路的设计方法\"></a>同步时序逻辑电路的设计方法</h3><p><img src=\"/2020/09/07/数字电路/image-20201208214549378.png\" alt=\"image-20201208214549378\"></p>\n<ol>\n<li>逻辑抽象，得出电路的状态转换图或状态转换表</li>\n<li>状态化简</li>\n</ol>\n<p><img src=\"/2020/09/07/数字电路/image-20201208214717350.png\" alt=\"image-20201208214717350\"></p>\n<ol>\n<li>状态分配</li>\n</ol>\n<p><img src=\"/2020/09/07/数字电路/image-20201208214956731.png\" alt=\"image-20201208214956731\"></p>\n<ol>\n<li>选定触发器的类型，求出电路的状态方程、驱动方程和输出方程</li>\n</ol>\n<p><img src=\"/2020/09/07/数字电路/image-20201208215446146.png\" alt=\"image-20201208215446146\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208215327269.png\" alt=\"image-20201208215327269\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208215405366.png\" alt=\"image-20201208215405366\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201208215602590.png\" alt=\"image-20201208215602590\"></p>\n<ol>\n<li>根据得到的方程式画出逻辑图</li>\n</ol>\n<p><img src=\"/2020/09/07/数字电路/image-20201208215639819.png\" alt=\"image-20201208215639819\"></p>\n<ol>\n<li>检查设计的电路能否自启动</li>\n</ol>\n<p><img src=\"/2020/09/07/数字电路/image-20201208215654220.png\" alt=\"image-20201208215654220\"></p>\n<h3 id=\"异步时序逻辑电路的设计方法\"><a href=\"#异步时序逻辑电路的设计方法\" class=\"headerlink\" title=\"异步时序逻辑电路的设计方法\"></a>异步时序逻辑电路的设计方法</h3><p><img src=\"/2020/09/07/数字电路/image-20201208215859239.png\" alt=\"image-20201208215859239\"></p>\n<h2 id=\"第七章-半导体存储器\"><a href=\"#第七章-半导体存储器\" class=\"headerlink\" title=\"第七章 半导体存储器\"></a>第七章 半导体存储器</h2><h3 id=\"分类\"><a href=\"#分类\" class=\"headerlink\" title=\"分类\"></a>分类</h3><h4 id=\"只读存储器\"><a href=\"#只读存储器\" class=\"headerlink\" title=\"只读存储器\"></a>只读存储器</h4><p>掩模 ROM</p>\n<p>可编程 PROM</p>\n<p>可擦除的可编程 EPROM</p>\n<h4 id=\"随机读写存储器\"><a href=\"#随机读写存储器\" class=\"headerlink\" title=\"随机读写存储器\"></a>随机读写存储器</h4><p>动态 DRAM</p>\n<p>静态 SRAM</p>\n<p><img src=\"/2020/09/07/数字电路/image-20201209091933646.png\" alt=\"image-20201209091933646\"></p>\n<p><img src=\"/2020/09/07/数字电路/image-20201209092949508.png\" alt=\"image-20201209092949508\"></p>"},{"title":"智能计算机实验","date":"2020-12-21T08:01:31.000Z","mathjax":true,"_content":"\n# 智能计算机实验\n\n## 我对于此课程实验的看法\n\n关于此实验的指导比较少，主要来源就是寒武纪论坛和一些大体的指导，没有详细的介绍，而这门实验的测试是在服务器上进行的，坑比较多，因此可能会耗费比较多的时间（除非你直接补充那七个文件而且不用在服务器上测试，平台提交直接AC）\n\n这篇文章的主要目的是提供一个比较详细的实验完成方法，并且减少大家在完成实验过程中踩的坑，但是不会提供具体的代码\n\n**注意**：如果你想快速顺利的完成此实验，可以观看这篇文章\n\n​         如果你想锻炼自己根据报错找 bug 的能力或者根据报错自学 tensorflow 的能力，可以先选择自己完成实验，如果实在是感到      困难，可以再来观看这篇文章\n\n<!--more-->\n## 实验一\n\n(听说不用快速幂和多核拆分就能过，哭了)\n\n1. 进入 /opt   将压缩包解压\n2. 进入 /opt/AICSE-demo-student/env  执行 source env.sh\n3. cd tensorflow-v1.10   执行 source env.sh   然后激活虚拟环境\n\n![image-20201221161604172](智能计算机/image-20201221161604172.png)\n\n3. 以上两步非常重要，在每一次进入服务器之后都要执行，否则会在执行脚本或编译的时候出现奇怪的错误\n4. 进入 /opt/AICSE-demo-student/demo/style_transfer_bcl/src/bangc/PluginPowerDifferenceOp ，开始进行代码的补充，我建议的顺序如下：\n   - plugin_power_difference_kernel.mlu \n   - plugin_power_difference_kernel.h\n   - powerDiff.cpp\n   - plugin_power_difference_op.cc\n   - cnplugin.h\n\n5. 在 .mlu 中进行 PowerDifference 算子的实现，这个部分比较简单，需要注意的地方为 GDRAM 和 NRAM 之间的转换，我的理解就是参数中的变量都是 GDRAM，你在函数中创建的 `__nram__ half` 变量都是 NRAM，而你的实现大概能分为三个阶段：\n\n   - 初级阶段，实现了基本的算子功能，能得到60分\n   - 中级阶段，用快速幂进行实现，能够小幅降低在 CNRT 上的延时，能得到70分（不过不用快速幂可能也行\n   - 高级阶段，实现多核拆分计算，能够同时在多个核上进行运算，能得到100分（bushi\n\n   此部分需要用到一些 bangc 的内置函数，使用其中的三个函数就能实现此算子：\n\n   - __memcpy (目标地址，源地址，长度，RAM类型转换)     功能为将源地址之后一定长度的数据拷贝到目标地址\n\n     一个栗子：`__memcpy(input1_nram+i*Seg, input1+i*Seg, Seg*sizeof(half), GDRAM2NRAM);`\n\n   - __bang_sub (目标地址，被减数，减数，长度)     功能为进行一定长度的向量减法，结果储存在目标地址\n\n     一个栗子：`__bang_sub(input1_nram+i*Seg, input1_nram+i*Seg, input2_nram+i*Seg, Seg);`\n\n   - __bang_mul     与上面类似，只不过进行的是乘法\n\n   关于函数的具体使用以及更多的函数介绍，可以参考 bangc 的开发指导书\n\n   噢，忘说了，函数的参数大致是这样：`__mlu_entry__ void PowerDifferenceKernel(half* input1, half* input2, int pow, half* output, int len)`\n\n6. 补全 plugin_power_difference_kernel.h，非常简单，只要和 .mlu 中的函数参数一致即可\n7. 补全 powerDiff.cpp，这部分若要自己写可能比较困难，我的建议是参照本来就有的其他算子的实现来完成，需要注意的是将其中的 *Kernel 改成自己的 PowerDifferenceKernel，当然还可能有其他的都需要改成 PowerDifference 对应的格式，在参照其他算子完成补全后，需要注意的是，如果你想使用多核拆分的话，还要修改两个地方：\n   - 将 dim.x = 1 改为 dim.x = 8\n   - 将 cnrtFunctionType_t c 改为 CNRT_FUNC_TYPE_UNION2\n\n8. 补全 plugin_power_difference_op.cc，这个比较难搞，即使参照其他算子，也比较烦人，我对于此部分的建议是选择的参照算子的实现可以选择简单的，并且不要思考的太过于复杂（\n9. 补全 cnplugin.h，参照上面的实现，定义 PowerDifference 对应的结构，结构指针以及 plugin_power_difference_op.cc 中函数的声明\n\n10. 在补全了以上文件之后，就可以进行算子的测试啦，在 xxx/src/bangc/PluginPowerDifferenceOp 中执行以下两句：\n    - bash make.sh\n    - ./power_diff_test\n\n    就可以看到测试结果，正确的测试结果大致如下：\n\n    ![image-20201221170316556](智能计算机/image-20201221170316556.png)\n\n11. 如果你的运行结果和上图差不多，说明你前面的实现已经差不多完成啦，接下来就要进行 cnplugin 的集成，步骤如下：\n\n    - 将 cnplugin.h 复制到下面两个目录中：\n\n      /opt/AICSE-demo-student/env/neuware/include/\n\n      /opt/AICSE-demo-student/env/Cambricon-CNPlugin-MLU270/common/include/\n\n    -  在 /opt/AICSE-demo-student/env/Cambricon-CNPlugin-MLU270 处执行 bash build_cnplugin.sh --mlu200，如果编译的最后显示 build success，说明你编译成功，会在 ./build 文件夹中生成新的 libcnplugin.so\n\n    - 将新生成的 libcnplugin.so 复制到 /opt/AICSE-demo-student/env/neuware/lib64/ 文件夹下\n\n12. 很快啊，cnplugin 的集成就完成了，接下来要进行的就是 TensorFlow 算子集成，此部分首先需要按照 /opt/AICSE-demo-student/demo/style_transfer_bcl/src/tf-implementation/tf-add-power-diff/readme.txt  即下图：\n\n    ![image-20201221171419046](智能计算机/image-20201221171419046.png)\n\n    将此文件夹下的其他文件复制到 readme.txt 里对应的文件夹中，在进行这一步时请务必仔细，否则在稍后编译时可能会产生各种各样奇怪的 bug，在复制完成后，如果你直接在 /opt/AICSE-demo-student/env/tensorflow-v1.10 中执行 bash build_tensorflow-v1.10_mlu.sh，有 99.9% 的可能会出现以下的错误：\n\n    ![image-20201221171900968](智能计算机/image-20201221171900968.png)\n\n    根据错误信息可以看出来，实验提供的 mlu_lib_ops.cc 和你补充的 plugin_power_difference_op.cc  中 ，cnmlCreatePluginPowerDifferenceOp 以及 cnmlComputePluginPowerDifferenceOpForward 的参数不同，你需要选择修改其中之一来保证两个文件中的参数一致，我的建议是修改实验提供的 mlu_lib_ops.cc，因为修改起来比较简单，并且在其中你可以使用 nullptr 来填充参数，，下面是我的实现以供参考：\n    \n    mlu_lib_ops.cc 中对于 plugin_power_difference_op的调用：\n    ![image-20201222121105346](智能计算机/image-20201222121105346.png)\n    plugin_power_difference_op.cc 中 plugin_power_difference_op 的参数：\n    ![image-20201222121110969](智能计算机/image-20201222121110969.png)\n    mlu_lib_ops.cc 中对于 cnmlComputePluginPowerDifferenceOpForward的调用：\n    ![image-20201222121125219](智能计算机/image-20201222121125219.png)\n    plugin_power_difference_op.cc 中 cnmlComputePluginPowerDifferenceOpForward 的参数：\n    ![image-20201222121129289](智能计算机/image-20201222121129289.png)\n\n    若在完成这一步之后，你的编译出现socket错误，就要将 .sh 文件中的 job_num 改为 16 ，你应该就可以成功的进行 tensorflow的编译啦（可能需要较长的时间\n\n13. 最后就是补全 .../src/online_mlu/power_difference_test_bcl.py 和 .../src/online_cpu/power_difference_test_cpu.py 文件 ， 执行 python power_difference_test_xxx.py 进行测试，这两个文件的补全比较简单，并且是基本一样的，只是在 test_bcl 中有一个特殊的地方要修改，因此我的建议是先进行 cpu 的测试，成功的测试结果如下图：\n\n    ![image-20201221173107160](智能计算机/image-20201221173107160.png)\n\n    而当你将补全的地方复制到 test_mlu.py 中，进行测试，你会得到以下结果：\n\n    ![image-20201221173352870](智能计算机/image-20201221173352870.png)\n\n    我在开始的时候将代码中的   os.environ['MLU_VISIBLE_DEVICES'] = \"0\"   改为 os.environ['MLU_VISIBLE_DEVICES'] = \"1\" ，然后再次测试：\n\n    ![image-20201221173555856](智能计算机/image-20201221173555856.png)\n\n    虽然错误率看上去比较高，但是交上去的话可以过。不过这种改的方法应该是不正确的, 而且在实验二中这个问题会同样出现但是无法解决， 出现这种情况的原因应该是在多核拆分的循环的最后一次中数据的长度不足 Seg，因此我们需要将最后的一次单独提取出来做计算，之后的结果是这样的：\n\n    ![image-20200118](智能计算机/image-20200118.png)\n\n    可以看到错误率比之前低了很多\n\n14. 最后，如果你使用了快速幂，多核拆分，但是在 MLU 上仍然有着 100+ ms 的延迟，那么你需要在 test_bcl.py 中进行如下修改：\n\n    ![image-20201221173834863](智能计算机/image-20201221173834863.png)\n\n    因为 MLU 的启动时间比较慢，所以可以多次运行来获得更低的延迟，如果这样你还不能拿到满分，请多提交几次\n\n15. 补充：如果你提交到平台上的结果为 JSON 格式错误，说明你代码写错了，请确保你在如上测试中都成功的运行出了正确的结果，如果你在实验的完成过程中出现了其他错误，请看一下自己是不是漏了某个步骤，或者某个步骤做的不够仔细，如果还是不行的话，请前往和助教对线或者在群里请求帮助，此外，请务必不要重启你的服务器，~~否则就会像我一样丢掉所有数据然后重新配一遍~~\n\n## 实验一选作（四选一）-- softmax 算子实现\n\n### softmax 算子介绍\n\n![image-20201222014249959](智能计算机/image-20201222014249959.png)\n\n### 算子实现\n\n因为输入数据的规模为 20 × 256，共 20 行，256 列，我们首先要找出每一列的最大值，方法为每次接受一行的数据，对于每一列来说，如果新输入的数据大于最大值，就更新，否则不变，然后将每一列的所有数减去这个最大值，求出 e 关于这个数的指数，再全部加起来，然后取一个倒数，然后对于每一列的每一个数，乘以之前计算出来的倒数，这样计算出来的结果即为正确结果\n\n### 具体代码\n\n```cpp\n#include \"mlu.h\"\n#define input_size 20     # 列数\n#define input_num  256    # 行数\n\n\n#define LEN  256*20\n__mlu_entry__ void SoftmaxKernel(half* input, half* output)\n{  \n   __nram__ half input_nram[input_num];\n   __nram__ half output_nram[LEN];\n   __nram__ half temp1_nram[input_num];\n   __nram__ half temp2_nram[input_num];\n   __nram__ half comL_nram[input_num];\n   __nram__ half sum_nram[input_num];\n   __nram__ half sum_recip_nram[input_num];\n   __nram__ half mulL_nram[input_num];\n   __nram__ half mulR_nram[input_num];\n   __nramset_half(comL_nram, input_num, -3000.0);\n   __nramset_half(sum_nram, input_num,0.0);\n   \n   for(int32_t i=0; i<input_size;i++)\n    {\n       __memcpy(input_nram, input+i*input_num, input_num*sizeof(half),GDRAM2NRAM);  # 分别获取每行的输入数据\n       __bang_gt(temp1_nram,comL_nram,input_nram,input_num);   # 若输入值小于最大值，则对应位置为1\n       __bang_not(temp2_nram,temp1_nram,input_num);            # 若输入值大于最大值，则对应位置为1\n       __bang_mul(mulL_nram,temp1_nram,comL_nram,input_num);   # 最大值不变的位置，置最大值\n       __bang_mul(mulR_nram,temp2_nram,input_nram,input_num);  # 最大值改变的位置，置输入值\n       __bang_add(comL_nram,mulL_nram,mulR_nram,input_num);    # 相加得到每列新的最大值\n    }\n\n   for(int32_t i=0; i<input_size;i++)\n     {\n       __memcpy(input_nram, input+i*input_num, input_num*sizeof(half),GDRAM2NRAM);  # 分别获取每行的输入数据\n       __bang_sub(temp1_nram,input_nram,comL_nram,input_num);  # 每一列减去该列最大值\n       __bang_active_exp(temp2_nram,temp1_nram,input_num);     # 求 e 关于 j-max 的指数\n       __bang_add(sum_nram,sum_nram,temp2_nram,input_num);     # 将所有的指数相加得到分母\n     }\n    __bang_active_recip(sum_recip_nram,sum_nram,input_num);    # 求出分母的倒数\n\n   for(int32_t i=0; i<input_size;i++)\n       {\n         __memcpy(input_nram, input+i*input_num, input_num*sizeof(half),GDRAM2NRAM);  # 分别获取每行的输入数据\n        __bang_sub(temp1_nram,input_nram,comL_nram,input_num);         # 每一列减去该列最大值\n        __bang_active_exp(temp2_nram,temp1_nram,input_num);            # 求 e 关于 i-max 的指数，即分子\n        __bang_mul(temp2_nram,temp2_nram,sum_recip_nram,input_num);    # 将分子和分母的倒数相乘，得到结果\n        __memcpy(output+i*input_num,temp2_nram,input_num*sizeof(half),NRAM2GDRAM);  # 将结果返回到输出中\n      }\n }\n```\n\n### 实验总结\n\n该实验对于 softmax 算子进行实现，难点在于如何灵活的运用 bangc 提供的各种函数对于数据进行操作和计算，只要按照 softmax 的定义对式子一步一步的计算，并合理的运用 bangc 提供的函数，就可以比较简单的实现 softmax 算子，在这个过程中，bangc 的教学文档起到了很大的作用，文档对于各种各样的函数做出了详细的解释与注意事项，可以对算子实现起到很大的帮助\n\n## 实验二\n\n### 模型量化\n\n该部分代码和量化手段已经提前给出，直接按照[教程](http://forum.cambricon.com/uploadfile/user/file/20200714/1594717975554836.pdf)即可完成。\n\n### 在线推理\n\n在线推理部分主要分为两块，分别需要补全\n\n/opt/AICSE-demo-student/demo/style_transfer_bcl/src/online_mlu/transform_mlu.py 和\n\n/opt/AICSE-demo-student/demo/style_transfer_bcl/src/online_cpu/transform_cpu.py\n\n#### online_cpu\n\n在cpu部分里，使用到的模型是非量化后的模型文件。\n\n该部分需要补全两个函数run_ori_power_diff_pb和run_numpy_pb\n\n- **run_ori_power_diff_pb** ：直接按照同文件下的run_ori_pb逻辑进行书写，但是要注意该函数使用的计算图与run_ori_pb不同点在于将原生的差平方计算算子改成了实验一中集成的power_difference算子，所以只需要我们进行feed数据（**不需要**重新实现power_difference的计算），将pow值传递至计算图计算。而其在**计算图中的各节点信息可使用[神经网络模型可视化网站](https://lutzroeder.github.io/netron/)进行查找**。\n\n  ![image-20201222004846500](智能计算机/image-20201222004846500.png)\n\n  从图中可以看出除了 X 还额外需要 feed 一个数据，即 PowerDifference_z，给它赋值为2即可，相当于将pow = 2 传递给了计算图\n\n  ![image-20201222004912384](智能计算机/image-20201222004912384.png)\n\n- **run_numpy_pb**：与上一个类似，只不过这里需要我们手动将原生的差平方计算算子的输入数据提出并使用实验一中的power_diff_numpy.py的内置函数进行计算后，再传回计算图进行计算。**需要注意**该函数的输入参数跟上一个run_ori_power_diff_pb的计算图一样的参数，因为这里要手动算，所以在可视化的计算图上可以发现这里断开了。\n\n  ![image-20201222004933612](智能计算机/image-20201222004933612.png)\n\n  上面这张图是使用原生的差平方计算算子的模型，可以看到SquaredDifference算子的输入分别为Conv2D_13和 moments_15/StopGradient\n\n  ![image-20201222004952263](智能计算机/image-20201222004952263.png)\n\n  可以看到这个模型的 Conv2D_13和 moments_15/StopGradient 并没有参与到算子的计算中，所以我们要把这两个节点的数据提取出来，再加上一个 pow 值为 2，作为 power_diff_numpy 的三个参数计算出 PowerDifference 算子的输出结果，此处需要注意的是从计算图中提取出来的 Tensor 不能直接进行 reshape，否则会报错，所以我们要通过 eval() 将其转换为数组，并且要向 eval() feed 一个数据 X\n\n  ![image-20201222005007770](智能计算机/image-20201222005007770.png)\n\n- 全部代码\n\n  ```python\n  import os\n  import tensorflow as tf\n  from tensorflow.python.platform import gfile\n  import argparse\n  import numpy as np\n  import cv2 as cv\n  import time\n  from power_diff_numpy import *\n  \n  os.putenv('MLU_VISIBLE_DEVICES','')\n  def parse_arg():\n      parser = argparse.ArgumentParser()\n      parser.add_argument('image')\n      parser.add_argument('ori_pb')\n      parser.add_argument('ori_power_diff_pb')\n      parser.add_argument('numpy_pb')\n      args = parser.parse_args()\n      return args\n  \n  def run_ori_pb():\n      args = parse_arg()\n      config = tf.ConfigProto(allow_soft_placement=True,\n                  inter_op_parallelism_threads=1,\n                              intra_op_parallelism_threads=1)\n      model_name = os.path.basename(args.ori_pb).split(\".\")[0]\n      image_name = os.path.basename(args.image).split(\".\")[0]\n  \n      g = tf.Graph()\n      with g.as_default():\n          with tf.gfile.FastGFile(args.ori_pb,'rb') as f:\n              graph_def = tf.GraphDef()\n              graph_def.ParseFromString(f.read())\n              tf.import_graph_def(graph_def, name='')\n          img = cv.imread(args.image)\n          X = cv.resize(img, (256, 256))\n          with tf.Session(config=config) as sess:\n              sess.graph.as_default()\n              sess.run(tf.global_variables_initializer())\n  \n              input_tensor = sess.graph.get_tensor_by_name('X_content:0')\n              output_tensor = sess.graph.get_tensor_by_name('add_37:0')\n  \n              start_time = time.time()\n              ret =sess.run(output_tensor, feed_dict={input_tensor:[X]})\n              end_time = time.time()\n              print(\"C++ inference(CPU) origin pb time is: \",end_time-start_time)\n              img1 = tf.reshape(ret,[256,256,3])\n              img_numpy = img1.eval(session=sess)\n              cv.imwrite(image_name + '_' + model_name + '_cpu.jpg',img_numpy)\n  \n  \n  def run_ori_power_diff_pb():\n      args = parse_arg()\n      config = tf.ConfigProto(allow_soft_placement=True,\n                  inter_op_parallelism_threads=1,\n                              intra_op_parallelism_threads=1)\n      model_name = os.path.basename(args.ori_power_diff_pb).split(\".\")[0]\n      image_name = os.path.basename(args.image).split(\".\")[0]\n  \n      g = tf.Graph()\n      with g.as_default():\n          with tf.gfile.FastGFile(args.ori_power_diff_pb,'rb') as f:\n              graph_def = tf.GraphDef()\n              graph_def.ParseFromString(f.read())\n              tf.import_graph_def(graph_def, name='')\n          img = cv.imread(args.image)\n          X = cv.resize(img, (256, 256))\n          with tf.Session(config=config) as sess:\n              sess.graph.as_default()\n              sess.run(tf.global_variables_initializer())\n  \n              input_tensor1 = sess.graph.get_tensor_by_name('X_content:0')\n              input_tensor2 = sess.graph.get_tensor_by_name('moments_15/PowerDifference_z:0')\n              output_tensor = sess.graph.get_tensor_by_name('add_37:0')\n  \n              start_time = time.time()\n              ret =sess.run(output_tensor, feed_dict={input_tensor1:[X], input_tensor2:2})\n              end_time = time.time()\n              print(\"C++ inference(CPU) time is: \",end_time-start_time)\n              img1 = tf.reshape(ret,[256,256,3])\n              img_numpy = img1.eval(session=sess)\n              cv.imwrite(image_name + '_' + model_name + '_cpu.jpg',img_numpy)\n  \n  def run_numpy_pb():\n      args = parse_arg()\n      config = tf.ConfigProto(allow_soft_placement=True,\n                  inter_op_parallelism_threads=1,\n                              intra_op_parallelism_threads=1)\n      model_name = os.path.basename(args.numpy_pb).split(\".\")[0]\n      image_name = os.path.basename(args.image).split(\".\")[0]\n  \n      g = tf.Graph()\n      with g.as_default():\n          with tf.gfile.FastGFile(args.numpy_pb,'rb') as f:\n              graph_def = tf.GraphDef()\n              graph_def.ParseFromString(f.read())\n              tf.import_graph_def(graph_def, name='')\n          img = cv.imread(args.image)\n          X = cv.resize(img, (256, 256))\n          with tf.Session(config=config) as sess:\n              sess.graph.as_default()\n              sess.run(tf.global_variables_initializer())\n  \n              input_tensor1 = sess.graph.get_tensor_by_name('X_content:0')\n              input_tensor2 = sess.graph.get_tensor_by_name('moments_15/PowerDifference:0')\n              output_tensor = sess.graph.get_tensor_by_name('add_37:0')\n  \n              start_time = time.time()\n              input_2 = power_diff_numpy(sess.graph.get_tensor_by_name('Conv2D_13:0').eval(feed_dict={input_tensor1:[X]}),sess.graph.get_tensor_by_name('moments_15/StopGradient:0').eval(feed_dict={input_tensor1:[X]}),2)\n              ret =sess.run(output_tensor, feed_dict={input_tensor1:[X], input_tensor2:input_2})\n              end_time = time.time()\n              print(\"Numpy inference(CPU) time is: \",end_time-start_time)\n              img1 = tf.reshape(ret,[256,256,3])\n              img_numpy = img1.eval(session=sess)\n              cv.imwrite(image_name + '_' + model_name + '_cpu.jpg',img_numpy)\n  \n  \n  if __name__ == '__main__':\n      run_ori_pb()\n      run_ori_power_diff_pb()\n      run_numpy_pb()\n  \n  ```\n\n#### online_mlu\n\n在mlu部分，使用到的模型是量化后的模型文件。\n\n仅仅需要在每个函数前加上\n\n`config.mlu_options.save_offline_model = True`\n\n这句话用于保存量化后可用于mlu的离线模型，其余部分均与cpu相同\n\n### 离线推理\n\n~~令人惊讶的是，当我写完了在线推理之后，提交了一手发现居然拿了满分，于是我还没有写离线推理~~\n\n代码：\n\n```cpp\n#include \"inference.h\"\n#include \"cnrt.h\"\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include \"stdlib.h\"\n#include <sys/time.h>\n#include <time.h>\n\nnamespace StyleTransfer{\n\ntypedef unsigned short half;\n\nvoid cnrtConvertFloatToHalfArray(uint16_t* x, const float* y, int len) {\n  for (int i = 0; i < len; i++){\n    cnrtConvertFloatToHalf(x+i,y[i]);\n  }\n}\n\nvoid cnrtConvertHalfToFloatArray(float* x, const uint16_t* y, int len) {\n  for (int i = 0; i < len; i++){\n    cnrtConvertHalfToFloat(x+i,y[i]);\n  }\n}\n\nvoid cnrtConvertFloatToHalfArray(uint16_t* x, float* y, int len) {\n  for (int i = 0; i < len; i++){\n    cnrtConvertFloatToHalf(x+i,y[i]);\n  }\n}\n\nvoid cnrtConvertHalfToFloatArray(float* x, uint16_t* y, int len) {\n  for (int i = 0; i < len; i++){\n    cnrtConvertHalfToFloat(x+i,y[i]);\n  }\n}\n\n\nInference :: Inference(std::string offline_model){\n    offline_model_ = offline_model;\n}\n\nvoid Inference :: run(DataTransfer* DataT){\n    cnrtInit(0);\n    cnrtModel_t model;\n    cnrtLoadModel(&model, offline_model_.c_str());\n\n    cnrtDev_t dev;\n    cnrtGetDeviceHandle(&dev, 0);\n    cnrtSetCurrentDevice(dev);\n    \n    float* input_data = reinterpret_cast<float*>(malloc(256*256*3*sizeof(float)));\n    float* output_data = reinterpret_cast<float*>(malloc(256*256*3*sizeof(float)));\n    int t = 256*256;\n    for(int i=0;i<t;i++)\n        for(int j=0;j<3;j++)\n            input_data[i*3+j] = DataT->input_data[t*j+i]; \n    int number = 0;\n    cnrtGetFunctionNumber(model, &number);\n\n    cnrtFunction_t function;\n    cnrtCreateFunction(&function);\n    cnrtExtractFunction(&function, model, \"subnet0\");\n    \n\n    int inputNum, outputNum;\n    int64_t *inputSizeS, *outputSizeS;\n    cnrtGetInputDataSize(&inputSizeS, &inputNum, function);\n    cnrtGetOutputDataSize(&outputSizeS, &outputNum, function);\n\n    DataT->output_data = reinterpret_cast<float*>(malloc(256 * 256 * 3 * sizeof(float)));\n    half* input_half = (half*)malloc(256 * 256 * 3 * sizeof(half));\n    half* output_half = (half*)malloc(256 * 256 * 3 * sizeof(half));\n  \n    cnrtConvertFloatToHalfArray(input_half, input_data, 256 * 256 * 3);\n    cnrtConvertFloatToHalfArray(output_half, DataT->output_data, 256 * 256 * 3);\n  \n  \n\n    void *mlu_input, *mlu_output;\n    cnrtMalloc(&(mlu_input), inputSizeS[0]);\n    cnrtMalloc(&(mlu_output), outputSizeS[0]);\n    cnrtMemcpy(mlu_input, input_half, 256 * 256 * 3 * sizeof(half), CNRT_MEM_TRANS_DIR_HOST2DEV);\n    \n\n    cnrtRuntimeContext_t ctx;\n    cnrtCreateRuntimeContext(&ctx, function, NULL);\n\n    cnrtSetRuntimeContextDeviceId(ctx, 0);\n    cnrtInitRuntimeContext(ctx, NULL);\n    \n    void *param[2];\n    param[0] = mlu_input;\n    param[1] = mlu_output;\n    cnrtQueue_t queue;\n    cnrtRuntimeContextCreateQueue(ctx, &queue);\n    cnrtInvokeRuntimeContext(ctx, (void**)param, queue, nullptr);\n    cnrtSyncQueue(queue);\n    \n    cnrtMemcpy(output_half, mlu_output, 256 * 256 * 3 * sizeof(half), CNRT_MEM_TRANS_DIR_DEV2HOST);\n    \n    cnrtConvertHalfToFloatArray(output_data, output_half, 256 * 256 * 3);\n    for(int i=0;i<t;i++)\n        for(int j=0;j<3;j++)\n            DataT->output_data[t*j+i] = output_data[i*3+j];\n    cnrtFree(mlu_input);\n    cnrtFree(mlu_output);\n    cnrtDestroyQueue(queue);\n    \n    cnrtDestroy();\n    free(input_half);\n    free(output_half);\n}\n\n}\n\n\n```\n\n## 结束语\n\n在这门课程中，~~我根据报错找 bug 的能力确实有了很大的提高~~，虽然体验不是很好，但是自己完成了之后还是挺有成就感的，如果您对于此篇文章有好的提议，或者对于这个实验还有其他的问题，可以向 $wz1234@buaa.edu.cn$ 发送邮件，也欢迎以其他方式和我交流","source":"_posts/智能计算机.md","raw":"---\ntitle: 智能计算机实验\ndate: 2020-12-21 16:01:31\ntags:\nmathjax: true\n---\n\n# 智能计算机实验\n\n## 我对于此课程实验的看法\n\n关于此实验的指导比较少，主要来源就是寒武纪论坛和一些大体的指导，没有详细的介绍，而这门实验的测试是在服务器上进行的，坑比较多，因此可能会耗费比较多的时间（除非你直接补充那七个文件而且不用在服务器上测试，平台提交直接AC）\n\n这篇文章的主要目的是提供一个比较详细的实验完成方法，并且减少大家在完成实验过程中踩的坑，但是不会提供具体的代码\n\n**注意**：如果你想快速顺利的完成此实验，可以观看这篇文章\n\n​         如果你想锻炼自己根据报错找 bug 的能力或者根据报错自学 tensorflow 的能力，可以先选择自己完成实验，如果实在是感到      困难，可以再来观看这篇文章\n\n<!--more-->\n## 实验一\n\n(听说不用快速幂和多核拆分就能过，哭了)\n\n1. 进入 /opt   将压缩包解压\n2. 进入 /opt/AICSE-demo-student/env  执行 source env.sh\n3. cd tensorflow-v1.10   执行 source env.sh   然后激活虚拟环境\n\n![image-20201221161604172](智能计算机/image-20201221161604172.png)\n\n3. 以上两步非常重要，在每一次进入服务器之后都要执行，否则会在执行脚本或编译的时候出现奇怪的错误\n4. 进入 /opt/AICSE-demo-student/demo/style_transfer_bcl/src/bangc/PluginPowerDifferenceOp ，开始进行代码的补充，我建议的顺序如下：\n   - plugin_power_difference_kernel.mlu \n   - plugin_power_difference_kernel.h\n   - powerDiff.cpp\n   - plugin_power_difference_op.cc\n   - cnplugin.h\n\n5. 在 .mlu 中进行 PowerDifference 算子的实现，这个部分比较简单，需要注意的地方为 GDRAM 和 NRAM 之间的转换，我的理解就是参数中的变量都是 GDRAM，你在函数中创建的 `__nram__ half` 变量都是 NRAM，而你的实现大概能分为三个阶段：\n\n   - 初级阶段，实现了基本的算子功能，能得到60分\n   - 中级阶段，用快速幂进行实现，能够小幅降低在 CNRT 上的延时，能得到70分（不过不用快速幂可能也行\n   - 高级阶段，实现多核拆分计算，能够同时在多个核上进行运算，能得到100分（bushi\n\n   此部分需要用到一些 bangc 的内置函数，使用其中的三个函数就能实现此算子：\n\n   - __memcpy (目标地址，源地址，长度，RAM类型转换)     功能为将源地址之后一定长度的数据拷贝到目标地址\n\n     一个栗子：`__memcpy(input1_nram+i*Seg, input1+i*Seg, Seg*sizeof(half), GDRAM2NRAM);`\n\n   - __bang_sub (目标地址，被减数，减数，长度)     功能为进行一定长度的向量减法，结果储存在目标地址\n\n     一个栗子：`__bang_sub(input1_nram+i*Seg, input1_nram+i*Seg, input2_nram+i*Seg, Seg);`\n\n   - __bang_mul     与上面类似，只不过进行的是乘法\n\n   关于函数的具体使用以及更多的函数介绍，可以参考 bangc 的开发指导书\n\n   噢，忘说了，函数的参数大致是这样：`__mlu_entry__ void PowerDifferenceKernel(half* input1, half* input2, int pow, half* output, int len)`\n\n6. 补全 plugin_power_difference_kernel.h，非常简单，只要和 .mlu 中的函数参数一致即可\n7. 补全 powerDiff.cpp，这部分若要自己写可能比较困难，我的建议是参照本来就有的其他算子的实现来完成，需要注意的是将其中的 *Kernel 改成自己的 PowerDifferenceKernel，当然还可能有其他的都需要改成 PowerDifference 对应的格式，在参照其他算子完成补全后，需要注意的是，如果你想使用多核拆分的话，还要修改两个地方：\n   - 将 dim.x = 1 改为 dim.x = 8\n   - 将 cnrtFunctionType_t c 改为 CNRT_FUNC_TYPE_UNION2\n\n8. 补全 plugin_power_difference_op.cc，这个比较难搞，即使参照其他算子，也比较烦人，我对于此部分的建议是选择的参照算子的实现可以选择简单的，并且不要思考的太过于复杂（\n9. 补全 cnplugin.h，参照上面的实现，定义 PowerDifference 对应的结构，结构指针以及 plugin_power_difference_op.cc 中函数的声明\n\n10. 在补全了以上文件之后，就可以进行算子的测试啦，在 xxx/src/bangc/PluginPowerDifferenceOp 中执行以下两句：\n    - bash make.sh\n    - ./power_diff_test\n\n    就可以看到测试结果，正确的测试结果大致如下：\n\n    ![image-20201221170316556](智能计算机/image-20201221170316556.png)\n\n11. 如果你的运行结果和上图差不多，说明你前面的实现已经差不多完成啦，接下来就要进行 cnplugin 的集成，步骤如下：\n\n    - 将 cnplugin.h 复制到下面两个目录中：\n\n      /opt/AICSE-demo-student/env/neuware/include/\n\n      /opt/AICSE-demo-student/env/Cambricon-CNPlugin-MLU270/common/include/\n\n    -  在 /opt/AICSE-demo-student/env/Cambricon-CNPlugin-MLU270 处执行 bash build_cnplugin.sh --mlu200，如果编译的最后显示 build success，说明你编译成功，会在 ./build 文件夹中生成新的 libcnplugin.so\n\n    - 将新生成的 libcnplugin.so 复制到 /opt/AICSE-demo-student/env/neuware/lib64/ 文件夹下\n\n12. 很快啊，cnplugin 的集成就完成了，接下来要进行的就是 TensorFlow 算子集成，此部分首先需要按照 /opt/AICSE-demo-student/demo/style_transfer_bcl/src/tf-implementation/tf-add-power-diff/readme.txt  即下图：\n\n    ![image-20201221171419046](智能计算机/image-20201221171419046.png)\n\n    将此文件夹下的其他文件复制到 readme.txt 里对应的文件夹中，在进行这一步时请务必仔细，否则在稍后编译时可能会产生各种各样奇怪的 bug，在复制完成后，如果你直接在 /opt/AICSE-demo-student/env/tensorflow-v1.10 中执行 bash build_tensorflow-v1.10_mlu.sh，有 99.9% 的可能会出现以下的错误：\n\n    ![image-20201221171900968](智能计算机/image-20201221171900968.png)\n\n    根据错误信息可以看出来，实验提供的 mlu_lib_ops.cc 和你补充的 plugin_power_difference_op.cc  中 ，cnmlCreatePluginPowerDifferenceOp 以及 cnmlComputePluginPowerDifferenceOpForward 的参数不同，你需要选择修改其中之一来保证两个文件中的参数一致，我的建议是修改实验提供的 mlu_lib_ops.cc，因为修改起来比较简单，并且在其中你可以使用 nullptr 来填充参数，，下面是我的实现以供参考：\n    \n    mlu_lib_ops.cc 中对于 plugin_power_difference_op的调用：\n    ![image-20201222121105346](智能计算机/image-20201222121105346.png)\n    plugin_power_difference_op.cc 中 plugin_power_difference_op 的参数：\n    ![image-20201222121110969](智能计算机/image-20201222121110969.png)\n    mlu_lib_ops.cc 中对于 cnmlComputePluginPowerDifferenceOpForward的调用：\n    ![image-20201222121125219](智能计算机/image-20201222121125219.png)\n    plugin_power_difference_op.cc 中 cnmlComputePluginPowerDifferenceOpForward 的参数：\n    ![image-20201222121129289](智能计算机/image-20201222121129289.png)\n\n    若在完成这一步之后，你的编译出现socket错误，就要将 .sh 文件中的 job_num 改为 16 ，你应该就可以成功的进行 tensorflow的编译啦（可能需要较长的时间\n\n13. 最后就是补全 .../src/online_mlu/power_difference_test_bcl.py 和 .../src/online_cpu/power_difference_test_cpu.py 文件 ， 执行 python power_difference_test_xxx.py 进行测试，这两个文件的补全比较简单，并且是基本一样的，只是在 test_bcl 中有一个特殊的地方要修改，因此我的建议是先进行 cpu 的测试，成功的测试结果如下图：\n\n    ![image-20201221173107160](智能计算机/image-20201221173107160.png)\n\n    而当你将补全的地方复制到 test_mlu.py 中，进行测试，你会得到以下结果：\n\n    ![image-20201221173352870](智能计算机/image-20201221173352870.png)\n\n    我在开始的时候将代码中的   os.environ['MLU_VISIBLE_DEVICES'] = \"0\"   改为 os.environ['MLU_VISIBLE_DEVICES'] = \"1\" ，然后再次测试：\n\n    ![image-20201221173555856](智能计算机/image-20201221173555856.png)\n\n    虽然错误率看上去比较高，但是交上去的话可以过。不过这种改的方法应该是不正确的, 而且在实验二中这个问题会同样出现但是无法解决， 出现这种情况的原因应该是在多核拆分的循环的最后一次中数据的长度不足 Seg，因此我们需要将最后的一次单独提取出来做计算，之后的结果是这样的：\n\n    ![image-20200118](智能计算机/image-20200118.png)\n\n    可以看到错误率比之前低了很多\n\n14. 最后，如果你使用了快速幂，多核拆分，但是在 MLU 上仍然有着 100+ ms 的延迟，那么你需要在 test_bcl.py 中进行如下修改：\n\n    ![image-20201221173834863](智能计算机/image-20201221173834863.png)\n\n    因为 MLU 的启动时间比较慢，所以可以多次运行来获得更低的延迟，如果这样你还不能拿到满分，请多提交几次\n\n15. 补充：如果你提交到平台上的结果为 JSON 格式错误，说明你代码写错了，请确保你在如上测试中都成功的运行出了正确的结果，如果你在实验的完成过程中出现了其他错误，请看一下自己是不是漏了某个步骤，或者某个步骤做的不够仔细，如果还是不行的话，请前往和助教对线或者在群里请求帮助，此外，请务必不要重启你的服务器，~~否则就会像我一样丢掉所有数据然后重新配一遍~~\n\n## 实验一选作（四选一）-- softmax 算子实现\n\n### softmax 算子介绍\n\n![image-20201222014249959](智能计算机/image-20201222014249959.png)\n\n### 算子实现\n\n因为输入数据的规模为 20 × 256，共 20 行，256 列，我们首先要找出每一列的最大值，方法为每次接受一行的数据，对于每一列来说，如果新输入的数据大于最大值，就更新，否则不变，然后将每一列的所有数减去这个最大值，求出 e 关于这个数的指数，再全部加起来，然后取一个倒数，然后对于每一列的每一个数，乘以之前计算出来的倒数，这样计算出来的结果即为正确结果\n\n### 具体代码\n\n```cpp\n#include \"mlu.h\"\n#define input_size 20     # 列数\n#define input_num  256    # 行数\n\n\n#define LEN  256*20\n__mlu_entry__ void SoftmaxKernel(half* input, half* output)\n{  \n   __nram__ half input_nram[input_num];\n   __nram__ half output_nram[LEN];\n   __nram__ half temp1_nram[input_num];\n   __nram__ half temp2_nram[input_num];\n   __nram__ half comL_nram[input_num];\n   __nram__ half sum_nram[input_num];\n   __nram__ half sum_recip_nram[input_num];\n   __nram__ half mulL_nram[input_num];\n   __nram__ half mulR_nram[input_num];\n   __nramset_half(comL_nram, input_num, -3000.0);\n   __nramset_half(sum_nram, input_num,0.0);\n   \n   for(int32_t i=0; i<input_size;i++)\n    {\n       __memcpy(input_nram, input+i*input_num, input_num*sizeof(half),GDRAM2NRAM);  # 分别获取每行的输入数据\n       __bang_gt(temp1_nram,comL_nram,input_nram,input_num);   # 若输入值小于最大值，则对应位置为1\n       __bang_not(temp2_nram,temp1_nram,input_num);            # 若输入值大于最大值，则对应位置为1\n       __bang_mul(mulL_nram,temp1_nram,comL_nram,input_num);   # 最大值不变的位置，置最大值\n       __bang_mul(mulR_nram,temp2_nram,input_nram,input_num);  # 最大值改变的位置，置输入值\n       __bang_add(comL_nram,mulL_nram,mulR_nram,input_num);    # 相加得到每列新的最大值\n    }\n\n   for(int32_t i=0; i<input_size;i++)\n     {\n       __memcpy(input_nram, input+i*input_num, input_num*sizeof(half),GDRAM2NRAM);  # 分别获取每行的输入数据\n       __bang_sub(temp1_nram,input_nram,comL_nram,input_num);  # 每一列减去该列最大值\n       __bang_active_exp(temp2_nram,temp1_nram,input_num);     # 求 e 关于 j-max 的指数\n       __bang_add(sum_nram,sum_nram,temp2_nram,input_num);     # 将所有的指数相加得到分母\n     }\n    __bang_active_recip(sum_recip_nram,sum_nram,input_num);    # 求出分母的倒数\n\n   for(int32_t i=0; i<input_size;i++)\n       {\n         __memcpy(input_nram, input+i*input_num, input_num*sizeof(half),GDRAM2NRAM);  # 分别获取每行的输入数据\n        __bang_sub(temp1_nram,input_nram,comL_nram,input_num);         # 每一列减去该列最大值\n        __bang_active_exp(temp2_nram,temp1_nram,input_num);            # 求 e 关于 i-max 的指数，即分子\n        __bang_mul(temp2_nram,temp2_nram,sum_recip_nram,input_num);    # 将分子和分母的倒数相乘，得到结果\n        __memcpy(output+i*input_num,temp2_nram,input_num*sizeof(half),NRAM2GDRAM);  # 将结果返回到输出中\n      }\n }\n```\n\n### 实验总结\n\n该实验对于 softmax 算子进行实现，难点在于如何灵活的运用 bangc 提供的各种函数对于数据进行操作和计算，只要按照 softmax 的定义对式子一步一步的计算，并合理的运用 bangc 提供的函数，就可以比较简单的实现 softmax 算子，在这个过程中，bangc 的教学文档起到了很大的作用，文档对于各种各样的函数做出了详细的解释与注意事项，可以对算子实现起到很大的帮助\n\n## 实验二\n\n### 模型量化\n\n该部分代码和量化手段已经提前给出，直接按照[教程](http://forum.cambricon.com/uploadfile/user/file/20200714/1594717975554836.pdf)即可完成。\n\n### 在线推理\n\n在线推理部分主要分为两块，分别需要补全\n\n/opt/AICSE-demo-student/demo/style_transfer_bcl/src/online_mlu/transform_mlu.py 和\n\n/opt/AICSE-demo-student/demo/style_transfer_bcl/src/online_cpu/transform_cpu.py\n\n#### online_cpu\n\n在cpu部分里，使用到的模型是非量化后的模型文件。\n\n该部分需要补全两个函数run_ori_power_diff_pb和run_numpy_pb\n\n- **run_ori_power_diff_pb** ：直接按照同文件下的run_ori_pb逻辑进行书写，但是要注意该函数使用的计算图与run_ori_pb不同点在于将原生的差平方计算算子改成了实验一中集成的power_difference算子，所以只需要我们进行feed数据（**不需要**重新实现power_difference的计算），将pow值传递至计算图计算。而其在**计算图中的各节点信息可使用[神经网络模型可视化网站](https://lutzroeder.github.io/netron/)进行查找**。\n\n  ![image-20201222004846500](智能计算机/image-20201222004846500.png)\n\n  从图中可以看出除了 X 还额外需要 feed 一个数据，即 PowerDifference_z，给它赋值为2即可，相当于将pow = 2 传递给了计算图\n\n  ![image-20201222004912384](智能计算机/image-20201222004912384.png)\n\n- **run_numpy_pb**：与上一个类似，只不过这里需要我们手动将原生的差平方计算算子的输入数据提出并使用实验一中的power_diff_numpy.py的内置函数进行计算后，再传回计算图进行计算。**需要注意**该函数的输入参数跟上一个run_ori_power_diff_pb的计算图一样的参数，因为这里要手动算，所以在可视化的计算图上可以发现这里断开了。\n\n  ![image-20201222004933612](智能计算机/image-20201222004933612.png)\n\n  上面这张图是使用原生的差平方计算算子的模型，可以看到SquaredDifference算子的输入分别为Conv2D_13和 moments_15/StopGradient\n\n  ![image-20201222004952263](智能计算机/image-20201222004952263.png)\n\n  可以看到这个模型的 Conv2D_13和 moments_15/StopGradient 并没有参与到算子的计算中，所以我们要把这两个节点的数据提取出来，再加上一个 pow 值为 2，作为 power_diff_numpy 的三个参数计算出 PowerDifference 算子的输出结果，此处需要注意的是从计算图中提取出来的 Tensor 不能直接进行 reshape，否则会报错，所以我们要通过 eval() 将其转换为数组，并且要向 eval() feed 一个数据 X\n\n  ![image-20201222005007770](智能计算机/image-20201222005007770.png)\n\n- 全部代码\n\n  ```python\n  import os\n  import tensorflow as tf\n  from tensorflow.python.platform import gfile\n  import argparse\n  import numpy as np\n  import cv2 as cv\n  import time\n  from power_diff_numpy import *\n  \n  os.putenv('MLU_VISIBLE_DEVICES','')\n  def parse_arg():\n      parser = argparse.ArgumentParser()\n      parser.add_argument('image')\n      parser.add_argument('ori_pb')\n      parser.add_argument('ori_power_diff_pb')\n      parser.add_argument('numpy_pb')\n      args = parser.parse_args()\n      return args\n  \n  def run_ori_pb():\n      args = parse_arg()\n      config = tf.ConfigProto(allow_soft_placement=True,\n                  inter_op_parallelism_threads=1,\n                              intra_op_parallelism_threads=1)\n      model_name = os.path.basename(args.ori_pb).split(\".\")[0]\n      image_name = os.path.basename(args.image).split(\".\")[0]\n  \n      g = tf.Graph()\n      with g.as_default():\n          with tf.gfile.FastGFile(args.ori_pb,'rb') as f:\n              graph_def = tf.GraphDef()\n              graph_def.ParseFromString(f.read())\n              tf.import_graph_def(graph_def, name='')\n          img = cv.imread(args.image)\n          X = cv.resize(img, (256, 256))\n          with tf.Session(config=config) as sess:\n              sess.graph.as_default()\n              sess.run(tf.global_variables_initializer())\n  \n              input_tensor = sess.graph.get_tensor_by_name('X_content:0')\n              output_tensor = sess.graph.get_tensor_by_name('add_37:0')\n  \n              start_time = time.time()\n              ret =sess.run(output_tensor, feed_dict={input_tensor:[X]})\n              end_time = time.time()\n              print(\"C++ inference(CPU) origin pb time is: \",end_time-start_time)\n              img1 = tf.reshape(ret,[256,256,3])\n              img_numpy = img1.eval(session=sess)\n              cv.imwrite(image_name + '_' + model_name + '_cpu.jpg',img_numpy)\n  \n  \n  def run_ori_power_diff_pb():\n      args = parse_arg()\n      config = tf.ConfigProto(allow_soft_placement=True,\n                  inter_op_parallelism_threads=1,\n                              intra_op_parallelism_threads=1)\n      model_name = os.path.basename(args.ori_power_diff_pb).split(\".\")[0]\n      image_name = os.path.basename(args.image).split(\".\")[0]\n  \n      g = tf.Graph()\n      with g.as_default():\n          with tf.gfile.FastGFile(args.ori_power_diff_pb,'rb') as f:\n              graph_def = tf.GraphDef()\n              graph_def.ParseFromString(f.read())\n              tf.import_graph_def(graph_def, name='')\n          img = cv.imread(args.image)\n          X = cv.resize(img, (256, 256))\n          with tf.Session(config=config) as sess:\n              sess.graph.as_default()\n              sess.run(tf.global_variables_initializer())\n  \n              input_tensor1 = sess.graph.get_tensor_by_name('X_content:0')\n              input_tensor2 = sess.graph.get_tensor_by_name('moments_15/PowerDifference_z:0')\n              output_tensor = sess.graph.get_tensor_by_name('add_37:0')\n  \n              start_time = time.time()\n              ret =sess.run(output_tensor, feed_dict={input_tensor1:[X], input_tensor2:2})\n              end_time = time.time()\n              print(\"C++ inference(CPU) time is: \",end_time-start_time)\n              img1 = tf.reshape(ret,[256,256,3])\n              img_numpy = img1.eval(session=sess)\n              cv.imwrite(image_name + '_' + model_name + '_cpu.jpg',img_numpy)\n  \n  def run_numpy_pb():\n      args = parse_arg()\n      config = tf.ConfigProto(allow_soft_placement=True,\n                  inter_op_parallelism_threads=1,\n                              intra_op_parallelism_threads=1)\n      model_name = os.path.basename(args.numpy_pb).split(\".\")[0]\n      image_name = os.path.basename(args.image).split(\".\")[0]\n  \n      g = tf.Graph()\n      with g.as_default():\n          with tf.gfile.FastGFile(args.numpy_pb,'rb') as f:\n              graph_def = tf.GraphDef()\n              graph_def.ParseFromString(f.read())\n              tf.import_graph_def(graph_def, name='')\n          img = cv.imread(args.image)\n          X = cv.resize(img, (256, 256))\n          with tf.Session(config=config) as sess:\n              sess.graph.as_default()\n              sess.run(tf.global_variables_initializer())\n  \n              input_tensor1 = sess.graph.get_tensor_by_name('X_content:0')\n              input_tensor2 = sess.graph.get_tensor_by_name('moments_15/PowerDifference:0')\n              output_tensor = sess.graph.get_tensor_by_name('add_37:0')\n  \n              start_time = time.time()\n              input_2 = power_diff_numpy(sess.graph.get_tensor_by_name('Conv2D_13:0').eval(feed_dict={input_tensor1:[X]}),sess.graph.get_tensor_by_name('moments_15/StopGradient:0').eval(feed_dict={input_tensor1:[X]}),2)\n              ret =sess.run(output_tensor, feed_dict={input_tensor1:[X], input_tensor2:input_2})\n              end_time = time.time()\n              print(\"Numpy inference(CPU) time is: \",end_time-start_time)\n              img1 = tf.reshape(ret,[256,256,3])\n              img_numpy = img1.eval(session=sess)\n              cv.imwrite(image_name + '_' + model_name + '_cpu.jpg',img_numpy)\n  \n  \n  if __name__ == '__main__':\n      run_ori_pb()\n      run_ori_power_diff_pb()\n      run_numpy_pb()\n  \n  ```\n\n#### online_mlu\n\n在mlu部分，使用到的模型是量化后的模型文件。\n\n仅仅需要在每个函数前加上\n\n`config.mlu_options.save_offline_model = True`\n\n这句话用于保存量化后可用于mlu的离线模型，其余部分均与cpu相同\n\n### 离线推理\n\n~~令人惊讶的是，当我写完了在线推理之后，提交了一手发现居然拿了满分，于是我还没有写离线推理~~\n\n代码：\n\n```cpp\n#include \"inference.h\"\n#include \"cnrt.h\"\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include \"stdlib.h\"\n#include <sys/time.h>\n#include <time.h>\n\nnamespace StyleTransfer{\n\ntypedef unsigned short half;\n\nvoid cnrtConvertFloatToHalfArray(uint16_t* x, const float* y, int len) {\n  for (int i = 0; i < len; i++){\n    cnrtConvertFloatToHalf(x+i,y[i]);\n  }\n}\n\nvoid cnrtConvertHalfToFloatArray(float* x, const uint16_t* y, int len) {\n  for (int i = 0; i < len; i++){\n    cnrtConvertHalfToFloat(x+i,y[i]);\n  }\n}\n\nvoid cnrtConvertFloatToHalfArray(uint16_t* x, float* y, int len) {\n  for (int i = 0; i < len; i++){\n    cnrtConvertFloatToHalf(x+i,y[i]);\n  }\n}\n\nvoid cnrtConvertHalfToFloatArray(float* x, uint16_t* y, int len) {\n  for (int i = 0; i < len; i++){\n    cnrtConvertHalfToFloat(x+i,y[i]);\n  }\n}\n\n\nInference :: Inference(std::string offline_model){\n    offline_model_ = offline_model;\n}\n\nvoid Inference :: run(DataTransfer* DataT){\n    cnrtInit(0);\n    cnrtModel_t model;\n    cnrtLoadModel(&model, offline_model_.c_str());\n\n    cnrtDev_t dev;\n    cnrtGetDeviceHandle(&dev, 0);\n    cnrtSetCurrentDevice(dev);\n    \n    float* input_data = reinterpret_cast<float*>(malloc(256*256*3*sizeof(float)));\n    float* output_data = reinterpret_cast<float*>(malloc(256*256*3*sizeof(float)));\n    int t = 256*256;\n    for(int i=0;i<t;i++)\n        for(int j=0;j<3;j++)\n            input_data[i*3+j] = DataT->input_data[t*j+i]; \n    int number = 0;\n    cnrtGetFunctionNumber(model, &number);\n\n    cnrtFunction_t function;\n    cnrtCreateFunction(&function);\n    cnrtExtractFunction(&function, model, \"subnet0\");\n    \n\n    int inputNum, outputNum;\n    int64_t *inputSizeS, *outputSizeS;\n    cnrtGetInputDataSize(&inputSizeS, &inputNum, function);\n    cnrtGetOutputDataSize(&outputSizeS, &outputNum, function);\n\n    DataT->output_data = reinterpret_cast<float*>(malloc(256 * 256 * 3 * sizeof(float)));\n    half* input_half = (half*)malloc(256 * 256 * 3 * sizeof(half));\n    half* output_half = (half*)malloc(256 * 256 * 3 * sizeof(half));\n  \n    cnrtConvertFloatToHalfArray(input_half, input_data, 256 * 256 * 3);\n    cnrtConvertFloatToHalfArray(output_half, DataT->output_data, 256 * 256 * 3);\n  \n  \n\n    void *mlu_input, *mlu_output;\n    cnrtMalloc(&(mlu_input), inputSizeS[0]);\n    cnrtMalloc(&(mlu_output), outputSizeS[0]);\n    cnrtMemcpy(mlu_input, input_half, 256 * 256 * 3 * sizeof(half), CNRT_MEM_TRANS_DIR_HOST2DEV);\n    \n\n    cnrtRuntimeContext_t ctx;\n    cnrtCreateRuntimeContext(&ctx, function, NULL);\n\n    cnrtSetRuntimeContextDeviceId(ctx, 0);\n    cnrtInitRuntimeContext(ctx, NULL);\n    \n    void *param[2];\n    param[0] = mlu_input;\n    param[1] = mlu_output;\n    cnrtQueue_t queue;\n    cnrtRuntimeContextCreateQueue(ctx, &queue);\n    cnrtInvokeRuntimeContext(ctx, (void**)param, queue, nullptr);\n    cnrtSyncQueue(queue);\n    \n    cnrtMemcpy(output_half, mlu_output, 256 * 256 * 3 * sizeof(half), CNRT_MEM_TRANS_DIR_DEV2HOST);\n    \n    cnrtConvertHalfToFloatArray(output_data, output_half, 256 * 256 * 3);\n    for(int i=0;i<t;i++)\n        for(int j=0;j<3;j++)\n            DataT->output_data[t*j+i] = output_data[i*3+j];\n    cnrtFree(mlu_input);\n    cnrtFree(mlu_output);\n    cnrtDestroyQueue(queue);\n    \n    cnrtDestroy();\n    free(input_half);\n    free(output_half);\n}\n\n}\n\n\n```\n\n## 结束语\n\n在这门课程中，~~我根据报错找 bug 的能力确实有了很大的提高~~，虽然体验不是很好，但是自己完成了之后还是挺有成就感的，如果您对于此篇文章有好的提议，或者对于这个实验还有其他的问题，可以向 $wz1234@buaa.edu.cn$ 发送邮件，也欢迎以其他方式和我交流","slug":"智能计算机","published":1,"updated":"2021-01-18T15:40:49.835Z","_id":"ckiyh709e0014a0uz5hog7sn5","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"智能计算机实验\"><a href=\"#智能计算机实验\" class=\"headerlink\" title=\"智能计算机实验\"></a>智能计算机实验</h1><h2 id=\"我对于此课程实验的看法\"><a href=\"#我对于此课程实验的看法\" class=\"headerlink\" title=\"我对于此课程实验的看法\"></a>我对于此课程实验的看法</h2><p>关于此实验的指导比较少，主要来源就是寒武纪论坛和一些大体的指导，没有详细的介绍，而这门实验的测试是在服务器上进行的，坑比较多，因此可能会耗费比较多的时间（除非你直接补充那七个文件而且不用在服务器上测试，平台提交直接AC）</p>\n<p>这篇文章的主要目的是提供一个比较详细的实验完成方法，并且减少大家在完成实验过程中踩的坑，但是不会提供具体的代码</p>\n<p><strong>注意</strong>：如果你想快速顺利的完成此实验，可以观看这篇文章</p>\n<p>​         如果你想锻炼自己根据报错找 bug 的能力或者根据报错自学 tensorflow 的能力，可以先选择自己完成实验，如果实在是感到      困难，可以再来观看这篇文章</p>\n<a id=\"more\"></a>\n<h2 id=\"实验一\"><a href=\"#实验一\" class=\"headerlink\" title=\"实验一\"></a>实验一</h2><p>(听说不用快速幂和多核拆分就能过，哭了)</p>\n<ol>\n<li>进入 /opt   将压缩包解压</li>\n<li>进入 /opt/AICSE-demo-student/env  执行 source env.sh</li>\n<li>cd tensorflow-v1.10   执行 source env.sh   然后激活虚拟环境</li>\n</ol>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221161604172.png\" alt=\"image-20201221161604172\"></p>\n<ol>\n<li>以上两步非常重要，在每一次进入服务器之后都要执行，否则会在执行脚本或编译的时候出现奇怪的错误</li>\n<li><p>进入 /opt/AICSE-demo-student/demo/style_transfer_bcl/src/bangc/PluginPowerDifferenceOp ，开始进行代码的补充，我建议的顺序如下：</p>\n<ul>\n<li>plugin_power_difference_kernel.mlu </li>\n<li>plugin_power_difference_kernel.h</li>\n<li>powerDiff.cpp</li>\n<li>plugin_power_difference_op.cc</li>\n<li>cnplugin.h</li>\n</ul>\n</li>\n<li><p>在 .mlu 中进行 PowerDifference 算子的实现，这个部分比较简单，需要注意的地方为 GDRAM 和 NRAM 之间的转换，我的理解就是参数中的变量都是 GDRAM，你在函数中创建的 <code>__nram__ half</code> 变量都是 NRAM，而你的实现大概能分为三个阶段：</p>\n<ul>\n<li>初级阶段，实现了基本的算子功能，能得到60分</li>\n<li>中级阶段，用快速幂进行实现，能够小幅降低在 CNRT 上的延时，能得到70分（不过不用快速幂可能也行</li>\n<li>高级阶段，实现多核拆分计算，能够同时在多个核上进行运算，能得到100分（bushi</li>\n</ul>\n<p>此部分需要用到一些 bangc 的内置函数，使用其中的三个函数就能实现此算子：</p>\n<ul>\n<li><p>__memcpy (目标地址，源地址，长度，RAM类型转换)     功能为将源地址之后一定长度的数据拷贝到目标地址</p>\n<p>一个栗子：<code>__memcpy(input1_nram+i*Seg, input1+i*Seg, Seg*sizeof(half), GDRAM2NRAM);</code></p>\n</li>\n<li><p>__bang_sub (目标地址，被减数，减数，长度)     功能为进行一定长度的向量减法，结果储存在目标地址</p>\n<p>一个栗子：<code>__bang_sub(input1_nram+i*Seg, input1_nram+i*Seg, input2_nram+i*Seg, Seg);</code></p>\n</li>\n<li><p>__bang_mul     与上面类似，只不过进行的是乘法</p>\n</li>\n</ul>\n<p>关于函数的具体使用以及更多的函数介绍，可以参考 bangc 的开发指导书</p>\n<p>噢，忘说了，函数的参数大致是这样：<code>__mlu_entry__ void PowerDifferenceKernel(half* input1, half* input2, int pow, half* output, int len)</code></p>\n</li>\n<li><p>补全 plugin_power_difference_kernel.h，非常简单，只要和 .mlu 中的函数参数一致即可</p>\n</li>\n<li><p>补全 powerDiff.cpp，这部分若要自己写可能比较困难，我的建议是参照本来就有的其他算子的实现来完成，需要注意的是将其中的 *Kernel 改成自己的 PowerDifferenceKernel，当然还可能有其他的都需要改成 PowerDifference 对应的格式，在参照其他算子完成补全后，需要注意的是，如果你想使用多核拆分的话，还要修改两个地方：</p>\n<ul>\n<li>将 dim.x = 1 改为 dim.x = 8</li>\n<li>将 cnrtFunctionType_t c 改为 CNRT_FUNC_TYPE_UNION2</li>\n</ul>\n</li>\n<li><p>补全 plugin_power_difference_op.cc，这个比较难搞，即使参照其他算子，也比较烦人，我对于此部分的建议是选择的参照算子的实现可以选择简单的，并且不要思考的太过于复杂（</p>\n</li>\n<li><p>补全 cnplugin.h，参照上面的实现，定义 PowerDifference 对应的结构，结构指针以及 plugin_power_difference_op.cc 中函数的声明</p>\n</li>\n<li><p>在补全了以上文件之后，就可以进行算子的测试啦，在 xxx/src/bangc/PluginPowerDifferenceOp 中执行以下两句：</p>\n<ul>\n<li>bash make.sh</li>\n<li>./power_diff_test</li>\n</ul>\n<p>就可以看到测试结果，正确的测试结果大致如下：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221170316556.png\" alt=\"image-20201221170316556\"></p>\n</li>\n<li><p>如果你的运行结果和上图差不多，说明你前面的实现已经差不多完成啦，接下来就要进行 cnplugin 的集成，步骤如下：</p>\n<ul>\n<li><p>将 cnplugin.h 复制到下面两个目录中：</p>\n<p>/opt/AICSE-demo-student/env/neuware/include/</p>\n<p>/opt/AICSE-demo-student/env/Cambricon-CNPlugin-MLU270/common/include/</p>\n</li>\n<li><p>在 /opt/AICSE-demo-student/env/Cambricon-CNPlugin-MLU270 处执行 bash build_cnplugin.sh —mlu200，如果编译的最后显示 build success，说明你编译成功，会在 ./build 文件夹中生成新的 libcnplugin.so</p>\n</li>\n<li><p>将新生成的 libcnplugin.so 复制到 /opt/AICSE-demo-student/env/neuware/lib64/ 文件夹下</p>\n</li>\n</ul>\n</li>\n<li><p>很快啊，cnplugin 的集成就完成了，接下来要进行的就是 TensorFlow 算子集成，此部分首先需要按照 /opt/AICSE-demo-student/demo/style_transfer_bcl/src/tf-implementation/tf-add-power-diff/readme.txt  即下图：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221171419046.png\" alt=\"image-20201221171419046\"></p>\n<p>将此文件夹下的其他文件复制到 readme.txt 里对应的文件夹中，在进行这一步时请务必仔细，否则在稍后编译时可能会产生各种各样奇怪的 bug，在复制完成后，如果你直接在 /opt/AICSE-demo-student/env/tensorflow-v1.10 中执行 bash build_tensorflow-v1.10_mlu.sh，有 99.9% 的可能会出现以下的错误：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221171900968.png\" alt=\"image-20201221171900968\"></p>\n<p>根据错误信息可以看出来，实验提供的 mlu_lib_ops.cc 和你补充的 plugin_power_difference_op.cc  中 ，cnmlCreatePluginPowerDifferenceOp 以及 cnmlComputePluginPowerDifferenceOpForward 的参数不同，你需要选择修改其中之一来保证两个文件中的参数一致，我的建议是修改实验提供的 mlu_lib_ops.cc，因为修改起来比较简单，并且在其中你可以使用 nullptr 来填充参数，，下面是我的实现以供参考：</p>\n<p>mlu_lib_ops.cc 中对于 plugin_power_difference_op的调用：<br><img src=\"/2020/12/21/智能计算机/image-20201222121105346.png\" alt=\"image-20201222121105346\"><br>plugin_power_difference_op.cc 中 plugin_power_difference_op 的参数：<br><img src=\"/2020/12/21/智能计算机/image-20201222121110969.png\" alt=\"image-20201222121110969\"><br>mlu_lib_ops.cc 中对于 cnmlComputePluginPowerDifferenceOpForward的调用：<br><img src=\"/2020/12/21/智能计算机/image-20201222121125219.png\" alt=\"image-20201222121125219\"><br>plugin_power_difference_op.cc 中 cnmlComputePluginPowerDifferenceOpForward 的参数：<br><img src=\"/2020/12/21/智能计算机/image-20201222121129289.png\" alt=\"image-20201222121129289\"></p>\n<p>若在完成这一步之后，你的编译出现socket错误，就要将 .sh 文件中的 job_num 改为 16 ，你应该就可以成功的进行 tensorflow的编译啦（可能需要较长的时间</p>\n</li>\n<li><p>最后就是补全 …/src/online_mlu/power_difference_test_bcl.py 和 …/src/online_cpu/power_difference_test_cpu.py 文件 ， 执行 python power_difference_test_xxx.py 进行测试，这两个文件的补全比较简单，并且是基本一样的，只是在 test_bcl 中有一个特殊的地方要修改，因此我的建议是先进行 cpu 的测试，成功的测试结果如下图：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221173107160.png\" alt=\"image-20201221173107160\"></p>\n<p>而当你将补全的地方复制到 test_mlu.py 中，进行测试，你会得到以下结果：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221173352870.png\" alt=\"image-20201221173352870\"></p>\n<p>我在开始的时候将代码中的   os.environ[‘MLU_VISIBLE_DEVICES’] = “0”   改为 os.environ[‘MLU_VISIBLE_DEVICES’] = “1” ，然后再次测试：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221173555856.png\" alt=\"image-20201221173555856\"></p>\n<p>虽然错误率看上去比较高，但是交上去的话可以过。不过这种改的方法应该是不正确的, 而且在实验二中这个问题会同样出现但是无法解决， 出现这种情况的原因应该是在多核拆分的循环的最后一次中数据的长度不足 Seg，因此我们需要将最后的一次单独提取出来做计算，之后的结果是这样的：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20200118.png\" alt=\"image-20200118\"></p>\n<p>可以看到错误率比之前低了很多</p>\n</li>\n<li><p>最后，如果你使用了快速幂，多核拆分，但是在 MLU 上仍然有着 100+ ms 的延迟，那么你需要在 test_bcl.py 中进行如下修改：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221173834863.png\" alt=\"image-20201221173834863\"></p>\n<p>因为 MLU 的启动时间比较慢，所以可以多次运行来获得更低的延迟，如果这样你还不能拿到满分，请多提交几次</p>\n</li>\n<li><p>补充：如果你提交到平台上的结果为 JSON 格式错误，说明你代码写错了，请确保你在如上测试中都成功的运行出了正确的结果，如果你在实验的完成过程中出现了其他错误，请看一下自己是不是漏了某个步骤，或者某个步骤做的不够仔细，如果还是不行的话，请前往和助教对线或者在群里请求帮助，此外，请务必不要重启你的服务器，<del>否则就会像我一样丢掉所有数据然后重新配一遍</del></p>\n</li>\n</ol>\n<h2 id=\"实验一选作（四选一）—-softmax-算子实现\"><a href=\"#实验一选作（四选一）—-softmax-算子实现\" class=\"headerlink\" title=\"实验一选作（四选一）— softmax 算子实现\"></a>实验一选作（四选一）— softmax 算子实现</h2><h3 id=\"softmax-算子介绍\"><a href=\"#softmax-算子介绍\" class=\"headerlink\" title=\"softmax 算子介绍\"></a>softmax 算子介绍</h3><p><img src=\"/2020/12/21/智能计算机/image-20201222014249959.png\" alt=\"image-20201222014249959\"></p>\n<h3 id=\"算子实现\"><a href=\"#算子实现\" class=\"headerlink\" title=\"算子实现\"></a>算子实现</h3><p>因为输入数据的规模为 20 × 256，共 20 行，256 列，我们首先要找出每一列的最大值，方法为每次接受一行的数据，对于每一列来说，如果新输入的数据大于最大值，就更新，否则不变，然后将每一列的所有数减去这个最大值，求出 e 关于这个数的指数，再全部加起来，然后取一个倒数，然后对于每一列的每一个数，乘以之前计算出来的倒数，这样计算出来的结果即为正确结果</p>\n<h3 id=\"具体代码\"><a href=\"#具体代码\" class=\"headerlink\" title=\"具体代码\"></a>具体代码</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"mlu.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> input_size 20     # 列数</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> input_num  256    # 行数</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> LEN  256*20</span></span><br><span class=\"line\">__<span class=\"function\">mlu_entry__ <span class=\"keyword\">void</span> <span class=\"title\">SoftmaxKernel</span><span class=\"params\">(half* input, half* output)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;  </span><br><span class=\"line\">   __nram__ half input_nram[input_num];</span><br><span class=\"line\">   __nram__ half output_nram[LEN];</span><br><span class=\"line\">   __nram__ half temp1_nram[input_num];</span><br><span class=\"line\">   __nram__ half temp2_nram[input_num];</span><br><span class=\"line\">   __nram__ half comL_nram[input_num];</span><br><span class=\"line\">   __nram__ half sum_nram[input_num];</span><br><span class=\"line\">   __nram__ half sum_recip_nram[input_num];</span><br><span class=\"line\">   __nram__ half mulL_nram[input_num];</span><br><span class=\"line\">   __nram__ half mulR_nram[input_num];</span><br><span class=\"line\">   __nramset_half(comL_nram, input_num, <span class=\"number\">-3000.0</span>);</span><br><span class=\"line\">   __nramset_half(sum_nram, input_num,<span class=\"number\">0.0</span>);</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"keyword\">for</span>(<span class=\"keyword\">int32_t</span> i=<span class=\"number\">0</span>; i&lt;input_size;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">       __memcpy(input_nram, input+i*input_num, input_num*<span class=\"keyword\">sizeof</span>(half),GDRAM2NRAM);  # 分别获取每行的输入数据</span><br><span class=\"line\">       __bang_gt(temp1_nram,comL_nram,input_nram,input_num);   # 若输入值小于最大值，则对应位置为<span class=\"number\">1</span></span><br><span class=\"line\">       __bang_not(temp2_nram,temp1_nram,input_num);            # 若输入值大于最大值，则对应位置为<span class=\"number\">1</span></span><br><span class=\"line\">       __bang_mul(mulL_nram,temp1_nram,comL_nram,input_num);   # 最大值不变的位置，置最大值</span><br><span class=\"line\">       __bang_mul(mulR_nram,temp2_nram,input_nram,input_num);  # 最大值改变的位置，置输入值</span><br><span class=\"line\">       __bang_add(comL_nram,mulL_nram,mulR_nram,input_num);    # 相加得到每列新的最大值</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">for</span>(<span class=\"keyword\">int32_t</span> i=<span class=\"number\">0</span>; i&lt;input_size;i++)</span><br><span class=\"line\">     &#123;</span><br><span class=\"line\">       __memcpy(input_nram, input+i*input_num, input_num*<span class=\"keyword\">sizeof</span>(half),GDRAM2NRAM);  # 分别获取每行的输入数据</span><br><span class=\"line\">       __bang_sub(temp1_nram,input_nram,comL_nram,input_num);  # 每一列减去该列最大值</span><br><span class=\"line\">       __bang_active_exp(temp2_nram,temp1_nram,input_num);     # 求 e 关于 j-max 的指数</span><br><span class=\"line\">       __bang_add(sum_nram,sum_nram,temp2_nram,input_num);     # 将所有的指数相加得到分母</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\">    __bang_active_recip(sum_recip_nram,sum_nram,input_num);    # 求出分母的倒数</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">for</span>(<span class=\"keyword\">int32_t</span> i=<span class=\"number\">0</span>; i&lt;input_size;i++)</span><br><span class=\"line\">       &#123;</span><br><span class=\"line\">         __memcpy(input_nram, input+i*input_num, input_num*<span class=\"keyword\">sizeof</span>(half),GDRAM2NRAM);  # 分别获取每行的输入数据</span><br><span class=\"line\">        __bang_sub(temp1_nram,input_nram,comL_nram,input_num);         # 每一列减去该列最大值</span><br><span class=\"line\">        __bang_active_exp(temp2_nram,temp1_nram,input_num);            # 求 e 关于 i-max 的指数，即分子</span><br><span class=\"line\">        __bang_mul(temp2_nram,temp2_nram,sum_recip_nram,input_num);    # 将分子和分母的倒数相乘，得到结果</span><br><span class=\"line\">        __memcpy(output+i*input_num,temp2_nram,input_num*<span class=\"keyword\">sizeof</span>(half),NRAM2GDRAM);  # 将结果返回到输出中</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"实验总结\"><a href=\"#实验总结\" class=\"headerlink\" title=\"实验总结\"></a>实验总结</h3><p>该实验对于 softmax 算子进行实现，难点在于如何灵活的运用 bangc 提供的各种函数对于数据进行操作和计算，只要按照 softmax 的定义对式子一步一步的计算，并合理的运用 bangc 提供的函数，就可以比较简单的实现 softmax 算子，在这个过程中，bangc 的教学文档起到了很大的作用，文档对于各种各样的函数做出了详细的解释与注意事项，可以对算子实现起到很大的帮助</p>\n<h2 id=\"实验二\"><a href=\"#实验二\" class=\"headerlink\" title=\"实验二\"></a>实验二</h2><h3 id=\"模型量化\"><a href=\"#模型量化\" class=\"headerlink\" title=\"模型量化\"></a>模型量化</h3><p>该部分代码和量化手段已经提前给出，直接按照<a href=\"http://forum.cambricon.com/uploadfile/user/file/20200714/1594717975554836.pdf\" target=\"_blank\" rel=\"noopener\">教程</a>即可完成。</p>\n<h3 id=\"在线推理\"><a href=\"#在线推理\" class=\"headerlink\" title=\"在线推理\"></a>在线推理</h3><p>在线推理部分主要分为两块，分别需要补全</p>\n<p>/opt/AICSE-demo-student/demo/style_transfer_bcl/src/online_mlu/transform_mlu.py 和</p>\n<p>/opt/AICSE-demo-student/demo/style_transfer_bcl/src/online_cpu/transform_cpu.py</p>\n<h4 id=\"online-cpu\"><a href=\"#online-cpu\" class=\"headerlink\" title=\"online_cpu\"></a>online_cpu</h4><p>在cpu部分里，使用到的模型是非量化后的模型文件。</p>\n<p>该部分需要补全两个函数run_ori_power_diff_pb和run_numpy_pb</p>\n<ul>\n<li><p><strong>run_ori_power_diff_pb</strong> ：直接按照同文件下的run_ori_pb逻辑进行书写，但是要注意该函数使用的计算图与run_ori_pb不同点在于将原生的差平方计算算子改成了实验一中集成的power_difference算子，所以只需要我们进行feed数据（<strong>不需要</strong>重新实现power_difference的计算），将pow值传递至计算图计算。而其在<strong>计算图中的各节点信息可使用<a href=\"https://lutzroeder.github.io/netron/\" target=\"_blank\" rel=\"noopener\">神经网络模型可视化网站</a>进行查找</strong>。</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201222004846500.png\" alt=\"image-20201222004846500\"></p>\n<p>从图中可以看出除了 X 还额外需要 feed 一个数据，即 PowerDifference_z，给它赋值为2即可，相当于将pow = 2 传递给了计算图</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201222004912384.png\" alt=\"image-20201222004912384\"></p>\n</li>\n<li><p><strong>run_numpy_pb</strong>：与上一个类似，只不过这里需要我们手动将原生的差平方计算算子的输入数据提出并使用实验一中的power_diff_numpy.py的内置函数进行计算后，再传回计算图进行计算。<strong>需要注意</strong>该函数的输入参数跟上一个run_ori_power_diff_pb的计算图一样的参数，因为这里要手动算，所以在可视化的计算图上可以发现这里断开了。</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201222004933612.png\" alt=\"image-20201222004933612\"></p>\n<p>上面这张图是使用原生的差平方计算算子的模型，可以看到SquaredDifference算子的输入分别为Conv2D_13和 moments_15/StopGradient</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201222004952263.png\" alt=\"image-20201222004952263\"></p>\n<p>可以看到这个模型的 Conv2D_13和 moments_15/StopGradient 并没有参与到算子的计算中，所以我们要把这两个节点的数据提取出来，再加上一个 pow 值为 2，作为 power_diff_numpy 的三个参数计算出 PowerDifference 算子的输出结果，此处需要注意的是从计算图中提取出来的 Tensor 不能直接进行 reshape，否则会报错，所以我们要通过 eval() 将其转换为数组，并且要向 eval() feed 一个数据 X</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201222005007770.png\" alt=\"image-20201222005007770\"></p>\n</li>\n<li><p>全部代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">from</span> tensorflow.python.platform <span class=\"keyword\">import</span> gfile</span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2 <span class=\"keyword\">as</span> cv</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">from</span> power_diff_numpy <span class=\"keyword\">import</span> *</span><br><span class=\"line\"></span><br><span class=\"line\">os.putenv(<span class=\"string\">'MLU_VISIBLE_DEVICES'</span>,<span class=\"string\">''</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse_arg</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    parser = argparse.ArgumentParser()</span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">'image'</span>)</span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">'ori_pb'</span>)</span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">'ori_power_diff_pb'</span>)</span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">'numpy_pb'</span>)</span><br><span class=\"line\">    args = parser.parse_args()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> args</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run_ori_pb</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    args = parse_arg()</span><br><span class=\"line\">    config = tf.ConfigProto(allow_soft_placement=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                inter_op_parallelism_threads=<span class=\"number\">1</span>,</span><br><span class=\"line\">                            intra_op_parallelism_threads=<span class=\"number\">1</span>)</span><br><span class=\"line\">    model_name = os.path.basename(args.ori_pb).split(<span class=\"string\">\".\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    image_name = os.path.basename(args.image).split(<span class=\"string\">\".\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    g = tf.Graph()</span><br><span class=\"line\">    <span class=\"keyword\">with</span> g.as_default():</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.gfile.FastGFile(args.ori_pb,<span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            graph_def = tf.GraphDef()</span><br><span class=\"line\">            graph_def.ParseFromString(f.read())</span><br><span class=\"line\">            tf.import_graph_def(graph_def, name=<span class=\"string\">''</span>)</span><br><span class=\"line\">        img = cv.imread(args.image)</span><br><span class=\"line\">        X = cv.resize(img, (<span class=\"number\">256</span>, <span class=\"number\">256</span>))</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.Session(config=config) <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">            sess.graph.as_default()</span><br><span class=\"line\">            sess.run(tf.global_variables_initializer())</span><br><span class=\"line\"></span><br><span class=\"line\">            input_tensor = sess.graph.get_tensor_by_name(<span class=\"string\">'X_content:0'</span>)</span><br><span class=\"line\">            output_tensor = sess.graph.get_tensor_by_name(<span class=\"string\">'add_37:0'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            start_time = time.time()</span><br><span class=\"line\">            ret =sess.run(output_tensor, feed_dict=&#123;input_tensor:[X]&#125;)</span><br><span class=\"line\">            end_time = time.time()</span><br><span class=\"line\">            print(<span class=\"string\">\"C++ inference(CPU) origin pb time is: \"</span>,end_time-start_time)</span><br><span class=\"line\">            img1 = tf.reshape(ret,[<span class=\"number\">256</span>,<span class=\"number\">256</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\">            img_numpy = img1.eval(session=sess)</span><br><span class=\"line\">            cv.imwrite(image_name + <span class=\"string\">'_'</span> + model_name + <span class=\"string\">'_cpu.jpg'</span>,img_numpy)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run_ori_power_diff_pb</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    args = parse_arg()</span><br><span class=\"line\">    config = tf.ConfigProto(allow_soft_placement=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                inter_op_parallelism_threads=<span class=\"number\">1</span>,</span><br><span class=\"line\">                            intra_op_parallelism_threads=<span class=\"number\">1</span>)</span><br><span class=\"line\">    model_name = os.path.basename(args.ori_power_diff_pb).split(<span class=\"string\">\".\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    image_name = os.path.basename(args.image).split(<span class=\"string\">\".\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    g = tf.Graph()</span><br><span class=\"line\">    <span class=\"keyword\">with</span> g.as_default():</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.gfile.FastGFile(args.ori_power_diff_pb,<span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            graph_def = tf.GraphDef()</span><br><span class=\"line\">            graph_def.ParseFromString(f.read())</span><br><span class=\"line\">            tf.import_graph_def(graph_def, name=<span class=\"string\">''</span>)</span><br><span class=\"line\">        img = cv.imread(args.image)</span><br><span class=\"line\">        X = cv.resize(img, (<span class=\"number\">256</span>, <span class=\"number\">256</span>))</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.Session(config=config) <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">            sess.graph.as_default()</span><br><span class=\"line\">            sess.run(tf.global_variables_initializer())</span><br><span class=\"line\"></span><br><span class=\"line\">            input_tensor1 = sess.graph.get_tensor_by_name(<span class=\"string\">'X_content:0'</span>)</span><br><span class=\"line\">            input_tensor2 = sess.graph.get_tensor_by_name(<span class=\"string\">'moments_15/PowerDifference_z:0'</span>)</span><br><span class=\"line\">            output_tensor = sess.graph.get_tensor_by_name(<span class=\"string\">'add_37:0'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            start_time = time.time()</span><br><span class=\"line\">            ret =sess.run(output_tensor, feed_dict=&#123;input_tensor1:[X], input_tensor2:<span class=\"number\">2</span>&#125;)</span><br><span class=\"line\">            end_time = time.time()</span><br><span class=\"line\">            print(<span class=\"string\">\"C++ inference(CPU) time is: \"</span>,end_time-start_time)</span><br><span class=\"line\">            img1 = tf.reshape(ret,[<span class=\"number\">256</span>,<span class=\"number\">256</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\">            img_numpy = img1.eval(session=sess)</span><br><span class=\"line\">            cv.imwrite(image_name + <span class=\"string\">'_'</span> + model_name + <span class=\"string\">'_cpu.jpg'</span>,img_numpy)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run_numpy_pb</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    args = parse_arg()</span><br><span class=\"line\">    config = tf.ConfigProto(allow_soft_placement=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                inter_op_parallelism_threads=<span class=\"number\">1</span>,</span><br><span class=\"line\">                            intra_op_parallelism_threads=<span class=\"number\">1</span>)</span><br><span class=\"line\">    model_name = os.path.basename(args.numpy_pb).split(<span class=\"string\">\".\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    image_name = os.path.basename(args.image).split(<span class=\"string\">\".\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    g = tf.Graph()</span><br><span class=\"line\">    <span class=\"keyword\">with</span> g.as_default():</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.gfile.FastGFile(args.numpy_pb,<span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            graph_def = tf.GraphDef()</span><br><span class=\"line\">            graph_def.ParseFromString(f.read())</span><br><span class=\"line\">            tf.import_graph_def(graph_def, name=<span class=\"string\">''</span>)</span><br><span class=\"line\">        img = cv.imread(args.image)</span><br><span class=\"line\">        X = cv.resize(img, (<span class=\"number\">256</span>, <span class=\"number\">256</span>))</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.Session(config=config) <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">            sess.graph.as_default()</span><br><span class=\"line\">            sess.run(tf.global_variables_initializer())</span><br><span class=\"line\"></span><br><span class=\"line\">            input_tensor1 = sess.graph.get_tensor_by_name(<span class=\"string\">'X_content:0'</span>)</span><br><span class=\"line\">            input_tensor2 = sess.graph.get_tensor_by_name(<span class=\"string\">'moments_15/PowerDifference:0'</span>)</span><br><span class=\"line\">            output_tensor = sess.graph.get_tensor_by_name(<span class=\"string\">'add_37:0'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            start_time = time.time()</span><br><span class=\"line\">            input_2 = power_diff_numpy(sess.graph.get_tensor_by_name(<span class=\"string\">'Conv2D_13:0'</span>).eval(feed_dict=&#123;input_tensor1:[X]&#125;),sess.graph.get_tensor_by_name(<span class=\"string\">'moments_15/StopGradient:0'</span>).eval(feed_dict=&#123;input_tensor1:[X]&#125;),<span class=\"number\">2</span>)</span><br><span class=\"line\">            ret =sess.run(output_tensor, feed_dict=&#123;input_tensor1:[X], input_tensor2:input_2&#125;)</span><br><span class=\"line\">            end_time = time.time()</span><br><span class=\"line\">            print(<span class=\"string\">\"Numpy inference(CPU) time is: \"</span>,end_time-start_time)</span><br><span class=\"line\">            img1 = tf.reshape(ret,[<span class=\"number\">256</span>,<span class=\"number\">256</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\">            img_numpy = img1.eval(session=sess)</span><br><span class=\"line\">            cv.imwrite(image_name + <span class=\"string\">'_'</span> + model_name + <span class=\"string\">'_cpu.jpg'</span>,img_numpy)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    run_ori_pb()</span><br><span class=\"line\">    run_ori_power_diff_pb()</span><br><span class=\"line\">    run_numpy_pb()</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"online-mlu\"><a href=\"#online-mlu\" class=\"headerlink\" title=\"online_mlu\"></a>online_mlu</h4><p>在mlu部分，使用到的模型是量化后的模型文件。</p>\n<p>仅仅需要在每个函数前加上</p>\n<p><code>config.mlu_options.save_offline_model = True</code></p>\n<p>这句话用于保存量化后可用于mlu的离线模型，其余部分均与cpu相同</p>\n<h3 id=\"离线推理\"><a href=\"#离线推理\" class=\"headerlink\" title=\"离线推理\"></a>离线推理</h3><p><del>令人惊讶的是，当我写完了在线推理之后，提交了一手发现居然拿了满分，于是我还没有写离线推理</del></p>\n<p>代码：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"inference.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"cnrt.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"stdlib.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sys/time.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;time.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">namespace</span> StyleTransfer&#123;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> half;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">cnrtConvertFloatToHalfArray</span><span class=\"params\">(<span class=\"keyword\">uint16_t</span>* x, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span>* y, <span class=\"keyword\">int</span> len)</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)&#123;</span><br><span class=\"line\">    cnrtConvertFloatToHalf(x+i,y[i]);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">cnrtConvertHalfToFloatArray</span><span class=\"params\">(<span class=\"keyword\">float</span>* x, <span class=\"keyword\">const</span> <span class=\"keyword\">uint16_t</span>* y, <span class=\"keyword\">int</span> len)</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)&#123;</span><br><span class=\"line\">    cnrtConvertHalfToFloat(x+i,y[i]);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">cnrtConvertFloatToHalfArray</span><span class=\"params\">(<span class=\"keyword\">uint16_t</span>* x, <span class=\"keyword\">float</span>* y, <span class=\"keyword\">int</span> len)</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)&#123;</span><br><span class=\"line\">    cnrtConvertFloatToHalf(x+i,y[i]);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">cnrtConvertHalfToFloatArray</span><span class=\"params\">(<span class=\"keyword\">float</span>* x, <span class=\"keyword\">uint16_t</span>* y, <span class=\"keyword\">int</span> len)</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)&#123;</span><br><span class=\"line\">    cnrtConvertHalfToFloat(x+i,y[i]);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">Inference :: Inference(<span class=\"built_in\">std</span>::<span class=\"built_in\">string</span> offline_model)&#123;</span><br><span class=\"line\">    offline_model_ = offline_model;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> Inference :: run(DataTransfer* DataT)&#123;</span><br><span class=\"line\">    cnrtInit(<span class=\"number\">0</span>);</span><br><span class=\"line\">    cnrtModel_t model;</span><br><span class=\"line\">    cnrtLoadModel(&amp;model, offline_model_.c_str());</span><br><span class=\"line\"></span><br><span class=\"line\">    cnrtDev_t dev;</span><br><span class=\"line\">    cnrtGetDeviceHandle(&amp;dev, <span class=\"number\">0</span>);</span><br><span class=\"line\">    cnrtSetCurrentDevice(dev);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">float</span>* input_data = <span class=\"keyword\">reinterpret_cast</span>&lt;<span class=\"keyword\">float</span>*&gt;(<span class=\"built_in\">malloc</span>(<span class=\"number\">256</span>*<span class=\"number\">256</span>*<span class=\"number\">3</span>*<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>)));</span><br><span class=\"line\">    <span class=\"keyword\">float</span>* output_data = <span class=\"keyword\">reinterpret_cast</span>&lt;<span class=\"keyword\">float</span>*&gt;(<span class=\"built_in\">malloc</span>(<span class=\"number\">256</span>*<span class=\"number\">256</span>*<span class=\"number\">3</span>*<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>)));</span><br><span class=\"line\">    <span class=\"keyword\">int</span> t = <span class=\"number\">256</span>*<span class=\"number\">256</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>;i&lt;t;i++)</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">0</span>;j&lt;<span class=\"number\">3</span>;j++)</span><br><span class=\"line\">            input_data[i*<span class=\"number\">3</span>+j] = DataT-&gt;input_data[t*j+i]; </span><br><span class=\"line\">    <span class=\"keyword\">int</span> number = <span class=\"number\">0</span>;</span><br><span class=\"line\">    cnrtGetFunctionNumber(model, &amp;number);</span><br><span class=\"line\"></span><br><span class=\"line\">    cnrtFunction_t function;</span><br><span class=\"line\">    cnrtCreateFunction(&amp;function);</span><br><span class=\"line\">    cnrtExtractFunction(&amp;function, model, <span class=\"string\">\"subnet0\"</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">int</span> inputNum, outputNum;</span><br><span class=\"line\">    <span class=\"keyword\">int64_t</span> *inputSizeS, *outputSizeS;</span><br><span class=\"line\">    cnrtGetInputDataSize(&amp;inputSizeS, &amp;inputNum, function);</span><br><span class=\"line\">    cnrtGetOutputDataSize(&amp;outputSizeS, &amp;outputNum, function);</span><br><span class=\"line\"></span><br><span class=\"line\">    DataT-&gt;output_data = <span class=\"keyword\">reinterpret_cast</span>&lt;<span class=\"keyword\">float</span>*&gt;(<span class=\"built_in\">malloc</span>(<span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span> * <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>)));</span><br><span class=\"line\">    half* input_half = (half*)<span class=\"built_in\">malloc</span>(<span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span> * <span class=\"keyword\">sizeof</span>(half));</span><br><span class=\"line\">    half* output_half = (half*)<span class=\"built_in\">malloc</span>(<span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span> * <span class=\"keyword\">sizeof</span>(half));</span><br><span class=\"line\">  </span><br><span class=\"line\">    cnrtConvertFloatToHalfArray(input_half, input_data, <span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span>);</span><br><span class=\"line\">    cnrtConvertFloatToHalfArray(output_half, DataT-&gt;output_data, <span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span>);</span><br><span class=\"line\">  </span><br><span class=\"line\">  </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">void</span> *mlu_input, *mlu_output;</span><br><span class=\"line\">    cnrtMalloc(&amp;(mlu_input), inputSizeS[<span class=\"number\">0</span>]);</span><br><span class=\"line\">    cnrtMalloc(&amp;(mlu_output), outputSizeS[<span class=\"number\">0</span>]);</span><br><span class=\"line\">    cnrtMemcpy(mlu_input, input_half, <span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span> * <span class=\"keyword\">sizeof</span>(half), CNRT_MEM_TRANS_DIR_HOST2DEV);</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">    cnrtRuntimeContext_t ctx;</span><br><span class=\"line\">    cnrtCreateRuntimeContext(&amp;ctx, function, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    cnrtSetRuntimeContextDeviceId(ctx, <span class=\"number\">0</span>);</span><br><span class=\"line\">    cnrtInitRuntimeContext(ctx, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">void</span> *param[<span class=\"number\">2</span>];</span><br><span class=\"line\">    param[<span class=\"number\">0</span>] = mlu_input;</span><br><span class=\"line\">    param[<span class=\"number\">1</span>] = mlu_output;</span><br><span class=\"line\">    cnrtQueue_t <span class=\"built_in\">queue</span>;</span><br><span class=\"line\">    cnrtRuntimeContextCreateQueue(ctx, &amp;<span class=\"built_in\">queue</span>);</span><br><span class=\"line\">    cnrtInvokeRuntimeContext(ctx, (<span class=\"keyword\">void</span>**)param, <span class=\"built_in\">queue</span>, <span class=\"literal\">nullptr</span>);</span><br><span class=\"line\">    cnrtSyncQueue(<span class=\"built_in\">queue</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    cnrtMemcpy(output_half, mlu_output, <span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span> * <span class=\"keyword\">sizeof</span>(half), CNRT_MEM_TRANS_DIR_DEV2HOST);</span><br><span class=\"line\">    </span><br><span class=\"line\">    cnrtConvertHalfToFloatArray(output_data, output_half, <span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span>);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>;i&lt;t;i++)</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">0</span>;j&lt;<span class=\"number\">3</span>;j++)</span><br><span class=\"line\">            DataT-&gt;output_data[t*j+i] = output_data[i*<span class=\"number\">3</span>+j];</span><br><span class=\"line\">    cnrtFree(mlu_input);</span><br><span class=\"line\">    cnrtFree(mlu_output);</span><br><span class=\"line\">    cnrtDestroyQueue(<span class=\"built_in\">queue</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    cnrtDestroy();</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(input_half);</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(output_half);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"结束语\"><a href=\"#结束语\" class=\"headerlink\" title=\"结束语\"></a>结束语</h2><p>在这门课程中，<del>我根据报错找 bug 的能力确实有了很大的提高</del>，虽然体验不是很好，但是自己完成了之后还是挺有成就感的，如果您对于此篇文章有好的提议，或者对于这个实验还有其他的问题，可以向 $wz1234@buaa.edu.cn$ 发送邮件，也欢迎以其他方式和我交流</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"智能计算机实验\"><a href=\"#智能计算机实验\" class=\"headerlink\" title=\"智能计算机实验\"></a>智能计算机实验</h1><h2 id=\"我对于此课程实验的看法\"><a href=\"#我对于此课程实验的看法\" class=\"headerlink\" title=\"我对于此课程实验的看法\"></a>我对于此课程实验的看法</h2><p>关于此实验的指导比较少，主要来源就是寒武纪论坛和一些大体的指导，没有详细的介绍，而这门实验的测试是在服务器上进行的，坑比较多，因此可能会耗费比较多的时间（除非你直接补充那七个文件而且不用在服务器上测试，平台提交直接AC）</p>\n<p>这篇文章的主要目的是提供一个比较详细的实验完成方法，并且减少大家在完成实验过程中踩的坑，但是不会提供具体的代码</p>\n<p><strong>注意</strong>：如果你想快速顺利的完成此实验，可以观看这篇文章</p>\n<p>​         如果你想锻炼自己根据报错找 bug 的能力或者根据报错自学 tensorflow 的能力，可以先选择自己完成实验，如果实在是感到      困难，可以再来观看这篇文章</p>","more":"<h2 id=\"实验一\"><a href=\"#实验一\" class=\"headerlink\" title=\"实验一\"></a>实验一</h2><p>(听说不用快速幂和多核拆分就能过，哭了)</p>\n<ol>\n<li>进入 /opt   将压缩包解压</li>\n<li>进入 /opt/AICSE-demo-student/env  执行 source env.sh</li>\n<li>cd tensorflow-v1.10   执行 source env.sh   然后激活虚拟环境</li>\n</ol>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221161604172.png\" alt=\"image-20201221161604172\"></p>\n<ol>\n<li>以上两步非常重要，在每一次进入服务器之后都要执行，否则会在执行脚本或编译的时候出现奇怪的错误</li>\n<li><p>进入 /opt/AICSE-demo-student/demo/style_transfer_bcl/src/bangc/PluginPowerDifferenceOp ，开始进行代码的补充，我建议的顺序如下：</p>\n<ul>\n<li>plugin_power_difference_kernel.mlu </li>\n<li>plugin_power_difference_kernel.h</li>\n<li>powerDiff.cpp</li>\n<li>plugin_power_difference_op.cc</li>\n<li>cnplugin.h</li>\n</ul>\n</li>\n<li><p>在 .mlu 中进行 PowerDifference 算子的实现，这个部分比较简单，需要注意的地方为 GDRAM 和 NRAM 之间的转换，我的理解就是参数中的变量都是 GDRAM，你在函数中创建的 <code>__nram__ half</code> 变量都是 NRAM，而你的实现大概能分为三个阶段：</p>\n<ul>\n<li>初级阶段，实现了基本的算子功能，能得到60分</li>\n<li>中级阶段，用快速幂进行实现，能够小幅降低在 CNRT 上的延时，能得到70分（不过不用快速幂可能也行</li>\n<li>高级阶段，实现多核拆分计算，能够同时在多个核上进行运算，能得到100分（bushi</li>\n</ul>\n<p>此部分需要用到一些 bangc 的内置函数，使用其中的三个函数就能实现此算子：</p>\n<ul>\n<li><p>__memcpy (目标地址，源地址，长度，RAM类型转换)     功能为将源地址之后一定长度的数据拷贝到目标地址</p>\n<p>一个栗子：<code>__memcpy(input1_nram+i*Seg, input1+i*Seg, Seg*sizeof(half), GDRAM2NRAM);</code></p>\n</li>\n<li><p>__bang_sub (目标地址，被减数，减数，长度)     功能为进行一定长度的向量减法，结果储存在目标地址</p>\n<p>一个栗子：<code>__bang_sub(input1_nram+i*Seg, input1_nram+i*Seg, input2_nram+i*Seg, Seg);</code></p>\n</li>\n<li><p>__bang_mul     与上面类似，只不过进行的是乘法</p>\n</li>\n</ul>\n<p>关于函数的具体使用以及更多的函数介绍，可以参考 bangc 的开发指导书</p>\n<p>噢，忘说了，函数的参数大致是这样：<code>__mlu_entry__ void PowerDifferenceKernel(half* input1, half* input2, int pow, half* output, int len)</code></p>\n</li>\n<li><p>补全 plugin_power_difference_kernel.h，非常简单，只要和 .mlu 中的函数参数一致即可</p>\n</li>\n<li><p>补全 powerDiff.cpp，这部分若要自己写可能比较困难，我的建议是参照本来就有的其他算子的实现来完成，需要注意的是将其中的 *Kernel 改成自己的 PowerDifferenceKernel，当然还可能有其他的都需要改成 PowerDifference 对应的格式，在参照其他算子完成补全后，需要注意的是，如果你想使用多核拆分的话，还要修改两个地方：</p>\n<ul>\n<li>将 dim.x = 1 改为 dim.x = 8</li>\n<li>将 cnrtFunctionType_t c 改为 CNRT_FUNC_TYPE_UNION2</li>\n</ul>\n</li>\n<li><p>补全 plugin_power_difference_op.cc，这个比较难搞，即使参照其他算子，也比较烦人，我对于此部分的建议是选择的参照算子的实现可以选择简单的，并且不要思考的太过于复杂（</p>\n</li>\n<li><p>补全 cnplugin.h，参照上面的实现，定义 PowerDifference 对应的结构，结构指针以及 plugin_power_difference_op.cc 中函数的声明</p>\n</li>\n<li><p>在补全了以上文件之后，就可以进行算子的测试啦，在 xxx/src/bangc/PluginPowerDifferenceOp 中执行以下两句：</p>\n<ul>\n<li>bash make.sh</li>\n<li>./power_diff_test</li>\n</ul>\n<p>就可以看到测试结果，正确的测试结果大致如下：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221170316556.png\" alt=\"image-20201221170316556\"></p>\n</li>\n<li><p>如果你的运行结果和上图差不多，说明你前面的实现已经差不多完成啦，接下来就要进行 cnplugin 的集成，步骤如下：</p>\n<ul>\n<li><p>将 cnplugin.h 复制到下面两个目录中：</p>\n<p>/opt/AICSE-demo-student/env/neuware/include/</p>\n<p>/opt/AICSE-demo-student/env/Cambricon-CNPlugin-MLU270/common/include/</p>\n</li>\n<li><p>在 /opt/AICSE-demo-student/env/Cambricon-CNPlugin-MLU270 处执行 bash build_cnplugin.sh —mlu200，如果编译的最后显示 build success，说明你编译成功，会在 ./build 文件夹中生成新的 libcnplugin.so</p>\n</li>\n<li><p>将新生成的 libcnplugin.so 复制到 /opt/AICSE-demo-student/env/neuware/lib64/ 文件夹下</p>\n</li>\n</ul>\n</li>\n<li><p>很快啊，cnplugin 的集成就完成了，接下来要进行的就是 TensorFlow 算子集成，此部分首先需要按照 /opt/AICSE-demo-student/demo/style_transfer_bcl/src/tf-implementation/tf-add-power-diff/readme.txt  即下图：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221171419046.png\" alt=\"image-20201221171419046\"></p>\n<p>将此文件夹下的其他文件复制到 readme.txt 里对应的文件夹中，在进行这一步时请务必仔细，否则在稍后编译时可能会产生各种各样奇怪的 bug，在复制完成后，如果你直接在 /opt/AICSE-demo-student/env/tensorflow-v1.10 中执行 bash build_tensorflow-v1.10_mlu.sh，有 99.9% 的可能会出现以下的错误：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221171900968.png\" alt=\"image-20201221171900968\"></p>\n<p>根据错误信息可以看出来，实验提供的 mlu_lib_ops.cc 和你补充的 plugin_power_difference_op.cc  中 ，cnmlCreatePluginPowerDifferenceOp 以及 cnmlComputePluginPowerDifferenceOpForward 的参数不同，你需要选择修改其中之一来保证两个文件中的参数一致，我的建议是修改实验提供的 mlu_lib_ops.cc，因为修改起来比较简单，并且在其中你可以使用 nullptr 来填充参数，，下面是我的实现以供参考：</p>\n<p>mlu_lib_ops.cc 中对于 plugin_power_difference_op的调用：<br><img src=\"/2020/12/21/智能计算机/image-20201222121105346.png\" alt=\"image-20201222121105346\"><br>plugin_power_difference_op.cc 中 plugin_power_difference_op 的参数：<br><img src=\"/2020/12/21/智能计算机/image-20201222121110969.png\" alt=\"image-20201222121110969\"><br>mlu_lib_ops.cc 中对于 cnmlComputePluginPowerDifferenceOpForward的调用：<br><img src=\"/2020/12/21/智能计算机/image-20201222121125219.png\" alt=\"image-20201222121125219\"><br>plugin_power_difference_op.cc 中 cnmlComputePluginPowerDifferenceOpForward 的参数：<br><img src=\"/2020/12/21/智能计算机/image-20201222121129289.png\" alt=\"image-20201222121129289\"></p>\n<p>若在完成这一步之后，你的编译出现socket错误，就要将 .sh 文件中的 job_num 改为 16 ，你应该就可以成功的进行 tensorflow的编译啦（可能需要较长的时间</p>\n</li>\n<li><p>最后就是补全 …/src/online_mlu/power_difference_test_bcl.py 和 …/src/online_cpu/power_difference_test_cpu.py 文件 ， 执行 python power_difference_test_xxx.py 进行测试，这两个文件的补全比较简单，并且是基本一样的，只是在 test_bcl 中有一个特殊的地方要修改，因此我的建议是先进行 cpu 的测试，成功的测试结果如下图：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221173107160.png\" alt=\"image-20201221173107160\"></p>\n<p>而当你将补全的地方复制到 test_mlu.py 中，进行测试，你会得到以下结果：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221173352870.png\" alt=\"image-20201221173352870\"></p>\n<p>我在开始的时候将代码中的   os.environ[‘MLU_VISIBLE_DEVICES’] = “0”   改为 os.environ[‘MLU_VISIBLE_DEVICES’] = “1” ，然后再次测试：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221173555856.png\" alt=\"image-20201221173555856\"></p>\n<p>虽然错误率看上去比较高，但是交上去的话可以过。不过这种改的方法应该是不正确的, 而且在实验二中这个问题会同样出现但是无法解决， 出现这种情况的原因应该是在多核拆分的循环的最后一次中数据的长度不足 Seg，因此我们需要将最后的一次单独提取出来做计算，之后的结果是这样的：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20200118.png\" alt=\"image-20200118\"></p>\n<p>可以看到错误率比之前低了很多</p>\n</li>\n<li><p>最后，如果你使用了快速幂，多核拆分，但是在 MLU 上仍然有着 100+ ms 的延迟，那么你需要在 test_bcl.py 中进行如下修改：</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201221173834863.png\" alt=\"image-20201221173834863\"></p>\n<p>因为 MLU 的启动时间比较慢，所以可以多次运行来获得更低的延迟，如果这样你还不能拿到满分，请多提交几次</p>\n</li>\n<li><p>补充：如果你提交到平台上的结果为 JSON 格式错误，说明你代码写错了，请确保你在如上测试中都成功的运行出了正确的结果，如果你在实验的完成过程中出现了其他错误，请看一下自己是不是漏了某个步骤，或者某个步骤做的不够仔细，如果还是不行的话，请前往和助教对线或者在群里请求帮助，此外，请务必不要重启你的服务器，<del>否则就会像我一样丢掉所有数据然后重新配一遍</del></p>\n</li>\n</ol>\n<h2 id=\"实验一选作（四选一）—-softmax-算子实现\"><a href=\"#实验一选作（四选一）—-softmax-算子实现\" class=\"headerlink\" title=\"实验一选作（四选一）— softmax 算子实现\"></a>实验一选作（四选一）— softmax 算子实现</h2><h3 id=\"softmax-算子介绍\"><a href=\"#softmax-算子介绍\" class=\"headerlink\" title=\"softmax 算子介绍\"></a>softmax 算子介绍</h3><p><img src=\"/2020/12/21/智能计算机/image-20201222014249959.png\" alt=\"image-20201222014249959\"></p>\n<h3 id=\"算子实现\"><a href=\"#算子实现\" class=\"headerlink\" title=\"算子实现\"></a>算子实现</h3><p>因为输入数据的规模为 20 × 256，共 20 行，256 列，我们首先要找出每一列的最大值，方法为每次接受一行的数据，对于每一列来说，如果新输入的数据大于最大值，就更新，否则不变，然后将每一列的所有数减去这个最大值，求出 e 关于这个数的指数，再全部加起来，然后取一个倒数，然后对于每一列的每一个数，乘以之前计算出来的倒数，这样计算出来的结果即为正确结果</p>\n<h3 id=\"具体代码\"><a href=\"#具体代码\" class=\"headerlink\" title=\"具体代码\"></a>具体代码</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"mlu.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> input_size 20     # 列数</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> input_num  256    # 行数</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> LEN  256*20</span></span><br><span class=\"line\">__<span class=\"function\">mlu_entry__ <span class=\"keyword\">void</span> <span class=\"title\">SoftmaxKernel</span><span class=\"params\">(half* input, half* output)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;  </span><br><span class=\"line\">   __nram__ half input_nram[input_num];</span><br><span class=\"line\">   __nram__ half output_nram[LEN];</span><br><span class=\"line\">   __nram__ half temp1_nram[input_num];</span><br><span class=\"line\">   __nram__ half temp2_nram[input_num];</span><br><span class=\"line\">   __nram__ half comL_nram[input_num];</span><br><span class=\"line\">   __nram__ half sum_nram[input_num];</span><br><span class=\"line\">   __nram__ half sum_recip_nram[input_num];</span><br><span class=\"line\">   __nram__ half mulL_nram[input_num];</span><br><span class=\"line\">   __nram__ half mulR_nram[input_num];</span><br><span class=\"line\">   __nramset_half(comL_nram, input_num, <span class=\"number\">-3000.0</span>);</span><br><span class=\"line\">   __nramset_half(sum_nram, input_num,<span class=\"number\">0.0</span>);</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"keyword\">for</span>(<span class=\"keyword\">int32_t</span> i=<span class=\"number\">0</span>; i&lt;input_size;i++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">       __memcpy(input_nram, input+i*input_num, input_num*<span class=\"keyword\">sizeof</span>(half),GDRAM2NRAM);  # 分别获取每行的输入数据</span><br><span class=\"line\">       __bang_gt(temp1_nram,comL_nram,input_nram,input_num);   # 若输入值小于最大值，则对应位置为<span class=\"number\">1</span></span><br><span class=\"line\">       __bang_not(temp2_nram,temp1_nram,input_num);            # 若输入值大于最大值，则对应位置为<span class=\"number\">1</span></span><br><span class=\"line\">       __bang_mul(mulL_nram,temp1_nram,comL_nram,input_num);   # 最大值不变的位置，置最大值</span><br><span class=\"line\">       __bang_mul(mulR_nram,temp2_nram,input_nram,input_num);  # 最大值改变的位置，置输入值</span><br><span class=\"line\">       __bang_add(comL_nram,mulL_nram,mulR_nram,input_num);    # 相加得到每列新的最大值</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">for</span>(<span class=\"keyword\">int32_t</span> i=<span class=\"number\">0</span>; i&lt;input_size;i++)</span><br><span class=\"line\">     &#123;</span><br><span class=\"line\">       __memcpy(input_nram, input+i*input_num, input_num*<span class=\"keyword\">sizeof</span>(half),GDRAM2NRAM);  # 分别获取每行的输入数据</span><br><span class=\"line\">       __bang_sub(temp1_nram,input_nram,comL_nram,input_num);  # 每一列减去该列最大值</span><br><span class=\"line\">       __bang_active_exp(temp2_nram,temp1_nram,input_num);     # 求 e 关于 j-max 的指数</span><br><span class=\"line\">       __bang_add(sum_nram,sum_nram,temp2_nram,input_num);     # 将所有的指数相加得到分母</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\">    __bang_active_recip(sum_recip_nram,sum_nram,input_num);    # 求出分母的倒数</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">for</span>(<span class=\"keyword\">int32_t</span> i=<span class=\"number\">0</span>; i&lt;input_size;i++)</span><br><span class=\"line\">       &#123;</span><br><span class=\"line\">         __memcpy(input_nram, input+i*input_num, input_num*<span class=\"keyword\">sizeof</span>(half),GDRAM2NRAM);  # 分别获取每行的输入数据</span><br><span class=\"line\">        __bang_sub(temp1_nram,input_nram,comL_nram,input_num);         # 每一列减去该列最大值</span><br><span class=\"line\">        __bang_active_exp(temp2_nram,temp1_nram,input_num);            # 求 e 关于 i-max 的指数，即分子</span><br><span class=\"line\">        __bang_mul(temp2_nram,temp2_nram,sum_recip_nram,input_num);    # 将分子和分母的倒数相乘，得到结果</span><br><span class=\"line\">        __memcpy(output+i*input_num,temp2_nram,input_num*<span class=\"keyword\">sizeof</span>(half),NRAM2GDRAM);  # 将结果返回到输出中</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"实验总结\"><a href=\"#实验总结\" class=\"headerlink\" title=\"实验总结\"></a>实验总结</h3><p>该实验对于 softmax 算子进行实现，难点在于如何灵活的运用 bangc 提供的各种函数对于数据进行操作和计算，只要按照 softmax 的定义对式子一步一步的计算，并合理的运用 bangc 提供的函数，就可以比较简单的实现 softmax 算子，在这个过程中，bangc 的教学文档起到了很大的作用，文档对于各种各样的函数做出了详细的解释与注意事项，可以对算子实现起到很大的帮助</p>\n<h2 id=\"实验二\"><a href=\"#实验二\" class=\"headerlink\" title=\"实验二\"></a>实验二</h2><h3 id=\"模型量化\"><a href=\"#模型量化\" class=\"headerlink\" title=\"模型量化\"></a>模型量化</h3><p>该部分代码和量化手段已经提前给出，直接按照<a href=\"http://forum.cambricon.com/uploadfile/user/file/20200714/1594717975554836.pdf\" target=\"_blank\" rel=\"noopener\">教程</a>即可完成。</p>\n<h3 id=\"在线推理\"><a href=\"#在线推理\" class=\"headerlink\" title=\"在线推理\"></a>在线推理</h3><p>在线推理部分主要分为两块，分别需要补全</p>\n<p>/opt/AICSE-demo-student/demo/style_transfer_bcl/src/online_mlu/transform_mlu.py 和</p>\n<p>/opt/AICSE-demo-student/demo/style_transfer_bcl/src/online_cpu/transform_cpu.py</p>\n<h4 id=\"online-cpu\"><a href=\"#online-cpu\" class=\"headerlink\" title=\"online_cpu\"></a>online_cpu</h4><p>在cpu部分里，使用到的模型是非量化后的模型文件。</p>\n<p>该部分需要补全两个函数run_ori_power_diff_pb和run_numpy_pb</p>\n<ul>\n<li><p><strong>run_ori_power_diff_pb</strong> ：直接按照同文件下的run_ori_pb逻辑进行书写，但是要注意该函数使用的计算图与run_ori_pb不同点在于将原生的差平方计算算子改成了实验一中集成的power_difference算子，所以只需要我们进行feed数据（<strong>不需要</strong>重新实现power_difference的计算），将pow值传递至计算图计算。而其在<strong>计算图中的各节点信息可使用<a href=\"https://lutzroeder.github.io/netron/\" target=\"_blank\" rel=\"noopener\">神经网络模型可视化网站</a>进行查找</strong>。</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201222004846500.png\" alt=\"image-20201222004846500\"></p>\n<p>从图中可以看出除了 X 还额外需要 feed 一个数据，即 PowerDifference_z，给它赋值为2即可，相当于将pow = 2 传递给了计算图</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201222004912384.png\" alt=\"image-20201222004912384\"></p>\n</li>\n<li><p><strong>run_numpy_pb</strong>：与上一个类似，只不过这里需要我们手动将原生的差平方计算算子的输入数据提出并使用实验一中的power_diff_numpy.py的内置函数进行计算后，再传回计算图进行计算。<strong>需要注意</strong>该函数的输入参数跟上一个run_ori_power_diff_pb的计算图一样的参数，因为这里要手动算，所以在可视化的计算图上可以发现这里断开了。</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201222004933612.png\" alt=\"image-20201222004933612\"></p>\n<p>上面这张图是使用原生的差平方计算算子的模型，可以看到SquaredDifference算子的输入分别为Conv2D_13和 moments_15/StopGradient</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201222004952263.png\" alt=\"image-20201222004952263\"></p>\n<p>可以看到这个模型的 Conv2D_13和 moments_15/StopGradient 并没有参与到算子的计算中，所以我们要把这两个节点的数据提取出来，再加上一个 pow 值为 2，作为 power_diff_numpy 的三个参数计算出 PowerDifference 算子的输出结果，此处需要注意的是从计算图中提取出来的 Tensor 不能直接进行 reshape，否则会报错，所以我们要通过 eval() 将其转换为数组，并且要向 eval() feed 一个数据 X</p>\n<p><img src=\"/2020/12/21/智能计算机/image-20201222005007770.png\" alt=\"image-20201222005007770\"></p>\n</li>\n<li><p>全部代码</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">from</span> tensorflow.python.platform <span class=\"keyword\">import</span> gfile</span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2 <span class=\"keyword\">as</span> cv</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">from</span> power_diff_numpy <span class=\"keyword\">import</span> *</span><br><span class=\"line\"></span><br><span class=\"line\">os.putenv(<span class=\"string\">'MLU_VISIBLE_DEVICES'</span>,<span class=\"string\">''</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse_arg</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    parser = argparse.ArgumentParser()</span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">'image'</span>)</span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">'ori_pb'</span>)</span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">'ori_power_diff_pb'</span>)</span><br><span class=\"line\">    parser.add_argument(<span class=\"string\">'numpy_pb'</span>)</span><br><span class=\"line\">    args = parser.parse_args()</span><br><span class=\"line\">    <span class=\"keyword\">return</span> args</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run_ori_pb</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    args = parse_arg()</span><br><span class=\"line\">    config = tf.ConfigProto(allow_soft_placement=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                inter_op_parallelism_threads=<span class=\"number\">1</span>,</span><br><span class=\"line\">                            intra_op_parallelism_threads=<span class=\"number\">1</span>)</span><br><span class=\"line\">    model_name = os.path.basename(args.ori_pb).split(<span class=\"string\">\".\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    image_name = os.path.basename(args.image).split(<span class=\"string\">\".\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    g = tf.Graph()</span><br><span class=\"line\">    <span class=\"keyword\">with</span> g.as_default():</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.gfile.FastGFile(args.ori_pb,<span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            graph_def = tf.GraphDef()</span><br><span class=\"line\">            graph_def.ParseFromString(f.read())</span><br><span class=\"line\">            tf.import_graph_def(graph_def, name=<span class=\"string\">''</span>)</span><br><span class=\"line\">        img = cv.imread(args.image)</span><br><span class=\"line\">        X = cv.resize(img, (<span class=\"number\">256</span>, <span class=\"number\">256</span>))</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.Session(config=config) <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">            sess.graph.as_default()</span><br><span class=\"line\">            sess.run(tf.global_variables_initializer())</span><br><span class=\"line\"></span><br><span class=\"line\">            input_tensor = sess.graph.get_tensor_by_name(<span class=\"string\">'X_content:0'</span>)</span><br><span class=\"line\">            output_tensor = sess.graph.get_tensor_by_name(<span class=\"string\">'add_37:0'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            start_time = time.time()</span><br><span class=\"line\">            ret =sess.run(output_tensor, feed_dict=&#123;input_tensor:[X]&#125;)</span><br><span class=\"line\">            end_time = time.time()</span><br><span class=\"line\">            print(<span class=\"string\">\"C++ inference(CPU) origin pb time is: \"</span>,end_time-start_time)</span><br><span class=\"line\">            img1 = tf.reshape(ret,[<span class=\"number\">256</span>,<span class=\"number\">256</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\">            img_numpy = img1.eval(session=sess)</span><br><span class=\"line\">            cv.imwrite(image_name + <span class=\"string\">'_'</span> + model_name + <span class=\"string\">'_cpu.jpg'</span>,img_numpy)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run_ori_power_diff_pb</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    args = parse_arg()</span><br><span class=\"line\">    config = tf.ConfigProto(allow_soft_placement=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                inter_op_parallelism_threads=<span class=\"number\">1</span>,</span><br><span class=\"line\">                            intra_op_parallelism_threads=<span class=\"number\">1</span>)</span><br><span class=\"line\">    model_name = os.path.basename(args.ori_power_diff_pb).split(<span class=\"string\">\".\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    image_name = os.path.basename(args.image).split(<span class=\"string\">\".\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    g = tf.Graph()</span><br><span class=\"line\">    <span class=\"keyword\">with</span> g.as_default():</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.gfile.FastGFile(args.ori_power_diff_pb,<span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            graph_def = tf.GraphDef()</span><br><span class=\"line\">            graph_def.ParseFromString(f.read())</span><br><span class=\"line\">            tf.import_graph_def(graph_def, name=<span class=\"string\">''</span>)</span><br><span class=\"line\">        img = cv.imread(args.image)</span><br><span class=\"line\">        X = cv.resize(img, (<span class=\"number\">256</span>, <span class=\"number\">256</span>))</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.Session(config=config) <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">            sess.graph.as_default()</span><br><span class=\"line\">            sess.run(tf.global_variables_initializer())</span><br><span class=\"line\"></span><br><span class=\"line\">            input_tensor1 = sess.graph.get_tensor_by_name(<span class=\"string\">'X_content:0'</span>)</span><br><span class=\"line\">            input_tensor2 = sess.graph.get_tensor_by_name(<span class=\"string\">'moments_15/PowerDifference_z:0'</span>)</span><br><span class=\"line\">            output_tensor = sess.graph.get_tensor_by_name(<span class=\"string\">'add_37:0'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            start_time = time.time()</span><br><span class=\"line\">            ret =sess.run(output_tensor, feed_dict=&#123;input_tensor1:[X], input_tensor2:<span class=\"number\">2</span>&#125;)</span><br><span class=\"line\">            end_time = time.time()</span><br><span class=\"line\">            print(<span class=\"string\">\"C++ inference(CPU) time is: \"</span>,end_time-start_time)</span><br><span class=\"line\">            img1 = tf.reshape(ret,[<span class=\"number\">256</span>,<span class=\"number\">256</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\">            img_numpy = img1.eval(session=sess)</span><br><span class=\"line\">            cv.imwrite(image_name + <span class=\"string\">'_'</span> + model_name + <span class=\"string\">'_cpu.jpg'</span>,img_numpy)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">run_numpy_pb</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    args = parse_arg()</span><br><span class=\"line\">    config = tf.ConfigProto(allow_soft_placement=<span class=\"literal\">True</span>,</span><br><span class=\"line\">                inter_op_parallelism_threads=<span class=\"number\">1</span>,</span><br><span class=\"line\">                            intra_op_parallelism_threads=<span class=\"number\">1</span>)</span><br><span class=\"line\">    model_name = os.path.basename(args.numpy_pb).split(<span class=\"string\">\".\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\">    image_name = os.path.basename(args.image).split(<span class=\"string\">\".\"</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    g = tf.Graph()</span><br><span class=\"line\">    <span class=\"keyword\">with</span> g.as_default():</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.gfile.FastGFile(args.numpy_pb,<span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            graph_def = tf.GraphDef()</span><br><span class=\"line\">            graph_def.ParseFromString(f.read())</span><br><span class=\"line\">            tf.import_graph_def(graph_def, name=<span class=\"string\">''</span>)</span><br><span class=\"line\">        img = cv.imread(args.image)</span><br><span class=\"line\">        X = cv.resize(img, (<span class=\"number\">256</span>, <span class=\"number\">256</span>))</span><br><span class=\"line\">        <span class=\"keyword\">with</span> tf.Session(config=config) <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">            sess.graph.as_default()</span><br><span class=\"line\">            sess.run(tf.global_variables_initializer())</span><br><span class=\"line\"></span><br><span class=\"line\">            input_tensor1 = sess.graph.get_tensor_by_name(<span class=\"string\">'X_content:0'</span>)</span><br><span class=\"line\">            input_tensor2 = sess.graph.get_tensor_by_name(<span class=\"string\">'moments_15/PowerDifference:0'</span>)</span><br><span class=\"line\">            output_tensor = sess.graph.get_tensor_by_name(<span class=\"string\">'add_37:0'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">            start_time = time.time()</span><br><span class=\"line\">            input_2 = power_diff_numpy(sess.graph.get_tensor_by_name(<span class=\"string\">'Conv2D_13:0'</span>).eval(feed_dict=&#123;input_tensor1:[X]&#125;),sess.graph.get_tensor_by_name(<span class=\"string\">'moments_15/StopGradient:0'</span>).eval(feed_dict=&#123;input_tensor1:[X]&#125;),<span class=\"number\">2</span>)</span><br><span class=\"line\">            ret =sess.run(output_tensor, feed_dict=&#123;input_tensor1:[X], input_tensor2:input_2&#125;)</span><br><span class=\"line\">            end_time = time.time()</span><br><span class=\"line\">            print(<span class=\"string\">\"Numpy inference(CPU) time is: \"</span>,end_time-start_time)</span><br><span class=\"line\">            img1 = tf.reshape(ret,[<span class=\"number\">256</span>,<span class=\"number\">256</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\">            img_numpy = img1.eval(session=sess)</span><br><span class=\"line\">            cv.imwrite(image_name + <span class=\"string\">'_'</span> + model_name + <span class=\"string\">'_cpu.jpg'</span>,img_numpy)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    run_ori_pb()</span><br><span class=\"line\">    run_ori_power_diff_pb()</span><br><span class=\"line\">    run_numpy_pb()</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"online-mlu\"><a href=\"#online-mlu\" class=\"headerlink\" title=\"online_mlu\"></a>online_mlu</h4><p>在mlu部分，使用到的模型是量化后的模型文件。</p>\n<p>仅仅需要在每个函数前加上</p>\n<p><code>config.mlu_options.save_offline_model = True</code></p>\n<p>这句话用于保存量化后可用于mlu的离线模型，其余部分均与cpu相同</p>\n<h3 id=\"离线推理\"><a href=\"#离线推理\" class=\"headerlink\" title=\"离线推理\"></a>离线推理</h3><p><del>令人惊讶的是，当我写完了在线推理之后，提交了一手发现居然拿了满分，于是我还没有写离线推理</del></p>\n<p>代码：</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"inference.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"cnrt.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"stdlib.h\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sys/time.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;time.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">namespace</span> StyleTransfer&#123;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">unsigned</span> <span class=\"keyword\">short</span> half;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">cnrtConvertFloatToHalfArray</span><span class=\"params\">(<span class=\"keyword\">uint16_t</span>* x, <span class=\"keyword\">const</span> <span class=\"keyword\">float</span>* y, <span class=\"keyword\">int</span> len)</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)&#123;</span><br><span class=\"line\">    cnrtConvertFloatToHalf(x+i,y[i]);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">cnrtConvertHalfToFloatArray</span><span class=\"params\">(<span class=\"keyword\">float</span>* x, <span class=\"keyword\">const</span> <span class=\"keyword\">uint16_t</span>* y, <span class=\"keyword\">int</span> len)</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)&#123;</span><br><span class=\"line\">    cnrtConvertHalfToFloat(x+i,y[i]);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">cnrtConvertFloatToHalfArray</span><span class=\"params\">(<span class=\"keyword\">uint16_t</span>* x, <span class=\"keyword\">float</span>* y, <span class=\"keyword\">int</span> len)</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)&#123;</span><br><span class=\"line\">    cnrtConvertFloatToHalf(x+i,y[i]);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">cnrtConvertHalfToFloatArray</span><span class=\"params\">(<span class=\"keyword\">float</span>* x, <span class=\"keyword\">uint16_t</span>* y, <span class=\"keyword\">int</span> len)</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; len; i++)&#123;</span><br><span class=\"line\">    cnrtConvertHalfToFloat(x+i,y[i]);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">Inference :: Inference(<span class=\"built_in\">std</span>::<span class=\"built_in\">string</span> offline_model)&#123;</span><br><span class=\"line\">    offline_model_ = offline_model;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">void</span> Inference :: run(DataTransfer* DataT)&#123;</span><br><span class=\"line\">    cnrtInit(<span class=\"number\">0</span>);</span><br><span class=\"line\">    cnrtModel_t model;</span><br><span class=\"line\">    cnrtLoadModel(&amp;model, offline_model_.c_str());</span><br><span class=\"line\"></span><br><span class=\"line\">    cnrtDev_t dev;</span><br><span class=\"line\">    cnrtGetDeviceHandle(&amp;dev, <span class=\"number\">0</span>);</span><br><span class=\"line\">    cnrtSetCurrentDevice(dev);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">float</span>* input_data = <span class=\"keyword\">reinterpret_cast</span>&lt;<span class=\"keyword\">float</span>*&gt;(<span class=\"built_in\">malloc</span>(<span class=\"number\">256</span>*<span class=\"number\">256</span>*<span class=\"number\">3</span>*<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>)));</span><br><span class=\"line\">    <span class=\"keyword\">float</span>* output_data = <span class=\"keyword\">reinterpret_cast</span>&lt;<span class=\"keyword\">float</span>*&gt;(<span class=\"built_in\">malloc</span>(<span class=\"number\">256</span>*<span class=\"number\">256</span>*<span class=\"number\">3</span>*<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>)));</span><br><span class=\"line\">    <span class=\"keyword\">int</span> t = <span class=\"number\">256</span>*<span class=\"number\">256</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>;i&lt;t;i++)</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">0</span>;j&lt;<span class=\"number\">3</span>;j++)</span><br><span class=\"line\">            input_data[i*<span class=\"number\">3</span>+j] = DataT-&gt;input_data[t*j+i]; </span><br><span class=\"line\">    <span class=\"keyword\">int</span> number = <span class=\"number\">0</span>;</span><br><span class=\"line\">    cnrtGetFunctionNumber(model, &amp;number);</span><br><span class=\"line\"></span><br><span class=\"line\">    cnrtFunction_t function;</span><br><span class=\"line\">    cnrtCreateFunction(&amp;function);</span><br><span class=\"line\">    cnrtExtractFunction(&amp;function, model, <span class=\"string\">\"subnet0\"</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">int</span> inputNum, outputNum;</span><br><span class=\"line\">    <span class=\"keyword\">int64_t</span> *inputSizeS, *outputSizeS;</span><br><span class=\"line\">    cnrtGetInputDataSize(&amp;inputSizeS, &amp;inputNum, function);</span><br><span class=\"line\">    cnrtGetOutputDataSize(&amp;outputSizeS, &amp;outputNum, function);</span><br><span class=\"line\"></span><br><span class=\"line\">    DataT-&gt;output_data = <span class=\"keyword\">reinterpret_cast</span>&lt;<span class=\"keyword\">float</span>*&gt;(<span class=\"built_in\">malloc</span>(<span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span> * <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>)));</span><br><span class=\"line\">    half* input_half = (half*)<span class=\"built_in\">malloc</span>(<span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span> * <span class=\"keyword\">sizeof</span>(half));</span><br><span class=\"line\">    half* output_half = (half*)<span class=\"built_in\">malloc</span>(<span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span> * <span class=\"keyword\">sizeof</span>(half));</span><br><span class=\"line\">  </span><br><span class=\"line\">    cnrtConvertFloatToHalfArray(input_half, input_data, <span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span>);</span><br><span class=\"line\">    cnrtConvertFloatToHalfArray(output_half, DataT-&gt;output_data, <span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span>);</span><br><span class=\"line\">  </span><br><span class=\"line\">  </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">void</span> *mlu_input, *mlu_output;</span><br><span class=\"line\">    cnrtMalloc(&amp;(mlu_input), inputSizeS[<span class=\"number\">0</span>]);</span><br><span class=\"line\">    cnrtMalloc(&amp;(mlu_output), outputSizeS[<span class=\"number\">0</span>]);</span><br><span class=\"line\">    cnrtMemcpy(mlu_input, input_half, <span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span> * <span class=\"keyword\">sizeof</span>(half), CNRT_MEM_TRANS_DIR_HOST2DEV);</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">    cnrtRuntimeContext_t ctx;</span><br><span class=\"line\">    cnrtCreateRuntimeContext(&amp;ctx, function, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    cnrtSetRuntimeContextDeviceId(ctx, <span class=\"number\">0</span>);</span><br><span class=\"line\">    cnrtInitRuntimeContext(ctx, <span class=\"literal\">NULL</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">void</span> *param[<span class=\"number\">2</span>];</span><br><span class=\"line\">    param[<span class=\"number\">0</span>] = mlu_input;</span><br><span class=\"line\">    param[<span class=\"number\">1</span>] = mlu_output;</span><br><span class=\"line\">    cnrtQueue_t <span class=\"built_in\">queue</span>;</span><br><span class=\"line\">    cnrtRuntimeContextCreateQueue(ctx, &amp;<span class=\"built_in\">queue</span>);</span><br><span class=\"line\">    cnrtInvokeRuntimeContext(ctx, (<span class=\"keyword\">void</span>**)param, <span class=\"built_in\">queue</span>, <span class=\"literal\">nullptr</span>);</span><br><span class=\"line\">    cnrtSyncQueue(<span class=\"built_in\">queue</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    cnrtMemcpy(output_half, mlu_output, <span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span> * <span class=\"keyword\">sizeof</span>(half), CNRT_MEM_TRANS_DIR_DEV2HOST);</span><br><span class=\"line\">    </span><br><span class=\"line\">    cnrtConvertHalfToFloatArray(output_data, output_half, <span class=\"number\">256</span> * <span class=\"number\">256</span> * <span class=\"number\">3</span>);</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> i=<span class=\"number\">0</span>;i&lt;t;i++)</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> j=<span class=\"number\">0</span>;j&lt;<span class=\"number\">3</span>;j++)</span><br><span class=\"line\">            DataT-&gt;output_data[t*j+i] = output_data[i*<span class=\"number\">3</span>+j];</span><br><span class=\"line\">    cnrtFree(mlu_input);</span><br><span class=\"line\">    cnrtFree(mlu_output);</span><br><span class=\"line\">    cnrtDestroyQueue(<span class=\"built_in\">queue</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    cnrtDestroy();</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(input_half);</span><br><span class=\"line\">    <span class=\"built_in\">free</span>(output_half);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"结束语\"><a href=\"#结束语\" class=\"headerlink\" title=\"结束语\"></a>结束语</h2><p>在这门课程中，<del>我根据报错找 bug 的能力确实有了很大的提高</del>，虽然体验不是很好，但是自己完成了之后还是挺有成就感的，如果您对于此篇文章有好的提议，或者对于这个实验还有其他的问题，可以向 $wz1234@buaa.edu.cn$ 发送邮件，也欢迎以其他方式和我交流</p>"}],"PostAsset":[{"_id":"source/_posts/数字电路/image-20201207103734768.png","slug":"image-20201207103734768.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207151538922.png","slug":"image-20201207151538922.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207164837016.png","slug":"image-20201207164837016.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207205834377.png","slug":"image-20201207205834377.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208212442919.png","slug":"image-20201208212442919.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201221173352870.png","slug":"image-20201221173352870.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207141338902.png","slug":"image-20201207141338902.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207163011726.png","slug":"image-20201207163011726.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207180435959.png","slug":"image-20201207180435959.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207204622034.png","slug":"image-20201207204622034.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207205904689.png","slug":"image-20201207205904689.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207230758027.png","slug":"image-20201207230758027.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207163100622.png","slug":"image-20201207163100622.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201221161604172.png","slug":"image-20201221161604172.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201221170316556.png","slug":"image-20201221170316556.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201221171419046.png","slug":"image-20201221171419046.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201221171900968.png","slug":"image-20201221171900968.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201221173107160.png","slug":"image-20201221173107160.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201221173555856.png","slug":"image-20201221173555856.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201221173834863.png","slug":"image-20201221173834863.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207095115200.png","slug":"image-20201207095115200.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207095702879.png","slug":"image-20201207095702879.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207100058038.png","slug":"image-20201207100058038.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207100101916.png","slug":"image-20201207100101916.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207100105985.png","slug":"image-20201207100105985.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207100108953.png","slug":"image-20201207100108953.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207100257128.png","slug":"image-20201207100257128.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207100339923.png","slug":"image-20201207100339923.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207100458411.png","slug":"image-20201207100458411.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207141227512.png","slug":"image-20201207141227512.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207141230974.png","slug":"image-20201207141230974.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207143351015.png","slug":"image-20201207143351015.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207143605620.png","slug":"image-20201207143605620.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207150409345.png","slug":"image-20201207150409345.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207155711758.png","slug":"image-20201207155711758.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207155851664.png","slug":"image-20201207155851664.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207155940917.png","slug":"image-20201207155940917.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207160054355.png","slug":"image-20201207160054355.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207163239045.png","slug":"image-20201207163239045.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207164852673.png","slug":"image-20201207164852673.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207180624804.png","slug":"image-20201207180624804.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207202208723.png","slug":"image-20201207202208723.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207202442317.png","slug":"image-20201207202442317.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207202617679.png","slug":"image-20201207202617679.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207202738889.png","slug":"image-20201207202738889.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207204428555.png","slug":"image-20201207204428555.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207204956445.png","slug":"image-20201207204956445.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207210045223.png","slug":"image-20201207210045223.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207211753609.png","slug":"image-20201207211753609.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207225752379.png","slug":"image-20201207225752379.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207231253193.png","slug":"image-20201207231253193.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207231257765.png","slug":"image-20201207231257765.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207231703395.png","slug":"image-20201207231703395.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207234319334.png","slug":"image-20201207234319334.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201207234431264.png","slug":"image-20201207234431264.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208093951521.png","slug":"image-20201208093951521.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208094730885.png","slug":"image-20201208094730885.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208095118685.png","slug":"image-20201208095118685.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208100213115.png","slug":"image-20201208100213115.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208100252440.png","slug":"image-20201208100252440.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208100311393.png","slug":"image-20201208100311393.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208100710777.png","slug":"image-20201208100710777.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208102916928.png","slug":"image-20201208102916928.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208103050351.png","slug":"image-20201208103050351.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208103304650.png","slug":"image-20201208103304650.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208103414917.png","slug":"image-20201208103414917.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208103416148.png","slug":"image-20201208103416148.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208120149198.png","slug":"image-20201208120149198.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208120335673.png","slug":"image-20201208120335673.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208133000921.png","slug":"image-20201208133000921.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208133500161.png","slug":"image-20201208133500161.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208162623051.png","slug":"image-20201208162623051.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208162700995.png","slug":"image-20201208162700995.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208163034352.png","slug":"image-20201208163034352.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208163053439.png","slug":"image-20201208163053439.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208163510773.png","slug":"image-20201208163510773.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208192312875.png","slug":"image-20201208192312875.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208192326383.png","slug":"image-20201208192326383.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208211819333.png","slug":"image-20201208211819333.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208211825145.png","slug":"image-20201208211825145.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208212439760.png","slug":"image-20201208212439760.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208214549378.png","slug":"image-20201208214549378.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208214717350.png","slug":"image-20201208214717350.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208214956731.png","slug":"image-20201208214956731.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208215327269.png","slug":"image-20201208215327269.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208215405366.png","slug":"image-20201208215405366.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208215446146.png","slug":"image-20201208215446146.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208215602590.png","slug":"image-20201208215602590.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208215639819.png","slug":"image-20201208215639819.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208215654220.png","slug":"image-20201208215654220.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201208215859239.png","slug":"image-20201208215859239.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201209091933646.png","slug":"image-20201209091933646.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/数字电路/image-20201209092949508.png","slug":"image-20201209092949508.png","post":"ckiyh709a0013a0uz9vnhwcoc","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201222004933612.png","slug":"image-20201222004933612.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201222004952263.png","slug":"image-20201222004952263.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201222004846500.png","slug":"image-20201222004846500.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201222004912384.png","slug":"image-20201222004912384.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201222005007770.png","slug":"image-20201222005007770.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201222014249959.png","slug":"image-20201222014249959.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201222121105346.png","slug":"image-20201222121105346.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201222121110969.png","slug":"image-20201222121110969.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201222121125219.png","slug":"image-20201222121125219.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20201222121129289.png","slug":"image-20201222121129289.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0},{"_id":"source/_posts/智能计算机/image-20200118.png","slug":"image-20200118.png","post":"ckiyh709e0014a0uz5hog7sn5","modified":0,"renderable":0}],"PostCategory":[],"PostTag":[{"post_id":"ckiyh70040000a0uzfafqh67h","tag_id":"ckiyh700n0004a0uzqsgrrrsh","_id":"ckiyh702c000ha0uzd78w4mao"},{"post_id":"ckiyh70040000a0uzfafqh67h","tag_id":"ckiyh70110009a0uz1ro2pg6c","_id":"ckiyh702h000ja0uzd7s2pbcu"},{"post_id":"ckiyh70040000a0uzfafqh67h","tag_id":"ckiyh701e000ca0uzlao2x1wy","_id":"ckiyh702w000ma0uz788ux0wo"},{"post_id":"ckiyh700j0002a0uzt2ees523","tag_id":"ckiyh7025000fa0uzwiuygzhh","_id":"ckiyh7034000na0uz6q2czzyf"},{"post_id":"ckiyh702g000ia0uzix55gl43","tag_id":"ckiyh700n0004a0uzqsgrrrsh","_id":"ckiyh703b000pa0uz9hs1hv06"},{"post_id":"ckiyh702g000ia0uzix55gl43","tag_id":"ckiyh70110009a0uz1ro2pg6c","_id":"ckiyh703g000qa0uz3v8u0smg"},{"post_id":"ckiyh700r0005a0uzr9shzlkd","tag_id":"ckiyh7025000fa0uzwiuygzhh","_id":"ckiyh703r000sa0uznzlplm2m"},{"post_id":"ckiyh700z0007a0uz8m47qx3o","tag_id":"ckiyh7025000fa0uzwiuygzhh","_id":"ckiyh7047000ta0uzx37075nc"},{"post_id":"ckiyh7013000aa0uzw85g9maf","tag_id":"ckiyh703p000ra0uz4q7a4jab","_id":"ckiyh704k000va0uz7m423jic"},{"post_id":"ckiyh7015000ba0uz1czx8bcy","tag_id":"ckiyh7025000fa0uzwiuygzhh","_id":"ckiyh704n000xa0uz2hrapvl9"},{"post_id":"ckiyh701g000da0uzb9e0qdsp","tag_id":"ckiyh704l000wa0uz24ywczch","_id":"ckiyh704o000za0uzw0dc6vzj"},{"post_id":"ckiyh7028000ga0uzxllhuef6","tag_id":"ckiyh704l000wa0uz24ywczch","_id":"ckiyh704p0011a0uzpr4eh56u"},{"post_id":"ckiyh702r000la0uz1bx5bevr","tag_id":"ckiyh704p0010a0uzvmn5uc5d","_id":"ckiyh704q0012a0uzj93j548e"}],"Tag":[{"name":"算法","_id":"ckiyh700n0004a0uzqsgrrrsh"},{"name":"动态规划","_id":"ckiyh70110009a0uz1ro2pg6c"},{"name":"背包问题","_id":"ckiyh701e000ca0uzlao2x1wy"},{"name":"机器学习","_id":"ckiyh7025000fa0uzwiuygzhh"},{"name":"STL","_id":"ckiyh703p000ra0uz4q7a4jab"},{"name":"数据结构","_id":"ckiyh704l000wa0uz24ywczch"},{"name":"题解","_id":"ckiyh704p0010a0uzvmn5uc5d"}]}}